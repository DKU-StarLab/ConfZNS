/* This file is autogenerated by tracetool, do not edit. */

#ifndef TRACE_UTIL_GENERATED_TRACERS_H
#define TRACE_UTIL_GENERATED_TRACERS_H

#include "trace/control.h"

extern TraceEvent _TRACE_RUN_POLL_HANDLERS_BEGIN_EVENT;
extern TraceEvent _TRACE_RUN_POLL_HANDLERS_END_EVENT;
extern TraceEvent _TRACE_POLL_SHRINK_EVENT;
extern TraceEvent _TRACE_POLL_GROW_EVENT;
extern TraceEvent _TRACE_POLL_ADD_EVENT;
extern TraceEvent _TRACE_POLL_REMOVE_EVENT;
extern TraceEvent _TRACE_AIO_CO_SCHEDULE_EVENT;
extern TraceEvent _TRACE_AIO_CO_SCHEDULE_BH_CB_EVENT;
extern TraceEvent _TRACE_THREAD_POOL_SUBMIT_EVENT;
extern TraceEvent _TRACE_THREAD_POOL_COMPLETE_EVENT;
extern TraceEvent _TRACE_THREAD_POOL_CANCEL_EVENT;
extern TraceEvent _TRACE_BUFFER_RESIZE_EVENT;
extern TraceEvent _TRACE_BUFFER_MOVE_EMPTY_EVENT;
extern TraceEvent _TRACE_BUFFER_MOVE_EVENT;
extern TraceEvent _TRACE_BUFFER_FREE_EVENT;
extern TraceEvent _TRACE_QEMU_FILE_MONITOR_ADD_WATCH_EVENT;
extern TraceEvent _TRACE_QEMU_FILE_MONITOR_REMOVE_WATCH_EVENT;
extern TraceEvent _TRACE_QEMU_FILE_MONITOR_NEW_EVENT;
extern TraceEvent _TRACE_QEMU_FILE_MONITOR_ENABLE_WATCH_EVENT;
extern TraceEvent _TRACE_QEMU_FILE_MONITOR_DISABLE_WATCH_EVENT;
extern TraceEvent _TRACE_QEMU_FILE_MONITOR_EVENT_EVENT;
extern TraceEvent _TRACE_QEMU_FILE_MONITOR_DISPATCH_EVENT;
extern TraceEvent _TRACE_QEMU_AIO_COROUTINE_ENTER_EVENT;
extern TraceEvent _TRACE_QEMU_COROUTINE_YIELD_EVENT;
extern TraceEvent _TRACE_QEMU_COROUTINE_TERMINATE_EVENT;
extern TraceEvent _TRACE_QEMU_CO_MUTEX_LOCK_UNCONTENDED_EVENT;
extern TraceEvent _TRACE_QEMU_CO_MUTEX_LOCK_ENTRY_EVENT;
extern TraceEvent _TRACE_QEMU_CO_MUTEX_LOCK_RETURN_EVENT;
extern TraceEvent _TRACE_QEMU_CO_MUTEX_UNLOCK_ENTRY_EVENT;
extern TraceEvent _TRACE_QEMU_CO_MUTEX_UNLOCK_RETURN_EVENT;
extern TraceEvent _TRACE_QEMU_MEMALIGN_EVENT;
extern TraceEvent _TRACE_QEMU_ANON_RAM_ALLOC_EVENT;
extern TraceEvent _TRACE_QEMU_VFREE_EVENT;
extern TraceEvent _TRACE_QEMU_ANON_RAM_FREE_EVENT;
extern TraceEvent _TRACE_HBITMAP_ITER_SKIP_WORDS_EVENT;
extern TraceEvent _TRACE_HBITMAP_RESET_EVENT;
extern TraceEvent _TRACE_HBITMAP_SET_EVENT;
extern TraceEvent _TRACE_LOCKCNT_FAST_PATH_ATTEMPT_EVENT;
extern TraceEvent _TRACE_LOCKCNT_FAST_PATH_SUCCESS_EVENT;
extern TraceEvent _TRACE_LOCKCNT_UNLOCK_ATTEMPT_EVENT;
extern TraceEvent _TRACE_LOCKCNT_UNLOCK_SUCCESS_EVENT;
extern TraceEvent _TRACE_LOCKCNT_FUTEX_WAIT_PREPARE_EVENT;
extern TraceEvent _TRACE_LOCKCNT_FUTEX_WAIT_EVENT;
extern TraceEvent _TRACE_LOCKCNT_FUTEX_WAIT_RESUME_EVENT;
extern TraceEvent _TRACE_LOCKCNT_FUTEX_WAKE_EVENT;
extern TraceEvent _TRACE_SOCKET_LISTEN_EVENT;
extern TraceEvent _TRACE_QEMU_MUTEX_LOCK_EVENT;
extern TraceEvent _TRACE_QEMU_MUTEX_LOCKED_EVENT;
extern TraceEvent _TRACE_QEMU_MUTEX_UNLOCK_EVENT;
extern TraceEvent _TRACE_QEMU_VFIO_DMA_RESET_TEMPORARY_EVENT;
extern TraceEvent _TRACE_QEMU_VFIO_RAM_BLOCK_ADDED_EVENT;
extern TraceEvent _TRACE_QEMU_VFIO_RAM_BLOCK_REMOVED_EVENT;
extern TraceEvent _TRACE_QEMU_VFIO_DUMP_MAPPING_EVENT;
extern TraceEvent _TRACE_QEMU_VFIO_FIND_MAPPING_EVENT;
extern TraceEvent _TRACE_QEMU_VFIO_NEW_MAPPING_EVENT;
extern TraceEvent _TRACE_QEMU_VFIO_DO_MAPPING_EVENT;
extern TraceEvent _TRACE_QEMU_VFIO_DMA_MAP_EVENT;
extern TraceEvent _TRACE_QEMU_VFIO_DMA_MAPPED_EVENT;
extern TraceEvent _TRACE_QEMU_VFIO_DMA_UNMAP_EVENT;
extern TraceEvent _TRACE_QEMU_VFIO_PCI_READ_CONFIG_EVENT;
extern TraceEvent _TRACE_QEMU_VFIO_PCI_WRITE_CONFIG_EVENT;
extern TraceEvent _TRACE_QEMU_VFIO_REGION_INFO_EVENT;
extern TraceEvent _TRACE_QEMU_VFIO_PCI_MAP_BAR_EVENT;
extern uint16_t _TRACE_RUN_POLL_HANDLERS_BEGIN_DSTATE;
extern uint16_t _TRACE_RUN_POLL_HANDLERS_END_DSTATE;
extern uint16_t _TRACE_POLL_SHRINK_DSTATE;
extern uint16_t _TRACE_POLL_GROW_DSTATE;
extern uint16_t _TRACE_POLL_ADD_DSTATE;
extern uint16_t _TRACE_POLL_REMOVE_DSTATE;
extern uint16_t _TRACE_AIO_CO_SCHEDULE_DSTATE;
extern uint16_t _TRACE_AIO_CO_SCHEDULE_BH_CB_DSTATE;
extern uint16_t _TRACE_THREAD_POOL_SUBMIT_DSTATE;
extern uint16_t _TRACE_THREAD_POOL_COMPLETE_DSTATE;
extern uint16_t _TRACE_THREAD_POOL_CANCEL_DSTATE;
extern uint16_t _TRACE_BUFFER_RESIZE_DSTATE;
extern uint16_t _TRACE_BUFFER_MOVE_EMPTY_DSTATE;
extern uint16_t _TRACE_BUFFER_MOVE_DSTATE;
extern uint16_t _TRACE_BUFFER_FREE_DSTATE;
extern uint16_t _TRACE_QEMU_FILE_MONITOR_ADD_WATCH_DSTATE;
extern uint16_t _TRACE_QEMU_FILE_MONITOR_REMOVE_WATCH_DSTATE;
extern uint16_t _TRACE_QEMU_FILE_MONITOR_NEW_DSTATE;
extern uint16_t _TRACE_QEMU_FILE_MONITOR_ENABLE_WATCH_DSTATE;
extern uint16_t _TRACE_QEMU_FILE_MONITOR_DISABLE_WATCH_DSTATE;
extern uint16_t _TRACE_QEMU_FILE_MONITOR_EVENT_DSTATE;
extern uint16_t _TRACE_QEMU_FILE_MONITOR_DISPATCH_DSTATE;
extern uint16_t _TRACE_QEMU_AIO_COROUTINE_ENTER_DSTATE;
extern uint16_t _TRACE_QEMU_COROUTINE_YIELD_DSTATE;
extern uint16_t _TRACE_QEMU_COROUTINE_TERMINATE_DSTATE;
extern uint16_t _TRACE_QEMU_CO_MUTEX_LOCK_UNCONTENDED_DSTATE;
extern uint16_t _TRACE_QEMU_CO_MUTEX_LOCK_ENTRY_DSTATE;
extern uint16_t _TRACE_QEMU_CO_MUTEX_LOCK_RETURN_DSTATE;
extern uint16_t _TRACE_QEMU_CO_MUTEX_UNLOCK_ENTRY_DSTATE;
extern uint16_t _TRACE_QEMU_CO_MUTEX_UNLOCK_RETURN_DSTATE;
extern uint16_t _TRACE_QEMU_MEMALIGN_DSTATE;
extern uint16_t _TRACE_QEMU_ANON_RAM_ALLOC_DSTATE;
extern uint16_t _TRACE_QEMU_VFREE_DSTATE;
extern uint16_t _TRACE_QEMU_ANON_RAM_FREE_DSTATE;
extern uint16_t _TRACE_HBITMAP_ITER_SKIP_WORDS_DSTATE;
extern uint16_t _TRACE_HBITMAP_RESET_DSTATE;
extern uint16_t _TRACE_HBITMAP_SET_DSTATE;
extern uint16_t _TRACE_LOCKCNT_FAST_PATH_ATTEMPT_DSTATE;
extern uint16_t _TRACE_LOCKCNT_FAST_PATH_SUCCESS_DSTATE;
extern uint16_t _TRACE_LOCKCNT_UNLOCK_ATTEMPT_DSTATE;
extern uint16_t _TRACE_LOCKCNT_UNLOCK_SUCCESS_DSTATE;
extern uint16_t _TRACE_LOCKCNT_FUTEX_WAIT_PREPARE_DSTATE;
extern uint16_t _TRACE_LOCKCNT_FUTEX_WAIT_DSTATE;
extern uint16_t _TRACE_LOCKCNT_FUTEX_WAIT_RESUME_DSTATE;
extern uint16_t _TRACE_LOCKCNT_FUTEX_WAKE_DSTATE;
extern uint16_t _TRACE_SOCKET_LISTEN_DSTATE;
extern uint16_t _TRACE_QEMU_MUTEX_LOCK_DSTATE;
extern uint16_t _TRACE_QEMU_MUTEX_LOCKED_DSTATE;
extern uint16_t _TRACE_QEMU_MUTEX_UNLOCK_DSTATE;
extern uint16_t _TRACE_QEMU_VFIO_DMA_RESET_TEMPORARY_DSTATE;
extern uint16_t _TRACE_QEMU_VFIO_RAM_BLOCK_ADDED_DSTATE;
extern uint16_t _TRACE_QEMU_VFIO_RAM_BLOCK_REMOVED_DSTATE;
extern uint16_t _TRACE_QEMU_VFIO_DUMP_MAPPING_DSTATE;
extern uint16_t _TRACE_QEMU_VFIO_FIND_MAPPING_DSTATE;
extern uint16_t _TRACE_QEMU_VFIO_NEW_MAPPING_DSTATE;
extern uint16_t _TRACE_QEMU_VFIO_DO_MAPPING_DSTATE;
extern uint16_t _TRACE_QEMU_VFIO_DMA_MAP_DSTATE;
extern uint16_t _TRACE_QEMU_VFIO_DMA_MAPPED_DSTATE;
extern uint16_t _TRACE_QEMU_VFIO_DMA_UNMAP_DSTATE;
extern uint16_t _TRACE_QEMU_VFIO_PCI_READ_CONFIG_DSTATE;
extern uint16_t _TRACE_QEMU_VFIO_PCI_WRITE_CONFIG_DSTATE;
extern uint16_t _TRACE_QEMU_VFIO_REGION_INFO_DSTATE;
extern uint16_t _TRACE_QEMU_VFIO_PCI_MAP_BAR_DSTATE;
#define TRACE_RUN_POLL_HANDLERS_BEGIN_ENABLED 1
#define TRACE_RUN_POLL_HANDLERS_END_ENABLED 1
#define TRACE_POLL_SHRINK_ENABLED 1
#define TRACE_POLL_GROW_ENABLED 1
#define TRACE_POLL_ADD_ENABLED 1
#define TRACE_POLL_REMOVE_ENABLED 1
#define TRACE_AIO_CO_SCHEDULE_ENABLED 1
#define TRACE_AIO_CO_SCHEDULE_BH_CB_ENABLED 1
#define TRACE_THREAD_POOL_SUBMIT_ENABLED 1
#define TRACE_THREAD_POOL_COMPLETE_ENABLED 1
#define TRACE_THREAD_POOL_CANCEL_ENABLED 1
#define TRACE_BUFFER_RESIZE_ENABLED 1
#define TRACE_BUFFER_MOVE_EMPTY_ENABLED 1
#define TRACE_BUFFER_MOVE_ENABLED 1
#define TRACE_BUFFER_FREE_ENABLED 1
#define TRACE_QEMU_FILE_MONITOR_ADD_WATCH_ENABLED 1
#define TRACE_QEMU_FILE_MONITOR_REMOVE_WATCH_ENABLED 1
#define TRACE_QEMU_FILE_MONITOR_NEW_ENABLED 1
#define TRACE_QEMU_FILE_MONITOR_ENABLE_WATCH_ENABLED 1
#define TRACE_QEMU_FILE_MONITOR_DISABLE_WATCH_ENABLED 1
#define TRACE_QEMU_FILE_MONITOR_EVENT_ENABLED 1
#define TRACE_QEMU_FILE_MONITOR_DISPATCH_ENABLED 1
#define TRACE_QEMU_AIO_COROUTINE_ENTER_ENABLED 1
#define TRACE_QEMU_COROUTINE_YIELD_ENABLED 1
#define TRACE_QEMU_COROUTINE_TERMINATE_ENABLED 1
#define TRACE_QEMU_CO_MUTEX_LOCK_UNCONTENDED_ENABLED 1
#define TRACE_QEMU_CO_MUTEX_LOCK_ENTRY_ENABLED 1
#define TRACE_QEMU_CO_MUTEX_LOCK_RETURN_ENABLED 1
#define TRACE_QEMU_CO_MUTEX_UNLOCK_ENTRY_ENABLED 1
#define TRACE_QEMU_CO_MUTEX_UNLOCK_RETURN_ENABLED 1
#define TRACE_QEMU_MEMALIGN_ENABLED 1
#define TRACE_QEMU_ANON_RAM_ALLOC_ENABLED 1
#define TRACE_QEMU_VFREE_ENABLED 1
#define TRACE_QEMU_ANON_RAM_FREE_ENABLED 1
#define TRACE_HBITMAP_ITER_SKIP_WORDS_ENABLED 1
#define TRACE_HBITMAP_RESET_ENABLED 1
#define TRACE_HBITMAP_SET_ENABLED 1
#define TRACE_LOCKCNT_FAST_PATH_ATTEMPT_ENABLED 1
#define TRACE_LOCKCNT_FAST_PATH_SUCCESS_ENABLED 1
#define TRACE_LOCKCNT_UNLOCK_ATTEMPT_ENABLED 1
#define TRACE_LOCKCNT_UNLOCK_SUCCESS_ENABLED 1
#define TRACE_LOCKCNT_FUTEX_WAIT_PREPARE_ENABLED 1
#define TRACE_LOCKCNT_FUTEX_WAIT_ENABLED 1
#define TRACE_LOCKCNT_FUTEX_WAIT_RESUME_ENABLED 1
#define TRACE_LOCKCNT_FUTEX_WAKE_ENABLED 1
#define TRACE_SOCKET_LISTEN_ENABLED 1
#define TRACE_QEMU_MUTEX_LOCK_ENABLED 1
#define TRACE_QEMU_MUTEX_LOCKED_ENABLED 1
#define TRACE_QEMU_MUTEX_UNLOCK_ENABLED 1
#define TRACE_QEMU_VFIO_DMA_RESET_TEMPORARY_ENABLED 1
#define TRACE_QEMU_VFIO_RAM_BLOCK_ADDED_ENABLED 1
#define TRACE_QEMU_VFIO_RAM_BLOCK_REMOVED_ENABLED 1
#define TRACE_QEMU_VFIO_DUMP_MAPPING_ENABLED 1
#define TRACE_QEMU_VFIO_FIND_MAPPING_ENABLED 1
#define TRACE_QEMU_VFIO_NEW_MAPPING_ENABLED 1
#define TRACE_QEMU_VFIO_DO_MAPPING_ENABLED 1
#define TRACE_QEMU_VFIO_DMA_MAP_ENABLED 1
#define TRACE_QEMU_VFIO_DMA_MAPPED_ENABLED 1
#define TRACE_QEMU_VFIO_DMA_UNMAP_ENABLED 1
#define TRACE_QEMU_VFIO_PCI_READ_CONFIG_ENABLED 1
#define TRACE_QEMU_VFIO_PCI_WRITE_CONFIG_ENABLED 1
#define TRACE_QEMU_VFIO_REGION_INFO_ENABLED 1
#define TRACE_QEMU_VFIO_PCI_MAP_BAR_ENABLED 1
#include "qemu/log-for-trace.h"


#define TRACE_RUN_POLL_HANDLERS_BEGIN_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_RUN_POLL_HANDLERS_BEGIN) || \
    false)

static inline void _nocheck__trace_run_poll_handlers_begin(void * ctx, int64_t max_ns, int64_t timeout)
{
    if (trace_event_get_state(TRACE_RUN_POLL_HANDLERS_BEGIN) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:run_poll_handlers_begin " "ctx %p max_ns %"PRId64 " timeout %"PRId64 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , ctx, max_ns, timeout);
    }
}

static inline void trace_run_poll_handlers_begin(void * ctx, int64_t max_ns, int64_t timeout)
{
    if (true) {
        _nocheck__trace_run_poll_handlers_begin(ctx, max_ns, timeout);
    }
}

#define TRACE_RUN_POLL_HANDLERS_END_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_RUN_POLL_HANDLERS_END) || \
    false)

static inline void _nocheck__trace_run_poll_handlers_end(void * ctx, bool progress, int64_t timeout)
{
    if (trace_event_get_state(TRACE_RUN_POLL_HANDLERS_END) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:run_poll_handlers_end " "ctx %p progress %d new timeout %"PRId64 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , ctx, progress, timeout);
    }
}

static inline void trace_run_poll_handlers_end(void * ctx, bool progress, int64_t timeout)
{
    if (true) {
        _nocheck__trace_run_poll_handlers_end(ctx, progress, timeout);
    }
}

#define TRACE_POLL_SHRINK_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_POLL_SHRINK) || \
    false)

static inline void _nocheck__trace_poll_shrink(void * ctx, int64_t old, int64_t new)
{
    if (trace_event_get_state(TRACE_POLL_SHRINK) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:poll_shrink " "ctx %p old %"PRId64" new %"PRId64 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , ctx, old, new);
    }
}

static inline void trace_poll_shrink(void * ctx, int64_t old, int64_t new)
{
    if (true) {
        _nocheck__trace_poll_shrink(ctx, old, new);
    }
}

#define TRACE_POLL_GROW_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_POLL_GROW) || \
    false)

static inline void _nocheck__trace_poll_grow(void * ctx, int64_t old, int64_t new)
{
    if (trace_event_get_state(TRACE_POLL_GROW) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:poll_grow " "ctx %p old %"PRId64" new %"PRId64 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , ctx, old, new);
    }
}

static inline void trace_poll_grow(void * ctx, int64_t old, int64_t new)
{
    if (true) {
        _nocheck__trace_poll_grow(ctx, old, new);
    }
}

#define TRACE_POLL_ADD_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_POLL_ADD) || \
    false)

static inline void _nocheck__trace_poll_add(void * ctx, void * node, int fd, unsigned revents)
{
    if (trace_event_get_state(TRACE_POLL_ADD) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:poll_add " "ctx %p node %p fd %d revents 0x%x" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , ctx, node, fd, revents);
    }
}

static inline void trace_poll_add(void * ctx, void * node, int fd, unsigned revents)
{
    if (true) {
        _nocheck__trace_poll_add(ctx, node, fd, revents);
    }
}

#define TRACE_POLL_REMOVE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_POLL_REMOVE) || \
    false)

static inline void _nocheck__trace_poll_remove(void * ctx, void * node, int fd)
{
    if (trace_event_get_state(TRACE_POLL_REMOVE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:poll_remove " "ctx %p node %p fd %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , ctx, node, fd);
    }
}

static inline void trace_poll_remove(void * ctx, void * node, int fd)
{
    if (true) {
        _nocheck__trace_poll_remove(ctx, node, fd);
    }
}

#define TRACE_AIO_CO_SCHEDULE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_AIO_CO_SCHEDULE) || \
    false)

static inline void _nocheck__trace_aio_co_schedule(void * ctx, void * co)
{
    if (trace_event_get_state(TRACE_AIO_CO_SCHEDULE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:aio_co_schedule " "ctx %p co %p" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , ctx, co);
    }
}

static inline void trace_aio_co_schedule(void * ctx, void * co)
{
    if (true) {
        _nocheck__trace_aio_co_schedule(ctx, co);
    }
}

#define TRACE_AIO_CO_SCHEDULE_BH_CB_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_AIO_CO_SCHEDULE_BH_CB) || \
    false)

static inline void _nocheck__trace_aio_co_schedule_bh_cb(void * ctx, void * co)
{
    if (trace_event_get_state(TRACE_AIO_CO_SCHEDULE_BH_CB) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:aio_co_schedule_bh_cb " "ctx %p co %p" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , ctx, co);
    }
}

static inline void trace_aio_co_schedule_bh_cb(void * ctx, void * co)
{
    if (true) {
        _nocheck__trace_aio_co_schedule_bh_cb(ctx, co);
    }
}

#define TRACE_THREAD_POOL_SUBMIT_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_THREAD_POOL_SUBMIT) || \
    false)

static inline void _nocheck__trace_thread_pool_submit(void * pool, void * req, void * opaque)
{
    if (trace_event_get_state(TRACE_THREAD_POOL_SUBMIT) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:thread_pool_submit " "pool %p req %p opaque %p" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , pool, req, opaque);
    }
}

static inline void trace_thread_pool_submit(void * pool, void * req, void * opaque)
{
    if (true) {
        _nocheck__trace_thread_pool_submit(pool, req, opaque);
    }
}

#define TRACE_THREAD_POOL_COMPLETE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_THREAD_POOL_COMPLETE) || \
    false)

static inline void _nocheck__trace_thread_pool_complete(void * pool, void * req, void * opaque, int ret)
{
    if (trace_event_get_state(TRACE_THREAD_POOL_COMPLETE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:thread_pool_complete " "pool %p req %p opaque %p ret %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , pool, req, opaque, ret);
    }
}

static inline void trace_thread_pool_complete(void * pool, void * req, void * opaque, int ret)
{
    if (true) {
        _nocheck__trace_thread_pool_complete(pool, req, opaque, ret);
    }
}

#define TRACE_THREAD_POOL_CANCEL_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_THREAD_POOL_CANCEL) || \
    false)

static inline void _nocheck__trace_thread_pool_cancel(void * req, void * opaque)
{
    if (trace_event_get_state(TRACE_THREAD_POOL_CANCEL) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:thread_pool_cancel " "req %p opaque %p" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , req, opaque);
    }
}

static inline void trace_thread_pool_cancel(void * req, void * opaque)
{
    if (true) {
        _nocheck__trace_thread_pool_cancel(req, opaque);
    }
}

#define TRACE_BUFFER_RESIZE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_BUFFER_RESIZE) || \
    false)

static inline void _nocheck__trace_buffer_resize(const char * buf, size_t olen, size_t len)
{
    if (trace_event_get_state(TRACE_BUFFER_RESIZE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:buffer_resize " "%s: old %zd, new %zd" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , buf, olen, len);
    }
}

static inline void trace_buffer_resize(const char * buf, size_t olen, size_t len)
{
    if (true) {
        _nocheck__trace_buffer_resize(buf, olen, len);
    }
}

#define TRACE_BUFFER_MOVE_EMPTY_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_BUFFER_MOVE_EMPTY) || \
    false)

static inline void _nocheck__trace_buffer_move_empty(const char * buf, size_t len, const char * from)
{
    if (trace_event_get_state(TRACE_BUFFER_MOVE_EMPTY) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:buffer_move_empty " "%s: %zd bytes from %s" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , buf, len, from);
    }
}

static inline void trace_buffer_move_empty(const char * buf, size_t len, const char * from)
{
    if (true) {
        _nocheck__trace_buffer_move_empty(buf, len, from);
    }
}

#define TRACE_BUFFER_MOVE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_BUFFER_MOVE) || \
    false)

static inline void _nocheck__trace_buffer_move(const char * buf, size_t len, const char * from)
{
    if (trace_event_get_state(TRACE_BUFFER_MOVE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:buffer_move " "%s: %zd bytes from %s" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , buf, len, from);
    }
}

static inline void trace_buffer_move(const char * buf, size_t len, const char * from)
{
    if (true) {
        _nocheck__trace_buffer_move(buf, len, from);
    }
}

#define TRACE_BUFFER_FREE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_BUFFER_FREE) || \
    false)

static inline void _nocheck__trace_buffer_free(const char * buf, size_t len)
{
    if (trace_event_get_state(TRACE_BUFFER_FREE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:buffer_free " "%s: capacity %zd" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , buf, len);
    }
}

static inline void trace_buffer_free(const char * buf, size_t len)
{
    if (true) {
        _nocheck__trace_buffer_free(buf, len);
    }
}

#define TRACE_QEMU_FILE_MONITOR_ADD_WATCH_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QEMU_FILE_MONITOR_ADD_WATCH) || \
    false)

static inline void _nocheck__trace_qemu_file_monitor_add_watch(void * mon, const char * dirpath, const char * filename, void * cb, void * opaque, int64_t id)
{
    if (trace_event_get_state(TRACE_QEMU_FILE_MONITOR_ADD_WATCH) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qemu_file_monitor_add_watch " "File monitor %p add watch dir='%s' file='%s' cb=%p opaque=%p id=%" PRId64 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , mon, dirpath, filename, cb, opaque, id);
    }
}

static inline void trace_qemu_file_monitor_add_watch(void * mon, const char * dirpath, const char * filename, void * cb, void * opaque, int64_t id)
{
    if (true) {
        _nocheck__trace_qemu_file_monitor_add_watch(mon, dirpath, filename, cb, opaque, id);
    }
}

#define TRACE_QEMU_FILE_MONITOR_REMOVE_WATCH_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QEMU_FILE_MONITOR_REMOVE_WATCH) || \
    false)

static inline void _nocheck__trace_qemu_file_monitor_remove_watch(void * mon, const char * dirpath, int64_t id)
{
    if (trace_event_get_state(TRACE_QEMU_FILE_MONITOR_REMOVE_WATCH) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qemu_file_monitor_remove_watch " "File monitor %p remove watch dir='%s' id=%" PRId64 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , mon, dirpath, id);
    }
}

static inline void trace_qemu_file_monitor_remove_watch(void * mon, const char * dirpath, int64_t id)
{
    if (true) {
        _nocheck__trace_qemu_file_monitor_remove_watch(mon, dirpath, id);
    }
}

#define TRACE_QEMU_FILE_MONITOR_NEW_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QEMU_FILE_MONITOR_NEW) || \
    false)

static inline void _nocheck__trace_qemu_file_monitor_new(void * mon, int fd)
{
    if (trace_event_get_state(TRACE_QEMU_FILE_MONITOR_NEW) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qemu_file_monitor_new " "File monitor %p created fd=%d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , mon, fd);
    }
}

static inline void trace_qemu_file_monitor_new(void * mon, int fd)
{
    if (true) {
        _nocheck__trace_qemu_file_monitor_new(mon, fd);
    }
}

#define TRACE_QEMU_FILE_MONITOR_ENABLE_WATCH_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QEMU_FILE_MONITOR_ENABLE_WATCH) || \
    false)

static inline void _nocheck__trace_qemu_file_monitor_enable_watch(void * mon, const char * dirpath, int id)
{
    if (trace_event_get_state(TRACE_QEMU_FILE_MONITOR_ENABLE_WATCH) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qemu_file_monitor_enable_watch " "File monitor %p enable watch dir='%s' id=%u" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , mon, dirpath, id);
    }
}

static inline void trace_qemu_file_monitor_enable_watch(void * mon, const char * dirpath, int id)
{
    if (true) {
        _nocheck__trace_qemu_file_monitor_enable_watch(mon, dirpath, id);
    }
}

#define TRACE_QEMU_FILE_MONITOR_DISABLE_WATCH_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QEMU_FILE_MONITOR_DISABLE_WATCH) || \
    false)

static inline void _nocheck__trace_qemu_file_monitor_disable_watch(void * mon, const char * dirpath, int id)
{
    if (trace_event_get_state(TRACE_QEMU_FILE_MONITOR_DISABLE_WATCH) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qemu_file_monitor_disable_watch " "File monitor %p disable watch dir='%s' id=%u" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , mon, dirpath, id);
    }
}

static inline void trace_qemu_file_monitor_disable_watch(void * mon, const char * dirpath, int id)
{
    if (true) {
        _nocheck__trace_qemu_file_monitor_disable_watch(mon, dirpath, id);
    }
}

#define TRACE_QEMU_FILE_MONITOR_EVENT_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QEMU_FILE_MONITOR_EVENT) || \
    false)

static inline void _nocheck__trace_qemu_file_monitor_event(void * mon, const char * dirpath, const char * filename, int mask, unsigned int id)
{
    if (trace_event_get_state(TRACE_QEMU_FILE_MONITOR_EVENT) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qemu_file_monitor_event " "File monitor %p event dir='%s' file='%s' mask=0x%x id=%u" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , mon, dirpath, filename, mask, id);
    }
}

static inline void trace_qemu_file_monitor_event(void * mon, const char * dirpath, const char * filename, int mask, unsigned int id)
{
    if (true) {
        _nocheck__trace_qemu_file_monitor_event(mon, dirpath, filename, mask, id);
    }
}

#define TRACE_QEMU_FILE_MONITOR_DISPATCH_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QEMU_FILE_MONITOR_DISPATCH) || \
    false)

static inline void _nocheck__trace_qemu_file_monitor_dispatch(void * mon, const char * dirpath, const char * filename, int ev, void * cb, void * opaque, int64_t id)
{
    if (trace_event_get_state(TRACE_QEMU_FILE_MONITOR_DISPATCH) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qemu_file_monitor_dispatch " "File monitor %p dispatch dir='%s' file='%s' ev=%d cb=%p opaque=%p id=%" PRId64 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , mon, dirpath, filename, ev, cb, opaque, id);
    }
}

static inline void trace_qemu_file_monitor_dispatch(void * mon, const char * dirpath, const char * filename, int ev, void * cb, void * opaque, int64_t id)
{
    if (true) {
        _nocheck__trace_qemu_file_monitor_dispatch(mon, dirpath, filename, ev, cb, opaque, id);
    }
}

#define TRACE_QEMU_AIO_COROUTINE_ENTER_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QEMU_AIO_COROUTINE_ENTER) || \
    false)

static inline void _nocheck__trace_qemu_aio_coroutine_enter(void * ctx, void * from, void * to, void * opaque)
{
    if (trace_event_get_state(TRACE_QEMU_AIO_COROUTINE_ENTER) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qemu_aio_coroutine_enter " "ctx %p from %p to %p opaque %p" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , ctx, from, to, opaque);
    }
}

static inline void trace_qemu_aio_coroutine_enter(void * ctx, void * from, void * to, void * opaque)
{
    if (true) {
        _nocheck__trace_qemu_aio_coroutine_enter(ctx, from, to, opaque);
    }
}

#define TRACE_QEMU_COROUTINE_YIELD_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QEMU_COROUTINE_YIELD) || \
    false)

static inline void _nocheck__trace_qemu_coroutine_yield(void * from, void * to)
{
    if (trace_event_get_state(TRACE_QEMU_COROUTINE_YIELD) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qemu_coroutine_yield " "from %p to %p" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , from, to);
    }
}

static inline void trace_qemu_coroutine_yield(void * from, void * to)
{
    if (true) {
        _nocheck__trace_qemu_coroutine_yield(from, to);
    }
}

#define TRACE_QEMU_COROUTINE_TERMINATE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QEMU_COROUTINE_TERMINATE) || \
    false)

static inline void _nocheck__trace_qemu_coroutine_terminate(void * co)
{
    if (trace_event_get_state(TRACE_QEMU_COROUTINE_TERMINATE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qemu_coroutine_terminate " "self %p" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , co);
    }
}

static inline void trace_qemu_coroutine_terminate(void * co)
{
    if (true) {
        _nocheck__trace_qemu_coroutine_terminate(co);
    }
}

#define TRACE_QEMU_CO_MUTEX_LOCK_UNCONTENDED_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QEMU_CO_MUTEX_LOCK_UNCONTENDED) || \
    false)

static inline void _nocheck__trace_qemu_co_mutex_lock_uncontended(void * mutex, void * self)
{
    if (trace_event_get_state(TRACE_QEMU_CO_MUTEX_LOCK_UNCONTENDED) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qemu_co_mutex_lock_uncontended " "mutex %p self %p" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , mutex, self);
    }
}

static inline void trace_qemu_co_mutex_lock_uncontended(void * mutex, void * self)
{
    if (true) {
        _nocheck__trace_qemu_co_mutex_lock_uncontended(mutex, self);
    }
}

#define TRACE_QEMU_CO_MUTEX_LOCK_ENTRY_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QEMU_CO_MUTEX_LOCK_ENTRY) || \
    false)

static inline void _nocheck__trace_qemu_co_mutex_lock_entry(void * mutex, void * self)
{
    if (trace_event_get_state(TRACE_QEMU_CO_MUTEX_LOCK_ENTRY) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qemu_co_mutex_lock_entry " "mutex %p self %p" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , mutex, self);
    }
}

static inline void trace_qemu_co_mutex_lock_entry(void * mutex, void * self)
{
    if (true) {
        _nocheck__trace_qemu_co_mutex_lock_entry(mutex, self);
    }
}

#define TRACE_QEMU_CO_MUTEX_LOCK_RETURN_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QEMU_CO_MUTEX_LOCK_RETURN) || \
    false)

static inline void _nocheck__trace_qemu_co_mutex_lock_return(void * mutex, void * self)
{
    if (trace_event_get_state(TRACE_QEMU_CO_MUTEX_LOCK_RETURN) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qemu_co_mutex_lock_return " "mutex %p self %p" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , mutex, self);
    }
}

static inline void trace_qemu_co_mutex_lock_return(void * mutex, void * self)
{
    if (true) {
        _nocheck__trace_qemu_co_mutex_lock_return(mutex, self);
    }
}

#define TRACE_QEMU_CO_MUTEX_UNLOCK_ENTRY_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QEMU_CO_MUTEX_UNLOCK_ENTRY) || \
    false)

static inline void _nocheck__trace_qemu_co_mutex_unlock_entry(void * mutex, void * self)
{
    if (trace_event_get_state(TRACE_QEMU_CO_MUTEX_UNLOCK_ENTRY) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qemu_co_mutex_unlock_entry " "mutex %p self %p" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , mutex, self);
    }
}

static inline void trace_qemu_co_mutex_unlock_entry(void * mutex, void * self)
{
    if (true) {
        _nocheck__trace_qemu_co_mutex_unlock_entry(mutex, self);
    }
}

#define TRACE_QEMU_CO_MUTEX_UNLOCK_RETURN_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QEMU_CO_MUTEX_UNLOCK_RETURN) || \
    false)

static inline void _nocheck__trace_qemu_co_mutex_unlock_return(void * mutex, void * self)
{
    if (trace_event_get_state(TRACE_QEMU_CO_MUTEX_UNLOCK_RETURN) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qemu_co_mutex_unlock_return " "mutex %p self %p" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , mutex, self);
    }
}

static inline void trace_qemu_co_mutex_unlock_return(void * mutex, void * self)
{
    if (true) {
        _nocheck__trace_qemu_co_mutex_unlock_return(mutex, self);
    }
}

#define TRACE_QEMU_MEMALIGN_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QEMU_MEMALIGN) || \
    false)

static inline void _nocheck__trace_qemu_memalign(size_t alignment, size_t size, void * ptr)
{
    if (trace_event_get_state(TRACE_QEMU_MEMALIGN) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qemu_memalign " "alignment %zu size %zu ptr %p" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , alignment, size, ptr);
    }
}

static inline void trace_qemu_memalign(size_t alignment, size_t size, void * ptr)
{
    if (true) {
        _nocheck__trace_qemu_memalign(alignment, size, ptr);
    }
}

#define TRACE_QEMU_ANON_RAM_ALLOC_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QEMU_ANON_RAM_ALLOC) || \
    false)

static inline void _nocheck__trace_qemu_anon_ram_alloc(size_t size, void * ptr)
{
    if (trace_event_get_state(TRACE_QEMU_ANON_RAM_ALLOC) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qemu_anon_ram_alloc " "size %zu ptr %p" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , size, ptr);
    }
}

static inline void trace_qemu_anon_ram_alloc(size_t size, void * ptr)
{
    if (true) {
        _nocheck__trace_qemu_anon_ram_alloc(size, ptr);
    }
}

#define TRACE_QEMU_VFREE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QEMU_VFREE) || \
    false)

static inline void _nocheck__trace_qemu_vfree(void * ptr)
{
    if (trace_event_get_state(TRACE_QEMU_VFREE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qemu_vfree " "ptr %p" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , ptr);
    }
}

static inline void trace_qemu_vfree(void * ptr)
{
    if (true) {
        _nocheck__trace_qemu_vfree(ptr);
    }
}

#define TRACE_QEMU_ANON_RAM_FREE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QEMU_ANON_RAM_FREE) || \
    false)

static inline void _nocheck__trace_qemu_anon_ram_free(void * ptr, size_t size)
{
    if (trace_event_get_state(TRACE_QEMU_ANON_RAM_FREE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qemu_anon_ram_free " "ptr %p size %zu" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , ptr, size);
    }
}

static inline void trace_qemu_anon_ram_free(void * ptr, size_t size)
{
    if (true) {
        _nocheck__trace_qemu_anon_ram_free(ptr, size);
    }
}

#define TRACE_HBITMAP_ITER_SKIP_WORDS_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_HBITMAP_ITER_SKIP_WORDS) || \
    false)

static inline void _nocheck__trace_hbitmap_iter_skip_words(const void * hb, void * hbi, uint64_t pos, unsigned long cur)
{
    if (trace_event_get_state(TRACE_HBITMAP_ITER_SKIP_WORDS) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:hbitmap_iter_skip_words " "hb %p hbi %p pos %"PRId64" cur 0x%lx" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , hb, hbi, pos, cur);
    }
}

static inline void trace_hbitmap_iter_skip_words(const void * hb, void * hbi, uint64_t pos, unsigned long cur)
{
    if (true) {
        _nocheck__trace_hbitmap_iter_skip_words(hb, hbi, pos, cur);
    }
}

#define TRACE_HBITMAP_RESET_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_HBITMAP_RESET) || \
    false)

static inline void _nocheck__trace_hbitmap_reset(void * hb, uint64_t start, uint64_t count, uint64_t sbit, uint64_t ebit)
{
    if (trace_event_get_state(TRACE_HBITMAP_RESET) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:hbitmap_reset " "hb %p items %"PRIu64",%"PRIu64" bits %"PRIu64"..%"PRIu64 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , hb, start, count, sbit, ebit);
    }
}

static inline void trace_hbitmap_reset(void * hb, uint64_t start, uint64_t count, uint64_t sbit, uint64_t ebit)
{
    if (true) {
        _nocheck__trace_hbitmap_reset(hb, start, count, sbit, ebit);
    }
}

#define TRACE_HBITMAP_SET_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_HBITMAP_SET) || \
    false)

static inline void _nocheck__trace_hbitmap_set(void * hb, uint64_t start, uint64_t count, uint64_t sbit, uint64_t ebit)
{
    if (trace_event_get_state(TRACE_HBITMAP_SET) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:hbitmap_set " "hb %p items %"PRIu64",%"PRIu64" bits %"PRIu64"..%"PRIu64 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , hb, start, count, sbit, ebit);
    }
}

static inline void trace_hbitmap_set(void * hb, uint64_t start, uint64_t count, uint64_t sbit, uint64_t ebit)
{
    if (true) {
        _nocheck__trace_hbitmap_set(hb, start, count, sbit, ebit);
    }
}

#define TRACE_LOCKCNT_FAST_PATH_ATTEMPT_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_LOCKCNT_FAST_PATH_ATTEMPT) || \
    false)

static inline void _nocheck__trace_lockcnt_fast_path_attempt(const void * lockcnt, int expected, int new)
{
    if (trace_event_get_state(TRACE_LOCKCNT_FAST_PATH_ATTEMPT) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:lockcnt_fast_path_attempt " "lockcnt %p fast path %d->%d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , lockcnt, expected, new);
    }
}

static inline void trace_lockcnt_fast_path_attempt(const void * lockcnt, int expected, int new)
{
    if (true) {
        _nocheck__trace_lockcnt_fast_path_attempt(lockcnt, expected, new);
    }
}

#define TRACE_LOCKCNT_FAST_PATH_SUCCESS_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_LOCKCNT_FAST_PATH_SUCCESS) || \
    false)

static inline void _nocheck__trace_lockcnt_fast_path_success(const void * lockcnt, int expected, int new)
{
    if (trace_event_get_state(TRACE_LOCKCNT_FAST_PATH_SUCCESS) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:lockcnt_fast_path_success " "lockcnt %p fast path %d->%d succeeded" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , lockcnt, expected, new);
    }
}

static inline void trace_lockcnt_fast_path_success(const void * lockcnt, int expected, int new)
{
    if (true) {
        _nocheck__trace_lockcnt_fast_path_success(lockcnt, expected, new);
    }
}

#define TRACE_LOCKCNT_UNLOCK_ATTEMPT_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_LOCKCNT_UNLOCK_ATTEMPT) || \
    false)

static inline void _nocheck__trace_lockcnt_unlock_attempt(const void * lockcnt, int expected, int new)
{
    if (trace_event_get_state(TRACE_LOCKCNT_UNLOCK_ATTEMPT) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:lockcnt_unlock_attempt " "lockcnt %p unlock %d->%d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , lockcnt, expected, new);
    }
}

static inline void trace_lockcnt_unlock_attempt(const void * lockcnt, int expected, int new)
{
    if (true) {
        _nocheck__trace_lockcnt_unlock_attempt(lockcnt, expected, new);
    }
}

#define TRACE_LOCKCNT_UNLOCK_SUCCESS_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_LOCKCNT_UNLOCK_SUCCESS) || \
    false)

static inline void _nocheck__trace_lockcnt_unlock_success(const void * lockcnt, int expected, int new)
{
    if (trace_event_get_state(TRACE_LOCKCNT_UNLOCK_SUCCESS) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:lockcnt_unlock_success " "lockcnt %p unlock %d->%d succeeded" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , lockcnt, expected, new);
    }
}

static inline void trace_lockcnt_unlock_success(const void * lockcnt, int expected, int new)
{
    if (true) {
        _nocheck__trace_lockcnt_unlock_success(lockcnt, expected, new);
    }
}

#define TRACE_LOCKCNT_FUTEX_WAIT_PREPARE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_LOCKCNT_FUTEX_WAIT_PREPARE) || \
    false)

static inline void _nocheck__trace_lockcnt_futex_wait_prepare(const void * lockcnt, int expected, int new)
{
    if (trace_event_get_state(TRACE_LOCKCNT_FUTEX_WAIT_PREPARE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:lockcnt_futex_wait_prepare " "lockcnt %p preparing slow path %d->%d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , lockcnt, expected, new);
    }
}

static inline void trace_lockcnt_futex_wait_prepare(const void * lockcnt, int expected, int new)
{
    if (true) {
        _nocheck__trace_lockcnt_futex_wait_prepare(lockcnt, expected, new);
    }
}

#define TRACE_LOCKCNT_FUTEX_WAIT_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_LOCKCNT_FUTEX_WAIT) || \
    false)

static inline void _nocheck__trace_lockcnt_futex_wait(const void * lockcnt, int val)
{
    if (trace_event_get_state(TRACE_LOCKCNT_FUTEX_WAIT) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:lockcnt_futex_wait " "lockcnt %p waiting on %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , lockcnt, val);
    }
}

static inline void trace_lockcnt_futex_wait(const void * lockcnt, int val)
{
    if (true) {
        _nocheck__trace_lockcnt_futex_wait(lockcnt, val);
    }
}

#define TRACE_LOCKCNT_FUTEX_WAIT_RESUME_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_LOCKCNT_FUTEX_WAIT_RESUME) || \
    false)

static inline void _nocheck__trace_lockcnt_futex_wait_resume(const void * lockcnt, int new)
{
    if (trace_event_get_state(TRACE_LOCKCNT_FUTEX_WAIT_RESUME) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:lockcnt_futex_wait_resume " "lockcnt %p after wait: %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , lockcnt, new);
    }
}

static inline void trace_lockcnt_futex_wait_resume(const void * lockcnt, int new)
{
    if (true) {
        _nocheck__trace_lockcnt_futex_wait_resume(lockcnt, new);
    }
}

#define TRACE_LOCKCNT_FUTEX_WAKE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_LOCKCNT_FUTEX_WAKE) || \
    false)

static inline void _nocheck__trace_lockcnt_futex_wake(const void * lockcnt)
{
    if (trace_event_get_state(TRACE_LOCKCNT_FUTEX_WAKE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:lockcnt_futex_wake " "lockcnt %p waking up one waiter" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , lockcnt);
    }
}

static inline void trace_lockcnt_futex_wake(const void * lockcnt)
{
    if (true) {
        _nocheck__trace_lockcnt_futex_wake(lockcnt);
    }
}

#define TRACE_SOCKET_LISTEN_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_SOCKET_LISTEN) || \
    false)

static inline void _nocheck__trace_socket_listen(int num)
{
    if (trace_event_get_state(TRACE_SOCKET_LISTEN) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:socket_listen " "backlog: %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , num);
    }
}

static inline void trace_socket_listen(int num)
{
    if (true) {
        _nocheck__trace_socket_listen(num);
    }
}

#define TRACE_QEMU_MUTEX_LOCK_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QEMU_MUTEX_LOCK) || \
    false)

static inline void _nocheck__trace_qemu_mutex_lock(void * mutex, const char * file, const int line)
{
    if (trace_event_get_state(TRACE_QEMU_MUTEX_LOCK) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qemu_mutex_lock " "waiting on mutex %p (%s:%d)" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , mutex, file, line);
    }
}

static inline void trace_qemu_mutex_lock(void * mutex, const char * file, const int line)
{
    if (true) {
        _nocheck__trace_qemu_mutex_lock(mutex, file, line);
    }
}

#define TRACE_QEMU_MUTEX_LOCKED_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QEMU_MUTEX_LOCKED) || \
    false)

static inline void _nocheck__trace_qemu_mutex_locked(void * mutex, const char * file, const int line)
{
    if (trace_event_get_state(TRACE_QEMU_MUTEX_LOCKED) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qemu_mutex_locked " "taken mutex %p (%s:%d)" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , mutex, file, line);
    }
}

static inline void trace_qemu_mutex_locked(void * mutex, const char * file, const int line)
{
    if (true) {
        _nocheck__trace_qemu_mutex_locked(mutex, file, line);
    }
}

#define TRACE_QEMU_MUTEX_UNLOCK_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QEMU_MUTEX_UNLOCK) || \
    false)

static inline void _nocheck__trace_qemu_mutex_unlock(void * mutex, const char * file, const int line)
{
    if (trace_event_get_state(TRACE_QEMU_MUTEX_UNLOCK) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qemu_mutex_unlock " "released mutex %p (%s:%d)" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , mutex, file, line);
    }
}

static inline void trace_qemu_mutex_unlock(void * mutex, const char * file, const int line)
{
    if (true) {
        _nocheck__trace_qemu_mutex_unlock(mutex, file, line);
    }
}

#define TRACE_QEMU_VFIO_DMA_RESET_TEMPORARY_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QEMU_VFIO_DMA_RESET_TEMPORARY) || \
    false)

static inline void _nocheck__trace_qemu_vfio_dma_reset_temporary(void * s)
{
    if (trace_event_get_state(TRACE_QEMU_VFIO_DMA_RESET_TEMPORARY) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qemu_vfio_dma_reset_temporary " "s %p" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s);
    }
}

static inline void trace_qemu_vfio_dma_reset_temporary(void * s)
{
    if (true) {
        _nocheck__trace_qemu_vfio_dma_reset_temporary(s);
    }
}

#define TRACE_QEMU_VFIO_RAM_BLOCK_ADDED_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QEMU_VFIO_RAM_BLOCK_ADDED) || \
    false)

static inline void _nocheck__trace_qemu_vfio_ram_block_added(void * s, void * p, size_t size)
{
    if (trace_event_get_state(TRACE_QEMU_VFIO_RAM_BLOCK_ADDED) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qemu_vfio_ram_block_added " "s %p host %p size 0x%zx" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, p, size);
    }
}

static inline void trace_qemu_vfio_ram_block_added(void * s, void * p, size_t size)
{
    if (true) {
        _nocheck__trace_qemu_vfio_ram_block_added(s, p, size);
    }
}

#define TRACE_QEMU_VFIO_RAM_BLOCK_REMOVED_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QEMU_VFIO_RAM_BLOCK_REMOVED) || \
    false)

static inline void _nocheck__trace_qemu_vfio_ram_block_removed(void * s, void * p, size_t size)
{
    if (trace_event_get_state(TRACE_QEMU_VFIO_RAM_BLOCK_REMOVED) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qemu_vfio_ram_block_removed " "s %p host %p size 0x%zx" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, p, size);
    }
}

static inline void trace_qemu_vfio_ram_block_removed(void * s, void * p, size_t size)
{
    if (true) {
        _nocheck__trace_qemu_vfio_ram_block_removed(s, p, size);
    }
}

#define TRACE_QEMU_VFIO_DUMP_MAPPING_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QEMU_VFIO_DUMP_MAPPING) || \
    false)

static inline void _nocheck__trace_qemu_vfio_dump_mapping(void * host, uint64_t iova, size_t size)
{
    if (trace_event_get_state(TRACE_QEMU_VFIO_DUMP_MAPPING) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qemu_vfio_dump_mapping " "vfio mapping %p to iova 0x%08" PRIx64 " size 0x%zx" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , host, iova, size);
    }
}

static inline void trace_qemu_vfio_dump_mapping(void * host, uint64_t iova, size_t size)
{
    if (true) {
        _nocheck__trace_qemu_vfio_dump_mapping(host, iova, size);
    }
}

#define TRACE_QEMU_VFIO_FIND_MAPPING_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QEMU_VFIO_FIND_MAPPING) || \
    false)

static inline void _nocheck__trace_qemu_vfio_find_mapping(void * s, void * p)
{
    if (trace_event_get_state(TRACE_QEMU_VFIO_FIND_MAPPING) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qemu_vfio_find_mapping " "s %p host %p" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, p);
    }
}

static inline void trace_qemu_vfio_find_mapping(void * s, void * p)
{
    if (true) {
        _nocheck__trace_qemu_vfio_find_mapping(s, p);
    }
}

#define TRACE_QEMU_VFIO_NEW_MAPPING_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QEMU_VFIO_NEW_MAPPING) || \
    false)

static inline void _nocheck__trace_qemu_vfio_new_mapping(void * s, void * host, size_t size, int index, uint64_t iova)
{
    if (trace_event_get_state(TRACE_QEMU_VFIO_NEW_MAPPING) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qemu_vfio_new_mapping " "s %p host %p size 0x%zx index %d iova 0x%"PRIx64 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, host, size, index, iova);
    }
}

static inline void trace_qemu_vfio_new_mapping(void * s, void * host, size_t size, int index, uint64_t iova)
{
    if (true) {
        _nocheck__trace_qemu_vfio_new_mapping(s, host, size, index, iova);
    }
}

#define TRACE_QEMU_VFIO_DO_MAPPING_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QEMU_VFIO_DO_MAPPING) || \
    false)

static inline void _nocheck__trace_qemu_vfio_do_mapping(void * s, void * host, uint64_t iova, size_t size)
{
    if (trace_event_get_state(TRACE_QEMU_VFIO_DO_MAPPING) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qemu_vfio_do_mapping " "s %p host %p <-> iova 0x%"PRIx64 " size 0x%zx" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, host, iova, size);
    }
}

static inline void trace_qemu_vfio_do_mapping(void * s, void * host, uint64_t iova, size_t size)
{
    if (true) {
        _nocheck__trace_qemu_vfio_do_mapping(s, host, iova, size);
    }
}

#define TRACE_QEMU_VFIO_DMA_MAP_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QEMU_VFIO_DMA_MAP) || \
    false)

static inline void _nocheck__trace_qemu_vfio_dma_map(void * s, void * host, size_t size, bool temporary, uint64_t * iova)
{
    if (trace_event_get_state(TRACE_QEMU_VFIO_DMA_MAP) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qemu_vfio_dma_map " "s %p host %p size 0x%zx temporary %d &iova %p" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, host, size, temporary, iova);
    }
}

static inline void trace_qemu_vfio_dma_map(void * s, void * host, size_t size, bool temporary, uint64_t * iova)
{
    if (true) {
        _nocheck__trace_qemu_vfio_dma_map(s, host, size, temporary, iova);
    }
}

#define TRACE_QEMU_VFIO_DMA_MAPPED_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QEMU_VFIO_DMA_MAPPED) || \
    false)

static inline void _nocheck__trace_qemu_vfio_dma_mapped(void * s, void * host, uint64_t iova, size_t size)
{
    if (trace_event_get_state(TRACE_QEMU_VFIO_DMA_MAPPED) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qemu_vfio_dma_mapped " "s %p host %p <-> iova 0x%"PRIx64" size 0x%zx" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, host, iova, size);
    }
}

static inline void trace_qemu_vfio_dma_mapped(void * s, void * host, uint64_t iova, size_t size)
{
    if (true) {
        _nocheck__trace_qemu_vfio_dma_mapped(s, host, iova, size);
    }
}

#define TRACE_QEMU_VFIO_DMA_UNMAP_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QEMU_VFIO_DMA_UNMAP) || \
    false)

static inline void _nocheck__trace_qemu_vfio_dma_unmap(void * s, void * host)
{
    if (trace_event_get_state(TRACE_QEMU_VFIO_DMA_UNMAP) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qemu_vfio_dma_unmap " "s %p host %p" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, host);
    }
}

static inline void trace_qemu_vfio_dma_unmap(void * s, void * host)
{
    if (true) {
        _nocheck__trace_qemu_vfio_dma_unmap(s, host);
    }
}

#define TRACE_QEMU_VFIO_PCI_READ_CONFIG_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QEMU_VFIO_PCI_READ_CONFIG) || \
    false)

static inline void _nocheck__trace_qemu_vfio_pci_read_config(void * buf, int ofs, int size, uint64_t region_ofs, uint64_t region_size)
{
    if (trace_event_get_state(TRACE_QEMU_VFIO_PCI_READ_CONFIG) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qemu_vfio_pci_read_config " "read cfg ptr %p ofs 0x%x size 0x%x (region addr 0x%"PRIx64" size 0x%"PRIx64")" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , buf, ofs, size, region_ofs, region_size);
    }
}

static inline void trace_qemu_vfio_pci_read_config(void * buf, int ofs, int size, uint64_t region_ofs, uint64_t region_size)
{
    if (true) {
        _nocheck__trace_qemu_vfio_pci_read_config(buf, ofs, size, region_ofs, region_size);
    }
}

#define TRACE_QEMU_VFIO_PCI_WRITE_CONFIG_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QEMU_VFIO_PCI_WRITE_CONFIG) || \
    false)

static inline void _nocheck__trace_qemu_vfio_pci_write_config(void * buf, int ofs, int size, uint64_t region_ofs, uint64_t region_size)
{
    if (trace_event_get_state(TRACE_QEMU_VFIO_PCI_WRITE_CONFIG) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qemu_vfio_pci_write_config " "write cfg ptr %p ofs 0x%x size 0x%x (region addr 0x%"PRIx64" size 0x%"PRIx64")" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , buf, ofs, size, region_ofs, region_size);
    }
}

static inline void trace_qemu_vfio_pci_write_config(void * buf, int ofs, int size, uint64_t region_ofs, uint64_t region_size)
{
    if (true) {
        _nocheck__trace_qemu_vfio_pci_write_config(buf, ofs, size, region_ofs, region_size);
    }
}

#define TRACE_QEMU_VFIO_REGION_INFO_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QEMU_VFIO_REGION_INFO) || \
    false)

static inline void _nocheck__trace_qemu_vfio_region_info(const char * desc, uint64_t region_ofs, uint64_t region_size, uint32_t cap_offset)
{
    if (trace_event_get_state(TRACE_QEMU_VFIO_REGION_INFO) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qemu_vfio_region_info " "region '%s' addr 0x%"PRIx64" size 0x%"PRIx64" cap_ofs 0x%"PRIx32 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , desc, region_ofs, region_size, cap_offset);
    }
}

static inline void trace_qemu_vfio_region_info(const char * desc, uint64_t region_ofs, uint64_t region_size, uint32_t cap_offset)
{
    if (true) {
        _nocheck__trace_qemu_vfio_region_info(desc, region_ofs, region_size, cap_offset);
    }
}

#define TRACE_QEMU_VFIO_PCI_MAP_BAR_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QEMU_VFIO_PCI_MAP_BAR) || \
    false)

static inline void _nocheck__trace_qemu_vfio_pci_map_bar(int index, uint64_t region_ofs, uint64_t region_size, int ofs, void * host)
{
    if (trace_event_get_state(TRACE_QEMU_VFIO_PCI_MAP_BAR) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qemu_vfio_pci_map_bar " "map region bar#%d addr 0x%"PRIx64" size 0x%"PRIx64" ofs 0x%x host %p" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , index, region_ofs, region_size, ofs, host);
    }
}

static inline void trace_qemu_vfio_pci_map_bar(int index, uint64_t region_ofs, uint64_t region_size, int ofs, void * host)
{
    if (true) {
        _nocheck__trace_qemu_vfio_pci_map_bar(index, region_ofs, region_size, ofs, host);
    }
}
#endif /* TRACE_UTIL_GENERATED_TRACERS_H */
