/* This file is autogenerated by tracetool, do not edit. */

#ifndef TRACE_BLOCK_GENERATED_TRACERS_H
#define TRACE_BLOCK_GENERATED_TRACERS_H

#include "trace/control.h"

extern TraceEvent _TRACE_BDRV_OPEN_COMMON_EVENT;
extern TraceEvent _TRACE_BDRV_LOCK_MEDIUM_EVENT;
extern TraceEvent _TRACE_BLK_CO_PREADV_EVENT;
extern TraceEvent _TRACE_BLK_CO_PWRITEV_EVENT;
extern TraceEvent _TRACE_BLK_ROOT_ATTACH_EVENT;
extern TraceEvent _TRACE_BLK_ROOT_DETACH_EVENT;
extern TraceEvent _TRACE_BDRV_CO_PREADV_EVENT;
extern TraceEvent _TRACE_BDRV_CO_PWRITEV_EVENT;
extern TraceEvent _TRACE_BDRV_CO_PWRITE_ZEROES_EVENT;
extern TraceEvent _TRACE_BDRV_CO_DO_COPY_ON_READV_EVENT;
extern TraceEvent _TRACE_BDRV_CO_COPY_RANGE_FROM_EVENT;
extern TraceEvent _TRACE_BDRV_CO_COPY_RANGE_TO_EVENT;
extern TraceEvent _TRACE_STREAM_ONE_ITERATION_EVENT;
extern TraceEvent _TRACE_STREAM_START_EVENT;
extern TraceEvent _TRACE_COMMIT_ONE_ITERATION_EVENT;
extern TraceEvent _TRACE_COMMIT_START_EVENT;
extern TraceEvent _TRACE_MIRROR_START_EVENT;
extern TraceEvent _TRACE_MIRROR_RESTART_ITER_EVENT;
extern TraceEvent _TRACE_MIRROR_BEFORE_FLUSH_EVENT;
extern TraceEvent _TRACE_MIRROR_BEFORE_DRAIN_EVENT;
extern TraceEvent _TRACE_MIRROR_BEFORE_SLEEP_EVENT;
extern TraceEvent _TRACE_MIRROR_ONE_ITERATION_EVENT;
extern TraceEvent _TRACE_MIRROR_ITERATION_DONE_EVENT;
extern TraceEvent _TRACE_MIRROR_YIELD_EVENT;
extern TraceEvent _TRACE_MIRROR_YIELD_IN_FLIGHT_EVENT;
extern TraceEvent _TRACE_BACKUP_DO_COW_ENTER_EVENT;
extern TraceEvent _TRACE_BACKUP_DO_COW_RETURN_EVENT;
extern TraceEvent _TRACE_BLOCK_COPY_SKIP_RANGE_EVENT;
extern TraceEvent _TRACE_BLOCK_COPY_PROCESS_EVENT;
extern TraceEvent _TRACE_BLOCK_COPY_COPY_RANGE_FAIL_EVENT;
extern TraceEvent _TRACE_BLOCK_COPY_READ_FAIL_EVENT;
extern TraceEvent _TRACE_BLOCK_COPY_WRITE_FAIL_EVENT;
extern TraceEvent _TRACE_BLOCK_COPY_WRITE_ZEROES_FAIL_EVENT;
extern TraceEvent _TRACE_QMP_BLOCK_JOB_CANCEL_EVENT;
extern TraceEvent _TRACE_QMP_BLOCK_JOB_PAUSE_EVENT;
extern TraceEvent _TRACE_QMP_BLOCK_JOB_RESUME_EVENT;
extern TraceEvent _TRACE_QMP_BLOCK_JOB_COMPLETE_EVENT;
extern TraceEvent _TRACE_QMP_BLOCK_JOB_FINALIZE_EVENT;
extern TraceEvent _TRACE_QMP_BLOCK_JOB_DISMISS_EVENT;
extern TraceEvent _TRACE_QMP_BLOCK_STREAM_EVENT;
extern TraceEvent _TRACE_FILE_PAIO_SUBMIT_EVENT;
extern TraceEvent _TRACE_LURING_INIT_STATE_EVENT;
extern TraceEvent _TRACE_LURING_CLEANUP_STATE_EVENT;
extern TraceEvent _TRACE_LURING_IO_PLUG_EVENT;
extern TraceEvent _TRACE_LURING_IO_UNPLUG_EVENT;
extern TraceEvent _TRACE_LURING_DO_SUBMIT_EVENT;
extern TraceEvent _TRACE_LURING_DO_SUBMIT_DONE_EVENT;
extern TraceEvent _TRACE_LURING_CO_SUBMIT_EVENT;
extern TraceEvent _TRACE_LURING_PROCESS_COMPLETION_EVENT;
extern TraceEvent _TRACE_LURING_IO_URING_SUBMIT_EVENT;
extern TraceEvent _TRACE_LURING_RESUBMIT_SHORT_READ_EVENT;
extern TraceEvent _TRACE_QCOW2_ADD_TASK_EVENT;
extern TraceEvent _TRACE_QCOW2_WRITEV_START_REQ_EVENT;
extern TraceEvent _TRACE_QCOW2_WRITEV_DONE_REQ_EVENT;
extern TraceEvent _TRACE_QCOW2_WRITEV_START_PART_EVENT;
extern TraceEvent _TRACE_QCOW2_WRITEV_DONE_PART_EVENT;
extern TraceEvent _TRACE_QCOW2_WRITEV_DATA_EVENT;
extern TraceEvent _TRACE_QCOW2_PWRITE_ZEROES_START_REQ_EVENT;
extern TraceEvent _TRACE_QCOW2_PWRITE_ZEROES_EVENT;
extern TraceEvent _TRACE_QCOW2_SKIP_COW_EVENT;
extern TraceEvent _TRACE_QCOW2_ALLOC_CLUSTERS_OFFSET_EVENT;
extern TraceEvent _TRACE_QCOW2_HANDLE_COPIED_EVENT;
extern TraceEvent _TRACE_QCOW2_HANDLE_ALLOC_EVENT;
extern TraceEvent _TRACE_QCOW2_DO_ALLOC_CLUSTERS_OFFSET_EVENT;
extern TraceEvent _TRACE_QCOW2_CLUSTER_ALLOC_PHYS_EVENT;
extern TraceEvent _TRACE_QCOW2_CLUSTER_LINK_L2_EVENT;
extern TraceEvent _TRACE_QCOW2_L2_ALLOCATE_EVENT;
extern TraceEvent _TRACE_QCOW2_L2_ALLOCATE_GET_EMPTY_EVENT;
extern TraceEvent _TRACE_QCOW2_L2_ALLOCATE_WRITE_L2_EVENT;
extern TraceEvent _TRACE_QCOW2_L2_ALLOCATE_WRITE_L1_EVENT;
extern TraceEvent _TRACE_QCOW2_L2_ALLOCATE_DONE_EVENT;
extern TraceEvent _TRACE_QCOW2_CACHE_GET_EVENT;
extern TraceEvent _TRACE_QCOW2_CACHE_GET_REPLACE_ENTRY_EVENT;
extern TraceEvent _TRACE_QCOW2_CACHE_GET_READ_EVENT;
extern TraceEvent _TRACE_QCOW2_CACHE_GET_DONE_EVENT;
extern TraceEvent _TRACE_QCOW2_CACHE_FLUSH_EVENT;
extern TraceEvent _TRACE_QCOW2_CACHE_ENTRY_FLUSH_EVENT;
extern TraceEvent _TRACE_QCOW2_PROCESS_DISCARDS_FAILED_REGION_EVENT;
extern TraceEvent _TRACE_QED_ALLOC_L2_CACHE_ENTRY_EVENT;
extern TraceEvent _TRACE_QED_UNREF_L2_CACHE_ENTRY_EVENT;
extern TraceEvent _TRACE_QED_FIND_L2_CACHE_ENTRY_EVENT;
extern TraceEvent _TRACE_QED_READ_TABLE_EVENT;
extern TraceEvent _TRACE_QED_READ_TABLE_CB_EVENT;
extern TraceEvent _TRACE_QED_WRITE_TABLE_EVENT;
extern TraceEvent _TRACE_QED_WRITE_TABLE_CB_EVENT;
extern TraceEvent _TRACE_QED_NEED_CHECK_TIMER_CB_EVENT;
extern TraceEvent _TRACE_QED_START_NEED_CHECK_TIMER_EVENT;
extern TraceEvent _TRACE_QED_CANCEL_NEED_CHECK_TIMER_EVENT;
extern TraceEvent _TRACE_QED_AIO_COMPLETE_EVENT;
extern TraceEvent _TRACE_QED_AIO_SETUP_EVENT;
extern TraceEvent _TRACE_QED_AIO_NEXT_IO_EVENT;
extern TraceEvent _TRACE_QED_AIO_READ_DATA_EVENT;
extern TraceEvent _TRACE_QED_AIO_WRITE_DATA_EVENT;
extern TraceEvent _TRACE_QED_AIO_WRITE_PREFILL_EVENT;
extern TraceEvent _TRACE_QED_AIO_WRITE_POSTFILL_EVENT;
extern TraceEvent _TRACE_QED_AIO_WRITE_MAIN_EVENT;
extern TraceEvent _TRACE_NVME_CONTROLLER_CAPABILITY_RAW_EVENT;
extern TraceEvent _TRACE_NVME_CONTROLLER_CAPABILITY_EVENT;
extern TraceEvent _TRACE_NVME_KICK_EVENT;
extern TraceEvent _TRACE_NVME_DMA_FLUSH_QUEUE_WAIT_EVENT;
extern TraceEvent _TRACE_NVME_ERROR_EVENT;
extern TraceEvent _TRACE_NVME_PROCESS_COMPLETION_EVENT;
extern TraceEvent _TRACE_NVME_PROCESS_COMPLETION_QUEUE_PLUGGED_EVENT;
extern TraceEvent _TRACE_NVME_COMPLETE_COMMAND_EVENT;
extern TraceEvent _TRACE_NVME_SUBMIT_COMMAND_EVENT;
extern TraceEvent _TRACE_NVME_SUBMIT_COMMAND_RAW_EVENT;
extern TraceEvent _TRACE_NVME_HANDLE_EVENT_EVENT;
extern TraceEvent _TRACE_NVME_POLL_QUEUE_EVENT;
extern TraceEvent _TRACE_NVME_PRW_ALIGNED_EVENT;
extern TraceEvent _TRACE_NVME_WRITE_ZEROES_EVENT;
extern TraceEvent _TRACE_NVME_QIOV_UNALIGNED_EVENT;
extern TraceEvent _TRACE_NVME_PRW_BUFFERED_EVENT;
extern TraceEvent _TRACE_NVME_RW_DONE_EVENT;
extern TraceEvent _TRACE_NVME_DSM_EVENT;
extern TraceEvent _TRACE_NVME_DSM_DONE_EVENT;
extern TraceEvent _TRACE_NVME_DMA_MAP_FLUSH_EVENT;
extern TraceEvent _TRACE_NVME_FREE_REQ_QUEUE_WAIT_EVENT;
extern TraceEvent _TRACE_NVME_CREATE_QUEUE_PAIR_EVENT;
extern TraceEvent _TRACE_NVME_FREE_QUEUE_PAIR_EVENT;
extern TraceEvent _TRACE_NVME_CMD_MAP_QIOV_EVENT;
extern TraceEvent _TRACE_NVME_CMD_MAP_QIOV_PAGES_EVENT;
extern TraceEvent _TRACE_NVME_CMD_MAP_QIOV_IOV_EVENT;
extern TraceEvent _TRACE_ISCSI_XCOPY_EVENT;
extern TraceEvent _TRACE_NBD_PARSE_BLOCKSTATUS_COMPLIANCE_EVENT;
extern TraceEvent _TRACE_NBD_STRUCTURED_READ_COMPLIANCE_EVENT;
extern TraceEvent _TRACE_NBD_READ_REPLY_ENTRY_FAIL_EVENT;
extern TraceEvent _TRACE_NBD_CO_REQUEST_FAIL_EVENT;
extern TraceEvent _TRACE_NBD_CLIENT_HANDSHAKE_EVENT;
extern TraceEvent _TRACE_NBD_CLIENT_HANDSHAKE_SUCCESS_EVENT;
extern TraceEvent _TRACE_SSH_RESTART_COROUTINE_EVENT;
extern TraceEvent _TRACE_SSH_FLUSH_EVENT;
extern TraceEvent _TRACE_SSH_CHECK_HOST_KEY_KNOWNHOSTS_EVENT;
extern TraceEvent _TRACE_SSH_CONNECT_TO_SSH_EVENT;
extern TraceEvent _TRACE_SSH_CO_YIELD_EVENT;
extern TraceEvent _TRACE_SSH_CO_YIELD_BACK_EVENT;
extern TraceEvent _TRACE_SSH_GETLENGTH_EVENT;
extern TraceEvent _TRACE_SSH_CO_CREATE_OPTS_EVENT;
extern TraceEvent _TRACE_SSH_READ_EVENT;
extern TraceEvent _TRACE_SSH_READ_BUF_EVENT;
extern TraceEvent _TRACE_SSH_READ_RETURN_EVENT;
extern TraceEvent _TRACE_SSH_WRITE_EVENT;
extern TraceEvent _TRACE_SSH_WRITE_BUF_EVENT;
extern TraceEvent _TRACE_SSH_WRITE_RETURN_EVENT;
extern TraceEvent _TRACE_SSH_SEEK_EVENT;
extern TraceEvent _TRACE_SSH_AUTH_METHODS_EVENT;
extern TraceEvent _TRACE_SSH_SERVER_STATUS_EVENT;
extern TraceEvent _TRACE_CURL_TIMER_CB_EVENT;
extern TraceEvent _TRACE_CURL_SOCK_CB_EVENT;
extern TraceEvent _TRACE_CURL_READ_CB_EVENT;
extern TraceEvent _TRACE_CURL_OPEN_EVENT;
extern TraceEvent _TRACE_CURL_OPEN_SIZE_EVENT;
extern TraceEvent _TRACE_CURL_SETUP_PREADV_EVENT;
extern TraceEvent _TRACE_CURL_CLOSE_EVENT;
extern TraceEvent _TRACE_FILE_COPY_FILE_RANGE_EVENT;
extern TraceEvent _TRACE_FILE_FINDEJECTABLEOPTICALMEDIA_EVENT;
extern TraceEvent _TRACE_FILE_SETUP_CDROM_EVENT;
extern TraceEvent _TRACE_FILE_HDEV_IS_SG_EVENT;
extern TraceEvent _TRACE_SHEEPDOG_RECONNECT_TO_SDOG_EVENT;
extern TraceEvent _TRACE_SHEEPDOG_AIO_READ_RESPONSE_EVENT;
extern TraceEvent _TRACE_SHEEPDOG_OPEN_EVENT;
extern TraceEvent _TRACE_SHEEPDOG_CLOSE_EVENT;
extern TraceEvent _TRACE_SHEEPDOG_CREATE_BRANCH_SNAPSHOT_EVENT;
extern TraceEvent _TRACE_SHEEPDOG_CREATE_BRANCH_CREATED_EVENT;
extern TraceEvent _TRACE_SHEEPDOG_CREATE_BRANCH_NEW_EVENT;
extern TraceEvent _TRACE_SHEEPDOG_CO_RW_VECTOR_UPDATE_EVENT;
extern TraceEvent _TRACE_SHEEPDOG_CO_RW_VECTOR_NEW_EVENT;
extern TraceEvent _TRACE_SHEEPDOG_SNAPSHOT_CREATE_INFO_EVENT;
extern TraceEvent _TRACE_SHEEPDOG_SNAPSHOT_CREATE_EVENT;
extern TraceEvent _TRACE_SHEEPDOG_SNAPSHOT_CREATE_INODE_EVENT;
extern TraceEvent _TRACE_SFTP_ERROR_EVENT;
extern uint16_t _TRACE_BDRV_OPEN_COMMON_DSTATE;
extern uint16_t _TRACE_BDRV_LOCK_MEDIUM_DSTATE;
extern uint16_t _TRACE_BLK_CO_PREADV_DSTATE;
extern uint16_t _TRACE_BLK_CO_PWRITEV_DSTATE;
extern uint16_t _TRACE_BLK_ROOT_ATTACH_DSTATE;
extern uint16_t _TRACE_BLK_ROOT_DETACH_DSTATE;
extern uint16_t _TRACE_BDRV_CO_PREADV_DSTATE;
extern uint16_t _TRACE_BDRV_CO_PWRITEV_DSTATE;
extern uint16_t _TRACE_BDRV_CO_PWRITE_ZEROES_DSTATE;
extern uint16_t _TRACE_BDRV_CO_DO_COPY_ON_READV_DSTATE;
extern uint16_t _TRACE_BDRV_CO_COPY_RANGE_FROM_DSTATE;
extern uint16_t _TRACE_BDRV_CO_COPY_RANGE_TO_DSTATE;
extern uint16_t _TRACE_STREAM_ONE_ITERATION_DSTATE;
extern uint16_t _TRACE_STREAM_START_DSTATE;
extern uint16_t _TRACE_COMMIT_ONE_ITERATION_DSTATE;
extern uint16_t _TRACE_COMMIT_START_DSTATE;
extern uint16_t _TRACE_MIRROR_START_DSTATE;
extern uint16_t _TRACE_MIRROR_RESTART_ITER_DSTATE;
extern uint16_t _TRACE_MIRROR_BEFORE_FLUSH_DSTATE;
extern uint16_t _TRACE_MIRROR_BEFORE_DRAIN_DSTATE;
extern uint16_t _TRACE_MIRROR_BEFORE_SLEEP_DSTATE;
extern uint16_t _TRACE_MIRROR_ONE_ITERATION_DSTATE;
extern uint16_t _TRACE_MIRROR_ITERATION_DONE_DSTATE;
extern uint16_t _TRACE_MIRROR_YIELD_DSTATE;
extern uint16_t _TRACE_MIRROR_YIELD_IN_FLIGHT_DSTATE;
extern uint16_t _TRACE_BACKUP_DO_COW_ENTER_DSTATE;
extern uint16_t _TRACE_BACKUP_DO_COW_RETURN_DSTATE;
extern uint16_t _TRACE_BLOCK_COPY_SKIP_RANGE_DSTATE;
extern uint16_t _TRACE_BLOCK_COPY_PROCESS_DSTATE;
extern uint16_t _TRACE_BLOCK_COPY_COPY_RANGE_FAIL_DSTATE;
extern uint16_t _TRACE_BLOCK_COPY_READ_FAIL_DSTATE;
extern uint16_t _TRACE_BLOCK_COPY_WRITE_FAIL_DSTATE;
extern uint16_t _TRACE_BLOCK_COPY_WRITE_ZEROES_FAIL_DSTATE;
extern uint16_t _TRACE_QMP_BLOCK_JOB_CANCEL_DSTATE;
extern uint16_t _TRACE_QMP_BLOCK_JOB_PAUSE_DSTATE;
extern uint16_t _TRACE_QMP_BLOCK_JOB_RESUME_DSTATE;
extern uint16_t _TRACE_QMP_BLOCK_JOB_COMPLETE_DSTATE;
extern uint16_t _TRACE_QMP_BLOCK_JOB_FINALIZE_DSTATE;
extern uint16_t _TRACE_QMP_BLOCK_JOB_DISMISS_DSTATE;
extern uint16_t _TRACE_QMP_BLOCK_STREAM_DSTATE;
extern uint16_t _TRACE_FILE_PAIO_SUBMIT_DSTATE;
extern uint16_t _TRACE_LURING_INIT_STATE_DSTATE;
extern uint16_t _TRACE_LURING_CLEANUP_STATE_DSTATE;
extern uint16_t _TRACE_LURING_IO_PLUG_DSTATE;
extern uint16_t _TRACE_LURING_IO_UNPLUG_DSTATE;
extern uint16_t _TRACE_LURING_DO_SUBMIT_DSTATE;
extern uint16_t _TRACE_LURING_DO_SUBMIT_DONE_DSTATE;
extern uint16_t _TRACE_LURING_CO_SUBMIT_DSTATE;
extern uint16_t _TRACE_LURING_PROCESS_COMPLETION_DSTATE;
extern uint16_t _TRACE_LURING_IO_URING_SUBMIT_DSTATE;
extern uint16_t _TRACE_LURING_RESUBMIT_SHORT_READ_DSTATE;
extern uint16_t _TRACE_QCOW2_ADD_TASK_DSTATE;
extern uint16_t _TRACE_QCOW2_WRITEV_START_REQ_DSTATE;
extern uint16_t _TRACE_QCOW2_WRITEV_DONE_REQ_DSTATE;
extern uint16_t _TRACE_QCOW2_WRITEV_START_PART_DSTATE;
extern uint16_t _TRACE_QCOW2_WRITEV_DONE_PART_DSTATE;
extern uint16_t _TRACE_QCOW2_WRITEV_DATA_DSTATE;
extern uint16_t _TRACE_QCOW2_PWRITE_ZEROES_START_REQ_DSTATE;
extern uint16_t _TRACE_QCOW2_PWRITE_ZEROES_DSTATE;
extern uint16_t _TRACE_QCOW2_SKIP_COW_DSTATE;
extern uint16_t _TRACE_QCOW2_ALLOC_CLUSTERS_OFFSET_DSTATE;
extern uint16_t _TRACE_QCOW2_HANDLE_COPIED_DSTATE;
extern uint16_t _TRACE_QCOW2_HANDLE_ALLOC_DSTATE;
extern uint16_t _TRACE_QCOW2_DO_ALLOC_CLUSTERS_OFFSET_DSTATE;
extern uint16_t _TRACE_QCOW2_CLUSTER_ALLOC_PHYS_DSTATE;
extern uint16_t _TRACE_QCOW2_CLUSTER_LINK_L2_DSTATE;
extern uint16_t _TRACE_QCOW2_L2_ALLOCATE_DSTATE;
extern uint16_t _TRACE_QCOW2_L2_ALLOCATE_GET_EMPTY_DSTATE;
extern uint16_t _TRACE_QCOW2_L2_ALLOCATE_WRITE_L2_DSTATE;
extern uint16_t _TRACE_QCOW2_L2_ALLOCATE_WRITE_L1_DSTATE;
extern uint16_t _TRACE_QCOW2_L2_ALLOCATE_DONE_DSTATE;
extern uint16_t _TRACE_QCOW2_CACHE_GET_DSTATE;
extern uint16_t _TRACE_QCOW2_CACHE_GET_REPLACE_ENTRY_DSTATE;
extern uint16_t _TRACE_QCOW2_CACHE_GET_READ_DSTATE;
extern uint16_t _TRACE_QCOW2_CACHE_GET_DONE_DSTATE;
extern uint16_t _TRACE_QCOW2_CACHE_FLUSH_DSTATE;
extern uint16_t _TRACE_QCOW2_CACHE_ENTRY_FLUSH_DSTATE;
extern uint16_t _TRACE_QCOW2_PROCESS_DISCARDS_FAILED_REGION_DSTATE;
extern uint16_t _TRACE_QED_ALLOC_L2_CACHE_ENTRY_DSTATE;
extern uint16_t _TRACE_QED_UNREF_L2_CACHE_ENTRY_DSTATE;
extern uint16_t _TRACE_QED_FIND_L2_CACHE_ENTRY_DSTATE;
extern uint16_t _TRACE_QED_READ_TABLE_DSTATE;
extern uint16_t _TRACE_QED_READ_TABLE_CB_DSTATE;
extern uint16_t _TRACE_QED_WRITE_TABLE_DSTATE;
extern uint16_t _TRACE_QED_WRITE_TABLE_CB_DSTATE;
extern uint16_t _TRACE_QED_NEED_CHECK_TIMER_CB_DSTATE;
extern uint16_t _TRACE_QED_START_NEED_CHECK_TIMER_DSTATE;
extern uint16_t _TRACE_QED_CANCEL_NEED_CHECK_TIMER_DSTATE;
extern uint16_t _TRACE_QED_AIO_COMPLETE_DSTATE;
extern uint16_t _TRACE_QED_AIO_SETUP_DSTATE;
extern uint16_t _TRACE_QED_AIO_NEXT_IO_DSTATE;
extern uint16_t _TRACE_QED_AIO_READ_DATA_DSTATE;
extern uint16_t _TRACE_QED_AIO_WRITE_DATA_DSTATE;
extern uint16_t _TRACE_QED_AIO_WRITE_PREFILL_DSTATE;
extern uint16_t _TRACE_QED_AIO_WRITE_POSTFILL_DSTATE;
extern uint16_t _TRACE_QED_AIO_WRITE_MAIN_DSTATE;
extern uint16_t _TRACE_NVME_CONTROLLER_CAPABILITY_RAW_DSTATE;
extern uint16_t _TRACE_NVME_CONTROLLER_CAPABILITY_DSTATE;
extern uint16_t _TRACE_NVME_KICK_DSTATE;
extern uint16_t _TRACE_NVME_DMA_FLUSH_QUEUE_WAIT_DSTATE;
extern uint16_t _TRACE_NVME_ERROR_DSTATE;
extern uint16_t _TRACE_NVME_PROCESS_COMPLETION_DSTATE;
extern uint16_t _TRACE_NVME_PROCESS_COMPLETION_QUEUE_PLUGGED_DSTATE;
extern uint16_t _TRACE_NVME_COMPLETE_COMMAND_DSTATE;
extern uint16_t _TRACE_NVME_SUBMIT_COMMAND_DSTATE;
extern uint16_t _TRACE_NVME_SUBMIT_COMMAND_RAW_DSTATE;
extern uint16_t _TRACE_NVME_HANDLE_EVENT_DSTATE;
extern uint16_t _TRACE_NVME_POLL_QUEUE_DSTATE;
extern uint16_t _TRACE_NVME_PRW_ALIGNED_DSTATE;
extern uint16_t _TRACE_NVME_WRITE_ZEROES_DSTATE;
extern uint16_t _TRACE_NVME_QIOV_UNALIGNED_DSTATE;
extern uint16_t _TRACE_NVME_PRW_BUFFERED_DSTATE;
extern uint16_t _TRACE_NVME_RW_DONE_DSTATE;
extern uint16_t _TRACE_NVME_DSM_DSTATE;
extern uint16_t _TRACE_NVME_DSM_DONE_DSTATE;
extern uint16_t _TRACE_NVME_DMA_MAP_FLUSH_DSTATE;
extern uint16_t _TRACE_NVME_FREE_REQ_QUEUE_WAIT_DSTATE;
extern uint16_t _TRACE_NVME_CREATE_QUEUE_PAIR_DSTATE;
extern uint16_t _TRACE_NVME_FREE_QUEUE_PAIR_DSTATE;
extern uint16_t _TRACE_NVME_CMD_MAP_QIOV_DSTATE;
extern uint16_t _TRACE_NVME_CMD_MAP_QIOV_PAGES_DSTATE;
extern uint16_t _TRACE_NVME_CMD_MAP_QIOV_IOV_DSTATE;
extern uint16_t _TRACE_ISCSI_XCOPY_DSTATE;
extern uint16_t _TRACE_NBD_PARSE_BLOCKSTATUS_COMPLIANCE_DSTATE;
extern uint16_t _TRACE_NBD_STRUCTURED_READ_COMPLIANCE_DSTATE;
extern uint16_t _TRACE_NBD_READ_REPLY_ENTRY_FAIL_DSTATE;
extern uint16_t _TRACE_NBD_CO_REQUEST_FAIL_DSTATE;
extern uint16_t _TRACE_NBD_CLIENT_HANDSHAKE_DSTATE;
extern uint16_t _TRACE_NBD_CLIENT_HANDSHAKE_SUCCESS_DSTATE;
extern uint16_t _TRACE_SSH_RESTART_COROUTINE_DSTATE;
extern uint16_t _TRACE_SSH_FLUSH_DSTATE;
extern uint16_t _TRACE_SSH_CHECK_HOST_KEY_KNOWNHOSTS_DSTATE;
extern uint16_t _TRACE_SSH_CONNECT_TO_SSH_DSTATE;
extern uint16_t _TRACE_SSH_CO_YIELD_DSTATE;
extern uint16_t _TRACE_SSH_CO_YIELD_BACK_DSTATE;
extern uint16_t _TRACE_SSH_GETLENGTH_DSTATE;
extern uint16_t _TRACE_SSH_CO_CREATE_OPTS_DSTATE;
extern uint16_t _TRACE_SSH_READ_DSTATE;
extern uint16_t _TRACE_SSH_READ_BUF_DSTATE;
extern uint16_t _TRACE_SSH_READ_RETURN_DSTATE;
extern uint16_t _TRACE_SSH_WRITE_DSTATE;
extern uint16_t _TRACE_SSH_WRITE_BUF_DSTATE;
extern uint16_t _TRACE_SSH_WRITE_RETURN_DSTATE;
extern uint16_t _TRACE_SSH_SEEK_DSTATE;
extern uint16_t _TRACE_SSH_AUTH_METHODS_DSTATE;
extern uint16_t _TRACE_SSH_SERVER_STATUS_DSTATE;
extern uint16_t _TRACE_CURL_TIMER_CB_DSTATE;
extern uint16_t _TRACE_CURL_SOCK_CB_DSTATE;
extern uint16_t _TRACE_CURL_READ_CB_DSTATE;
extern uint16_t _TRACE_CURL_OPEN_DSTATE;
extern uint16_t _TRACE_CURL_OPEN_SIZE_DSTATE;
extern uint16_t _TRACE_CURL_SETUP_PREADV_DSTATE;
extern uint16_t _TRACE_CURL_CLOSE_DSTATE;
extern uint16_t _TRACE_FILE_COPY_FILE_RANGE_DSTATE;
extern uint16_t _TRACE_FILE_FINDEJECTABLEOPTICALMEDIA_DSTATE;
extern uint16_t _TRACE_FILE_SETUP_CDROM_DSTATE;
extern uint16_t _TRACE_FILE_HDEV_IS_SG_DSTATE;
extern uint16_t _TRACE_SHEEPDOG_RECONNECT_TO_SDOG_DSTATE;
extern uint16_t _TRACE_SHEEPDOG_AIO_READ_RESPONSE_DSTATE;
extern uint16_t _TRACE_SHEEPDOG_OPEN_DSTATE;
extern uint16_t _TRACE_SHEEPDOG_CLOSE_DSTATE;
extern uint16_t _TRACE_SHEEPDOG_CREATE_BRANCH_SNAPSHOT_DSTATE;
extern uint16_t _TRACE_SHEEPDOG_CREATE_BRANCH_CREATED_DSTATE;
extern uint16_t _TRACE_SHEEPDOG_CREATE_BRANCH_NEW_DSTATE;
extern uint16_t _TRACE_SHEEPDOG_CO_RW_VECTOR_UPDATE_DSTATE;
extern uint16_t _TRACE_SHEEPDOG_CO_RW_VECTOR_NEW_DSTATE;
extern uint16_t _TRACE_SHEEPDOG_SNAPSHOT_CREATE_INFO_DSTATE;
extern uint16_t _TRACE_SHEEPDOG_SNAPSHOT_CREATE_DSTATE;
extern uint16_t _TRACE_SHEEPDOG_SNAPSHOT_CREATE_INODE_DSTATE;
extern uint16_t _TRACE_SFTP_ERROR_DSTATE;
#define TRACE_BDRV_OPEN_COMMON_ENABLED 1
#define TRACE_BDRV_LOCK_MEDIUM_ENABLED 1
#define TRACE_BLK_CO_PREADV_ENABLED 1
#define TRACE_BLK_CO_PWRITEV_ENABLED 1
#define TRACE_BLK_ROOT_ATTACH_ENABLED 1
#define TRACE_BLK_ROOT_DETACH_ENABLED 1
#define TRACE_BDRV_CO_PREADV_ENABLED 1
#define TRACE_BDRV_CO_PWRITEV_ENABLED 1
#define TRACE_BDRV_CO_PWRITE_ZEROES_ENABLED 1
#define TRACE_BDRV_CO_DO_COPY_ON_READV_ENABLED 1
#define TRACE_BDRV_CO_COPY_RANGE_FROM_ENABLED 1
#define TRACE_BDRV_CO_COPY_RANGE_TO_ENABLED 1
#define TRACE_STREAM_ONE_ITERATION_ENABLED 1
#define TRACE_STREAM_START_ENABLED 1
#define TRACE_COMMIT_ONE_ITERATION_ENABLED 1
#define TRACE_COMMIT_START_ENABLED 1
#define TRACE_MIRROR_START_ENABLED 1
#define TRACE_MIRROR_RESTART_ITER_ENABLED 1
#define TRACE_MIRROR_BEFORE_FLUSH_ENABLED 1
#define TRACE_MIRROR_BEFORE_DRAIN_ENABLED 1
#define TRACE_MIRROR_BEFORE_SLEEP_ENABLED 1
#define TRACE_MIRROR_ONE_ITERATION_ENABLED 1
#define TRACE_MIRROR_ITERATION_DONE_ENABLED 1
#define TRACE_MIRROR_YIELD_ENABLED 1
#define TRACE_MIRROR_YIELD_IN_FLIGHT_ENABLED 1
#define TRACE_BACKUP_DO_COW_ENTER_ENABLED 1
#define TRACE_BACKUP_DO_COW_RETURN_ENABLED 1
#define TRACE_BLOCK_COPY_SKIP_RANGE_ENABLED 1
#define TRACE_BLOCK_COPY_PROCESS_ENABLED 1
#define TRACE_BLOCK_COPY_COPY_RANGE_FAIL_ENABLED 1
#define TRACE_BLOCK_COPY_READ_FAIL_ENABLED 1
#define TRACE_BLOCK_COPY_WRITE_FAIL_ENABLED 1
#define TRACE_BLOCK_COPY_WRITE_ZEROES_FAIL_ENABLED 1
#define TRACE_QMP_BLOCK_JOB_CANCEL_ENABLED 1
#define TRACE_QMP_BLOCK_JOB_PAUSE_ENABLED 1
#define TRACE_QMP_BLOCK_JOB_RESUME_ENABLED 1
#define TRACE_QMP_BLOCK_JOB_COMPLETE_ENABLED 1
#define TRACE_QMP_BLOCK_JOB_FINALIZE_ENABLED 1
#define TRACE_QMP_BLOCK_JOB_DISMISS_ENABLED 1
#define TRACE_QMP_BLOCK_STREAM_ENABLED 1
#define TRACE_FILE_PAIO_SUBMIT_ENABLED 1
#define TRACE_LURING_INIT_STATE_ENABLED 1
#define TRACE_LURING_CLEANUP_STATE_ENABLED 1
#define TRACE_LURING_IO_PLUG_ENABLED 1
#define TRACE_LURING_IO_UNPLUG_ENABLED 1
#define TRACE_LURING_DO_SUBMIT_ENABLED 1
#define TRACE_LURING_DO_SUBMIT_DONE_ENABLED 1
#define TRACE_LURING_CO_SUBMIT_ENABLED 1
#define TRACE_LURING_PROCESS_COMPLETION_ENABLED 1
#define TRACE_LURING_IO_URING_SUBMIT_ENABLED 1
#define TRACE_LURING_RESUBMIT_SHORT_READ_ENABLED 1
#define TRACE_QCOW2_ADD_TASK_ENABLED 1
#define TRACE_QCOW2_WRITEV_START_REQ_ENABLED 1
#define TRACE_QCOW2_WRITEV_DONE_REQ_ENABLED 1
#define TRACE_QCOW2_WRITEV_START_PART_ENABLED 1
#define TRACE_QCOW2_WRITEV_DONE_PART_ENABLED 1
#define TRACE_QCOW2_WRITEV_DATA_ENABLED 1
#define TRACE_QCOW2_PWRITE_ZEROES_START_REQ_ENABLED 1
#define TRACE_QCOW2_PWRITE_ZEROES_ENABLED 1
#define TRACE_QCOW2_SKIP_COW_ENABLED 1
#define TRACE_QCOW2_ALLOC_CLUSTERS_OFFSET_ENABLED 1
#define TRACE_QCOW2_HANDLE_COPIED_ENABLED 1
#define TRACE_QCOW2_HANDLE_ALLOC_ENABLED 1
#define TRACE_QCOW2_DO_ALLOC_CLUSTERS_OFFSET_ENABLED 1
#define TRACE_QCOW2_CLUSTER_ALLOC_PHYS_ENABLED 1
#define TRACE_QCOW2_CLUSTER_LINK_L2_ENABLED 1
#define TRACE_QCOW2_L2_ALLOCATE_ENABLED 1
#define TRACE_QCOW2_L2_ALLOCATE_GET_EMPTY_ENABLED 1
#define TRACE_QCOW2_L2_ALLOCATE_WRITE_L2_ENABLED 1
#define TRACE_QCOW2_L2_ALLOCATE_WRITE_L1_ENABLED 1
#define TRACE_QCOW2_L2_ALLOCATE_DONE_ENABLED 1
#define TRACE_QCOW2_CACHE_GET_ENABLED 1
#define TRACE_QCOW2_CACHE_GET_REPLACE_ENTRY_ENABLED 1
#define TRACE_QCOW2_CACHE_GET_READ_ENABLED 1
#define TRACE_QCOW2_CACHE_GET_DONE_ENABLED 1
#define TRACE_QCOW2_CACHE_FLUSH_ENABLED 1
#define TRACE_QCOW2_CACHE_ENTRY_FLUSH_ENABLED 1
#define TRACE_QCOW2_PROCESS_DISCARDS_FAILED_REGION_ENABLED 1
#define TRACE_QED_ALLOC_L2_CACHE_ENTRY_ENABLED 1
#define TRACE_QED_UNREF_L2_CACHE_ENTRY_ENABLED 1
#define TRACE_QED_FIND_L2_CACHE_ENTRY_ENABLED 1
#define TRACE_QED_READ_TABLE_ENABLED 1
#define TRACE_QED_READ_TABLE_CB_ENABLED 1
#define TRACE_QED_WRITE_TABLE_ENABLED 1
#define TRACE_QED_WRITE_TABLE_CB_ENABLED 1
#define TRACE_QED_NEED_CHECK_TIMER_CB_ENABLED 1
#define TRACE_QED_START_NEED_CHECK_TIMER_ENABLED 1
#define TRACE_QED_CANCEL_NEED_CHECK_TIMER_ENABLED 1
#define TRACE_QED_AIO_COMPLETE_ENABLED 1
#define TRACE_QED_AIO_SETUP_ENABLED 1
#define TRACE_QED_AIO_NEXT_IO_ENABLED 1
#define TRACE_QED_AIO_READ_DATA_ENABLED 1
#define TRACE_QED_AIO_WRITE_DATA_ENABLED 1
#define TRACE_QED_AIO_WRITE_PREFILL_ENABLED 1
#define TRACE_QED_AIO_WRITE_POSTFILL_ENABLED 1
#define TRACE_QED_AIO_WRITE_MAIN_ENABLED 1
#define TRACE_NVME_CONTROLLER_CAPABILITY_RAW_ENABLED 1
#define TRACE_NVME_CONTROLLER_CAPABILITY_ENABLED 1
#define TRACE_NVME_KICK_ENABLED 1
#define TRACE_NVME_DMA_FLUSH_QUEUE_WAIT_ENABLED 1
#define TRACE_NVME_ERROR_ENABLED 1
#define TRACE_NVME_PROCESS_COMPLETION_ENABLED 1
#define TRACE_NVME_PROCESS_COMPLETION_QUEUE_PLUGGED_ENABLED 1
#define TRACE_NVME_COMPLETE_COMMAND_ENABLED 1
#define TRACE_NVME_SUBMIT_COMMAND_ENABLED 1
#define TRACE_NVME_SUBMIT_COMMAND_RAW_ENABLED 1
#define TRACE_NVME_HANDLE_EVENT_ENABLED 1
#define TRACE_NVME_POLL_QUEUE_ENABLED 1
#define TRACE_NVME_PRW_ALIGNED_ENABLED 1
#define TRACE_NVME_WRITE_ZEROES_ENABLED 1
#define TRACE_NVME_QIOV_UNALIGNED_ENABLED 1
#define TRACE_NVME_PRW_BUFFERED_ENABLED 1
#define TRACE_NVME_RW_DONE_ENABLED 1
#define TRACE_NVME_DSM_ENABLED 1
#define TRACE_NVME_DSM_DONE_ENABLED 1
#define TRACE_NVME_DMA_MAP_FLUSH_ENABLED 1
#define TRACE_NVME_FREE_REQ_QUEUE_WAIT_ENABLED 1
#define TRACE_NVME_CREATE_QUEUE_PAIR_ENABLED 1
#define TRACE_NVME_FREE_QUEUE_PAIR_ENABLED 1
#define TRACE_NVME_CMD_MAP_QIOV_ENABLED 1
#define TRACE_NVME_CMD_MAP_QIOV_PAGES_ENABLED 1
#define TRACE_NVME_CMD_MAP_QIOV_IOV_ENABLED 1
#define TRACE_ISCSI_XCOPY_ENABLED 1
#define TRACE_NBD_PARSE_BLOCKSTATUS_COMPLIANCE_ENABLED 1
#define TRACE_NBD_STRUCTURED_READ_COMPLIANCE_ENABLED 1
#define TRACE_NBD_READ_REPLY_ENTRY_FAIL_ENABLED 1
#define TRACE_NBD_CO_REQUEST_FAIL_ENABLED 1
#define TRACE_NBD_CLIENT_HANDSHAKE_ENABLED 1
#define TRACE_NBD_CLIENT_HANDSHAKE_SUCCESS_ENABLED 1
#define TRACE_SSH_RESTART_COROUTINE_ENABLED 1
#define TRACE_SSH_FLUSH_ENABLED 1
#define TRACE_SSH_CHECK_HOST_KEY_KNOWNHOSTS_ENABLED 1
#define TRACE_SSH_CONNECT_TO_SSH_ENABLED 1
#define TRACE_SSH_CO_YIELD_ENABLED 1
#define TRACE_SSH_CO_YIELD_BACK_ENABLED 1
#define TRACE_SSH_GETLENGTH_ENABLED 1
#define TRACE_SSH_CO_CREATE_OPTS_ENABLED 1
#define TRACE_SSH_READ_ENABLED 1
#define TRACE_SSH_READ_BUF_ENABLED 1
#define TRACE_SSH_READ_RETURN_ENABLED 1
#define TRACE_SSH_WRITE_ENABLED 1
#define TRACE_SSH_WRITE_BUF_ENABLED 1
#define TRACE_SSH_WRITE_RETURN_ENABLED 1
#define TRACE_SSH_SEEK_ENABLED 1
#define TRACE_SSH_AUTH_METHODS_ENABLED 1
#define TRACE_SSH_SERVER_STATUS_ENABLED 1
#define TRACE_CURL_TIMER_CB_ENABLED 1
#define TRACE_CURL_SOCK_CB_ENABLED 1
#define TRACE_CURL_READ_CB_ENABLED 1
#define TRACE_CURL_OPEN_ENABLED 1
#define TRACE_CURL_OPEN_SIZE_ENABLED 1
#define TRACE_CURL_SETUP_PREADV_ENABLED 1
#define TRACE_CURL_CLOSE_ENABLED 1
#define TRACE_FILE_COPY_FILE_RANGE_ENABLED 1
#define TRACE_FILE_FINDEJECTABLEOPTICALMEDIA_ENABLED 1
#define TRACE_FILE_SETUP_CDROM_ENABLED 1
#define TRACE_FILE_HDEV_IS_SG_ENABLED 1
#define TRACE_SHEEPDOG_RECONNECT_TO_SDOG_ENABLED 1
#define TRACE_SHEEPDOG_AIO_READ_RESPONSE_ENABLED 1
#define TRACE_SHEEPDOG_OPEN_ENABLED 1
#define TRACE_SHEEPDOG_CLOSE_ENABLED 1
#define TRACE_SHEEPDOG_CREATE_BRANCH_SNAPSHOT_ENABLED 1
#define TRACE_SHEEPDOG_CREATE_BRANCH_CREATED_ENABLED 1
#define TRACE_SHEEPDOG_CREATE_BRANCH_NEW_ENABLED 1
#define TRACE_SHEEPDOG_CO_RW_VECTOR_UPDATE_ENABLED 1
#define TRACE_SHEEPDOG_CO_RW_VECTOR_NEW_ENABLED 1
#define TRACE_SHEEPDOG_SNAPSHOT_CREATE_INFO_ENABLED 1
#define TRACE_SHEEPDOG_SNAPSHOT_CREATE_ENABLED 1
#define TRACE_SHEEPDOG_SNAPSHOT_CREATE_INODE_ENABLED 1
#define TRACE_SFTP_ERROR_ENABLED 1
#include "qemu/log-for-trace.h"


#define TRACE_BDRV_OPEN_COMMON_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_BDRV_OPEN_COMMON) || \
    false)

static inline void _nocheck__trace_bdrv_open_common(void * bs, const char * filename, int flags, const char * format_name)
{
    if (trace_event_get_state(TRACE_BDRV_OPEN_COMMON) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:bdrv_open_common " "bs %p filename \"%s\" flags 0x%x format_name \"%s\"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , bs, filename, flags, format_name);
    }
}

static inline void trace_bdrv_open_common(void * bs, const char * filename, int flags, const char * format_name)
{
    if (true) {
        _nocheck__trace_bdrv_open_common(bs, filename, flags, format_name);
    }
}

#define TRACE_BDRV_LOCK_MEDIUM_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_BDRV_LOCK_MEDIUM) || \
    false)

static inline void _nocheck__trace_bdrv_lock_medium(void * bs, bool locked)
{
    if (trace_event_get_state(TRACE_BDRV_LOCK_MEDIUM) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:bdrv_lock_medium " "bs %p locked %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , bs, locked);
    }
}

static inline void trace_bdrv_lock_medium(void * bs, bool locked)
{
    if (true) {
        _nocheck__trace_bdrv_lock_medium(bs, locked);
    }
}

#define TRACE_BLK_CO_PREADV_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_BLK_CO_PREADV) || \
    false)

static inline void _nocheck__trace_blk_co_preadv(void * blk, void * bs, int64_t offset, unsigned int bytes, int flags)
{
    if (trace_event_get_state(TRACE_BLK_CO_PREADV) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:blk_co_preadv " "blk %p bs %p offset %"PRId64" bytes %u flags 0x%x" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , blk, bs, offset, bytes, flags);
    }
}

static inline void trace_blk_co_preadv(void * blk, void * bs, int64_t offset, unsigned int bytes, int flags)
{
    if (true) {
        _nocheck__trace_blk_co_preadv(blk, bs, offset, bytes, flags);
    }
}

#define TRACE_BLK_CO_PWRITEV_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_BLK_CO_PWRITEV) || \
    false)

static inline void _nocheck__trace_blk_co_pwritev(void * blk, void * bs, int64_t offset, unsigned int bytes, int flags)
{
    if (trace_event_get_state(TRACE_BLK_CO_PWRITEV) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:blk_co_pwritev " "blk %p bs %p offset %"PRId64" bytes %u flags 0x%x" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , blk, bs, offset, bytes, flags);
    }
}

static inline void trace_blk_co_pwritev(void * blk, void * bs, int64_t offset, unsigned int bytes, int flags)
{
    if (true) {
        _nocheck__trace_blk_co_pwritev(blk, bs, offset, bytes, flags);
    }
}

#define TRACE_BLK_ROOT_ATTACH_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_BLK_ROOT_ATTACH) || \
    false)

static inline void _nocheck__trace_blk_root_attach(void * child, void * blk, void * bs)
{
    if (trace_event_get_state(TRACE_BLK_ROOT_ATTACH) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:blk_root_attach " "child %p blk %p bs %p" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , child, blk, bs);
    }
}

static inline void trace_blk_root_attach(void * child, void * blk, void * bs)
{
    if (true) {
        _nocheck__trace_blk_root_attach(child, blk, bs);
    }
}

#define TRACE_BLK_ROOT_DETACH_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_BLK_ROOT_DETACH) || \
    false)

static inline void _nocheck__trace_blk_root_detach(void * child, void * blk, void * bs)
{
    if (trace_event_get_state(TRACE_BLK_ROOT_DETACH) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:blk_root_detach " "child %p blk %p bs %p" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , child, blk, bs);
    }
}

static inline void trace_blk_root_detach(void * child, void * blk, void * bs)
{
    if (true) {
        _nocheck__trace_blk_root_detach(child, blk, bs);
    }
}

#define TRACE_BDRV_CO_PREADV_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_BDRV_CO_PREADV) || \
    false)

static inline void _nocheck__trace_bdrv_co_preadv(void * bs, int64_t offset, int64_t nbytes, unsigned int flags)
{
    if (trace_event_get_state(TRACE_BDRV_CO_PREADV) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:bdrv_co_preadv " "bs %p offset %"PRId64" nbytes %"PRId64" flags 0x%x" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , bs, offset, nbytes, flags);
    }
}

static inline void trace_bdrv_co_preadv(void * bs, int64_t offset, int64_t nbytes, unsigned int flags)
{
    if (true) {
        _nocheck__trace_bdrv_co_preadv(bs, offset, nbytes, flags);
    }
}

#define TRACE_BDRV_CO_PWRITEV_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_BDRV_CO_PWRITEV) || \
    false)

static inline void _nocheck__trace_bdrv_co_pwritev(void * bs, int64_t offset, int64_t nbytes, unsigned int flags)
{
    if (trace_event_get_state(TRACE_BDRV_CO_PWRITEV) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:bdrv_co_pwritev " "bs %p offset %"PRId64" nbytes %"PRId64" flags 0x%x" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , bs, offset, nbytes, flags);
    }
}

static inline void trace_bdrv_co_pwritev(void * bs, int64_t offset, int64_t nbytes, unsigned int flags)
{
    if (true) {
        _nocheck__trace_bdrv_co_pwritev(bs, offset, nbytes, flags);
    }
}

#define TRACE_BDRV_CO_PWRITE_ZEROES_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_BDRV_CO_PWRITE_ZEROES) || \
    false)

static inline void _nocheck__trace_bdrv_co_pwrite_zeroes(void * bs, int64_t offset, int count, int flags)
{
    if (trace_event_get_state(TRACE_BDRV_CO_PWRITE_ZEROES) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:bdrv_co_pwrite_zeroes " "bs %p offset %"PRId64" count %d flags 0x%x" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , bs, offset, count, flags);
    }
}

static inline void trace_bdrv_co_pwrite_zeroes(void * bs, int64_t offset, int count, int flags)
{
    if (true) {
        _nocheck__trace_bdrv_co_pwrite_zeroes(bs, offset, count, flags);
    }
}

#define TRACE_BDRV_CO_DO_COPY_ON_READV_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_BDRV_CO_DO_COPY_ON_READV) || \
    false)

static inline void _nocheck__trace_bdrv_co_do_copy_on_readv(void * bs, int64_t offset, unsigned int bytes, int64_t cluster_offset, int64_t cluster_bytes)
{
    if (trace_event_get_state(TRACE_BDRV_CO_DO_COPY_ON_READV) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:bdrv_co_do_copy_on_readv " "bs %p offset %"PRId64" bytes %u cluster_offset %"PRId64" cluster_bytes %"PRId64 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , bs, offset, bytes, cluster_offset, cluster_bytes);
    }
}

static inline void trace_bdrv_co_do_copy_on_readv(void * bs, int64_t offset, unsigned int bytes, int64_t cluster_offset, int64_t cluster_bytes)
{
    if (true) {
        _nocheck__trace_bdrv_co_do_copy_on_readv(bs, offset, bytes, cluster_offset, cluster_bytes);
    }
}

#define TRACE_BDRV_CO_COPY_RANGE_FROM_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_BDRV_CO_COPY_RANGE_FROM) || \
    false)

static inline void _nocheck__trace_bdrv_co_copy_range_from(void * src, uint64_t src_offset, void * dst, uint64_t dst_offset, uint64_t bytes, int read_flags, int write_flags)
{
    if (trace_event_get_state(TRACE_BDRV_CO_COPY_RANGE_FROM) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:bdrv_co_copy_range_from " "src %p offset %"PRIu64" dst %p offset %"PRIu64" bytes %"PRIu64" rw flags 0x%x 0x%x" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , src, src_offset, dst, dst_offset, bytes, read_flags, write_flags);
    }
}

static inline void trace_bdrv_co_copy_range_from(void * src, uint64_t src_offset, void * dst, uint64_t dst_offset, uint64_t bytes, int read_flags, int write_flags)
{
    if (true) {
        _nocheck__trace_bdrv_co_copy_range_from(src, src_offset, dst, dst_offset, bytes, read_flags, write_flags);
    }
}

#define TRACE_BDRV_CO_COPY_RANGE_TO_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_BDRV_CO_COPY_RANGE_TO) || \
    false)

static inline void _nocheck__trace_bdrv_co_copy_range_to(void * src, uint64_t src_offset, void * dst, uint64_t dst_offset, uint64_t bytes, int read_flags, int write_flags)
{
    if (trace_event_get_state(TRACE_BDRV_CO_COPY_RANGE_TO) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:bdrv_co_copy_range_to " "src %p offset %"PRIu64" dst %p offset %"PRIu64" bytes %"PRIu64" rw flags 0x%x 0x%x" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , src, src_offset, dst, dst_offset, bytes, read_flags, write_flags);
    }
}

static inline void trace_bdrv_co_copy_range_to(void * src, uint64_t src_offset, void * dst, uint64_t dst_offset, uint64_t bytes, int read_flags, int write_flags)
{
    if (true) {
        _nocheck__trace_bdrv_co_copy_range_to(src, src_offset, dst, dst_offset, bytes, read_flags, write_flags);
    }
}

#define TRACE_STREAM_ONE_ITERATION_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_STREAM_ONE_ITERATION) || \
    false)

static inline void _nocheck__trace_stream_one_iteration(void * s, int64_t offset, uint64_t bytes, int is_allocated)
{
    if (trace_event_get_state(TRACE_STREAM_ONE_ITERATION) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:stream_one_iteration " "s %p offset %" PRId64 " bytes %" PRIu64 " is_allocated %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, offset, bytes, is_allocated);
    }
}

static inline void trace_stream_one_iteration(void * s, int64_t offset, uint64_t bytes, int is_allocated)
{
    if (true) {
        _nocheck__trace_stream_one_iteration(s, offset, bytes, is_allocated);
    }
}

#define TRACE_STREAM_START_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_STREAM_START) || \
    false)

static inline void _nocheck__trace_stream_start(void * bs, void * base, void * s)
{
    if (trace_event_get_state(TRACE_STREAM_START) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:stream_start " "bs %p base %p s %p" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , bs, base, s);
    }
}

static inline void trace_stream_start(void * bs, void * base, void * s)
{
    if (true) {
        _nocheck__trace_stream_start(bs, base, s);
    }
}

#define TRACE_COMMIT_ONE_ITERATION_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_COMMIT_ONE_ITERATION) || \
    false)

static inline void _nocheck__trace_commit_one_iteration(void * s, int64_t offset, uint64_t bytes, int is_allocated)
{
    if (trace_event_get_state(TRACE_COMMIT_ONE_ITERATION) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:commit_one_iteration " "s %p offset %" PRId64 " bytes %" PRIu64 " is_allocated %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, offset, bytes, is_allocated);
    }
}

static inline void trace_commit_one_iteration(void * s, int64_t offset, uint64_t bytes, int is_allocated)
{
    if (true) {
        _nocheck__trace_commit_one_iteration(s, offset, bytes, is_allocated);
    }
}

#define TRACE_COMMIT_START_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_COMMIT_START) || \
    false)

static inline void _nocheck__trace_commit_start(void * bs, void * base, void * top, void * s)
{
    if (trace_event_get_state(TRACE_COMMIT_START) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:commit_start " "bs %p base %p top %p s %p" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , bs, base, top, s);
    }
}

static inline void trace_commit_start(void * bs, void * base, void * top, void * s)
{
    if (true) {
        _nocheck__trace_commit_start(bs, base, top, s);
    }
}

#define TRACE_MIRROR_START_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_MIRROR_START) || \
    false)

static inline void _nocheck__trace_mirror_start(void * bs, void * s, void * opaque)
{
    if (trace_event_get_state(TRACE_MIRROR_START) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:mirror_start " "bs %p s %p opaque %p" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , bs, s, opaque);
    }
}

static inline void trace_mirror_start(void * bs, void * s, void * opaque)
{
    if (true) {
        _nocheck__trace_mirror_start(bs, s, opaque);
    }
}

#define TRACE_MIRROR_RESTART_ITER_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_MIRROR_RESTART_ITER) || \
    false)

static inline void _nocheck__trace_mirror_restart_iter(void * s, int64_t cnt)
{
    if (trace_event_get_state(TRACE_MIRROR_RESTART_ITER) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:mirror_restart_iter " "s %p dirty count %"PRId64 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, cnt);
    }
}

static inline void trace_mirror_restart_iter(void * s, int64_t cnt)
{
    if (true) {
        _nocheck__trace_mirror_restart_iter(s, cnt);
    }
}

#define TRACE_MIRROR_BEFORE_FLUSH_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_MIRROR_BEFORE_FLUSH) || \
    false)

static inline void _nocheck__trace_mirror_before_flush(void * s)
{
    if (trace_event_get_state(TRACE_MIRROR_BEFORE_FLUSH) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:mirror_before_flush " "s %p" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s);
    }
}

static inline void trace_mirror_before_flush(void * s)
{
    if (true) {
        _nocheck__trace_mirror_before_flush(s);
    }
}

#define TRACE_MIRROR_BEFORE_DRAIN_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_MIRROR_BEFORE_DRAIN) || \
    false)

static inline void _nocheck__trace_mirror_before_drain(void * s, int64_t cnt)
{
    if (trace_event_get_state(TRACE_MIRROR_BEFORE_DRAIN) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:mirror_before_drain " "s %p dirty count %"PRId64 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, cnt);
    }
}

static inline void trace_mirror_before_drain(void * s, int64_t cnt)
{
    if (true) {
        _nocheck__trace_mirror_before_drain(s, cnt);
    }
}

#define TRACE_MIRROR_BEFORE_SLEEP_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_MIRROR_BEFORE_SLEEP) || \
    false)

static inline void _nocheck__trace_mirror_before_sleep(void * s, int64_t cnt, int synced, uint64_t delay_ns)
{
    if (trace_event_get_state(TRACE_MIRROR_BEFORE_SLEEP) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:mirror_before_sleep " "s %p dirty count %"PRId64" synced %d delay %"PRIu64"ns" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, cnt, synced, delay_ns);
    }
}

static inline void trace_mirror_before_sleep(void * s, int64_t cnt, int synced, uint64_t delay_ns)
{
    if (true) {
        _nocheck__trace_mirror_before_sleep(s, cnt, synced, delay_ns);
    }
}

#define TRACE_MIRROR_ONE_ITERATION_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_MIRROR_ONE_ITERATION) || \
    false)

static inline void _nocheck__trace_mirror_one_iteration(void * s, int64_t offset, uint64_t bytes)
{
    if (trace_event_get_state(TRACE_MIRROR_ONE_ITERATION) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:mirror_one_iteration " "s %p offset %" PRId64 " bytes %" PRIu64 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, offset, bytes);
    }
}

static inline void trace_mirror_one_iteration(void * s, int64_t offset, uint64_t bytes)
{
    if (true) {
        _nocheck__trace_mirror_one_iteration(s, offset, bytes);
    }
}

#define TRACE_MIRROR_ITERATION_DONE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_MIRROR_ITERATION_DONE) || \
    false)

static inline void _nocheck__trace_mirror_iteration_done(void * s, int64_t offset, uint64_t bytes, int ret)
{
    if (trace_event_get_state(TRACE_MIRROR_ITERATION_DONE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:mirror_iteration_done " "s %p offset %" PRId64 " bytes %" PRIu64 " ret %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, offset, bytes, ret);
    }
}

static inline void trace_mirror_iteration_done(void * s, int64_t offset, uint64_t bytes, int ret)
{
    if (true) {
        _nocheck__trace_mirror_iteration_done(s, offset, bytes, ret);
    }
}

#define TRACE_MIRROR_YIELD_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_MIRROR_YIELD) || \
    false)

static inline void _nocheck__trace_mirror_yield(void * s, int64_t cnt, int buf_free_count, int in_flight)
{
    if (trace_event_get_state(TRACE_MIRROR_YIELD) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:mirror_yield " "s %p dirty count %"PRId64" free buffers %d in_flight %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, cnt, buf_free_count, in_flight);
    }
}

static inline void trace_mirror_yield(void * s, int64_t cnt, int buf_free_count, int in_flight)
{
    if (true) {
        _nocheck__trace_mirror_yield(s, cnt, buf_free_count, in_flight);
    }
}

#define TRACE_MIRROR_YIELD_IN_FLIGHT_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_MIRROR_YIELD_IN_FLIGHT) || \
    false)

static inline void _nocheck__trace_mirror_yield_in_flight(void * s, int64_t offset, int in_flight)
{
    if (trace_event_get_state(TRACE_MIRROR_YIELD_IN_FLIGHT) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:mirror_yield_in_flight " "s %p offset %" PRId64 " in_flight %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, offset, in_flight);
    }
}

static inline void trace_mirror_yield_in_flight(void * s, int64_t offset, int in_flight)
{
    if (true) {
        _nocheck__trace_mirror_yield_in_flight(s, offset, in_flight);
    }
}

#define TRACE_BACKUP_DO_COW_ENTER_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_BACKUP_DO_COW_ENTER) || \
    false)

static inline void _nocheck__trace_backup_do_cow_enter(void * job, int64_t start, int64_t offset, uint64_t bytes)
{
    if (trace_event_get_state(TRACE_BACKUP_DO_COW_ENTER) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:backup_do_cow_enter " "job %p start %" PRId64 " offset %" PRId64 " bytes %" PRIu64 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , job, start, offset, bytes);
    }
}

static inline void trace_backup_do_cow_enter(void * job, int64_t start, int64_t offset, uint64_t bytes)
{
    if (true) {
        _nocheck__trace_backup_do_cow_enter(job, start, offset, bytes);
    }
}

#define TRACE_BACKUP_DO_COW_RETURN_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_BACKUP_DO_COW_RETURN) || \
    false)

static inline void _nocheck__trace_backup_do_cow_return(void * job, int64_t offset, uint64_t bytes, int ret)
{
    if (trace_event_get_state(TRACE_BACKUP_DO_COW_RETURN) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:backup_do_cow_return " "job %p offset %" PRId64 " bytes %" PRIu64 " ret %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , job, offset, bytes, ret);
    }
}

static inline void trace_backup_do_cow_return(void * job, int64_t offset, uint64_t bytes, int ret)
{
    if (true) {
        _nocheck__trace_backup_do_cow_return(job, offset, bytes, ret);
    }
}

#define TRACE_BLOCK_COPY_SKIP_RANGE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_BLOCK_COPY_SKIP_RANGE) || \
    false)

static inline void _nocheck__trace_block_copy_skip_range(void * bcs, int64_t start, uint64_t bytes)
{
    if (trace_event_get_state(TRACE_BLOCK_COPY_SKIP_RANGE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:block_copy_skip_range " "bcs %p start %"PRId64" bytes %"PRId64 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , bcs, start, bytes);
    }
}

static inline void trace_block_copy_skip_range(void * bcs, int64_t start, uint64_t bytes)
{
    if (true) {
        _nocheck__trace_block_copy_skip_range(bcs, start, bytes);
    }
}

#define TRACE_BLOCK_COPY_PROCESS_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_BLOCK_COPY_PROCESS) || \
    false)

static inline void _nocheck__trace_block_copy_process(void * bcs, int64_t start)
{
    if (trace_event_get_state(TRACE_BLOCK_COPY_PROCESS) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:block_copy_process " "bcs %p start %"PRId64 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , bcs, start);
    }
}

static inline void trace_block_copy_process(void * bcs, int64_t start)
{
    if (true) {
        _nocheck__trace_block_copy_process(bcs, start);
    }
}

#define TRACE_BLOCK_COPY_COPY_RANGE_FAIL_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_BLOCK_COPY_COPY_RANGE_FAIL) || \
    false)

static inline void _nocheck__trace_block_copy_copy_range_fail(void * bcs, int64_t start, int ret)
{
    if (trace_event_get_state(TRACE_BLOCK_COPY_COPY_RANGE_FAIL) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:block_copy_copy_range_fail " "bcs %p start %"PRId64" ret %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , bcs, start, ret);
    }
}

static inline void trace_block_copy_copy_range_fail(void * bcs, int64_t start, int ret)
{
    if (true) {
        _nocheck__trace_block_copy_copy_range_fail(bcs, start, ret);
    }
}

#define TRACE_BLOCK_COPY_READ_FAIL_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_BLOCK_COPY_READ_FAIL) || \
    false)

static inline void _nocheck__trace_block_copy_read_fail(void * bcs, int64_t start, int ret)
{
    if (trace_event_get_state(TRACE_BLOCK_COPY_READ_FAIL) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:block_copy_read_fail " "bcs %p start %"PRId64" ret %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , bcs, start, ret);
    }
}

static inline void trace_block_copy_read_fail(void * bcs, int64_t start, int ret)
{
    if (true) {
        _nocheck__trace_block_copy_read_fail(bcs, start, ret);
    }
}

#define TRACE_BLOCK_COPY_WRITE_FAIL_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_BLOCK_COPY_WRITE_FAIL) || \
    false)

static inline void _nocheck__trace_block_copy_write_fail(void * bcs, int64_t start, int ret)
{
    if (trace_event_get_state(TRACE_BLOCK_COPY_WRITE_FAIL) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:block_copy_write_fail " "bcs %p start %"PRId64" ret %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , bcs, start, ret);
    }
}

static inline void trace_block_copy_write_fail(void * bcs, int64_t start, int ret)
{
    if (true) {
        _nocheck__trace_block_copy_write_fail(bcs, start, ret);
    }
}

#define TRACE_BLOCK_COPY_WRITE_ZEROES_FAIL_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_BLOCK_COPY_WRITE_ZEROES_FAIL) || \
    false)

static inline void _nocheck__trace_block_copy_write_zeroes_fail(void * bcs, int64_t start, int ret)
{
    if (trace_event_get_state(TRACE_BLOCK_COPY_WRITE_ZEROES_FAIL) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:block_copy_write_zeroes_fail " "bcs %p start %"PRId64" ret %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , bcs, start, ret);
    }
}

static inline void trace_block_copy_write_zeroes_fail(void * bcs, int64_t start, int ret)
{
    if (true) {
        _nocheck__trace_block_copy_write_zeroes_fail(bcs, start, ret);
    }
}

#define TRACE_QMP_BLOCK_JOB_CANCEL_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QMP_BLOCK_JOB_CANCEL) || \
    false)

static inline void _nocheck__trace_qmp_block_job_cancel(void * job)
{
    if (trace_event_get_state(TRACE_QMP_BLOCK_JOB_CANCEL) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qmp_block_job_cancel " "job %p" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , job);
    }
}

static inline void trace_qmp_block_job_cancel(void * job)
{
    if (true) {
        _nocheck__trace_qmp_block_job_cancel(job);
    }
}

#define TRACE_QMP_BLOCK_JOB_PAUSE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QMP_BLOCK_JOB_PAUSE) || \
    false)

static inline void _nocheck__trace_qmp_block_job_pause(void * job)
{
    if (trace_event_get_state(TRACE_QMP_BLOCK_JOB_PAUSE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qmp_block_job_pause " "job %p" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , job);
    }
}

static inline void trace_qmp_block_job_pause(void * job)
{
    if (true) {
        _nocheck__trace_qmp_block_job_pause(job);
    }
}

#define TRACE_QMP_BLOCK_JOB_RESUME_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QMP_BLOCK_JOB_RESUME) || \
    false)

static inline void _nocheck__trace_qmp_block_job_resume(void * job)
{
    if (trace_event_get_state(TRACE_QMP_BLOCK_JOB_RESUME) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qmp_block_job_resume " "job %p" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , job);
    }
}

static inline void trace_qmp_block_job_resume(void * job)
{
    if (true) {
        _nocheck__trace_qmp_block_job_resume(job);
    }
}

#define TRACE_QMP_BLOCK_JOB_COMPLETE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QMP_BLOCK_JOB_COMPLETE) || \
    false)

static inline void _nocheck__trace_qmp_block_job_complete(void * job)
{
    if (trace_event_get_state(TRACE_QMP_BLOCK_JOB_COMPLETE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qmp_block_job_complete " "job %p" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , job);
    }
}

static inline void trace_qmp_block_job_complete(void * job)
{
    if (true) {
        _nocheck__trace_qmp_block_job_complete(job);
    }
}

#define TRACE_QMP_BLOCK_JOB_FINALIZE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QMP_BLOCK_JOB_FINALIZE) || \
    false)

static inline void _nocheck__trace_qmp_block_job_finalize(void * job)
{
    if (trace_event_get_state(TRACE_QMP_BLOCK_JOB_FINALIZE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qmp_block_job_finalize " "job %p" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , job);
    }
}

static inline void trace_qmp_block_job_finalize(void * job)
{
    if (true) {
        _nocheck__trace_qmp_block_job_finalize(job);
    }
}

#define TRACE_QMP_BLOCK_JOB_DISMISS_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QMP_BLOCK_JOB_DISMISS) || \
    false)

static inline void _nocheck__trace_qmp_block_job_dismiss(void * job)
{
    if (trace_event_get_state(TRACE_QMP_BLOCK_JOB_DISMISS) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qmp_block_job_dismiss " "job %p" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , job);
    }
}

static inline void trace_qmp_block_job_dismiss(void * job)
{
    if (true) {
        _nocheck__trace_qmp_block_job_dismiss(job);
    }
}

#define TRACE_QMP_BLOCK_STREAM_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QMP_BLOCK_STREAM) || \
    false)

static inline void _nocheck__trace_qmp_block_stream(void * bs)
{
    if (trace_event_get_state(TRACE_QMP_BLOCK_STREAM) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qmp_block_stream " "bs %p" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , bs);
    }
}

static inline void trace_qmp_block_stream(void * bs)
{
    if (true) {
        _nocheck__trace_qmp_block_stream(bs);
    }
}

#define TRACE_FILE_PAIO_SUBMIT_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_FILE_PAIO_SUBMIT) || \
    false)

static inline void _nocheck__trace_file_paio_submit(void * acb, void * opaque, int64_t offset, int count, int type)
{
    if (trace_event_get_state(TRACE_FILE_PAIO_SUBMIT) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:file_paio_submit " "acb %p opaque %p offset %"PRId64" count %d type %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , acb, opaque, offset, count, type);
    }
}

static inline void trace_file_paio_submit(void * acb, void * opaque, int64_t offset, int count, int type)
{
    if (true) {
        _nocheck__trace_file_paio_submit(acb, opaque, offset, count, type);
    }
}

#define TRACE_LURING_INIT_STATE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_LURING_INIT_STATE) || \
    false)

static inline void _nocheck__trace_luring_init_state(void * s, size_t size)
{
    if (trace_event_get_state(TRACE_LURING_INIT_STATE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:luring_init_state " "s %p size %zu" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, size);
    }
}

static inline void trace_luring_init_state(void * s, size_t size)
{
    if (true) {
        _nocheck__trace_luring_init_state(s, size);
    }
}

#define TRACE_LURING_CLEANUP_STATE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_LURING_CLEANUP_STATE) || \
    false)

static inline void _nocheck__trace_luring_cleanup_state(void * s)
{
    if (trace_event_get_state(TRACE_LURING_CLEANUP_STATE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:luring_cleanup_state " "%p freed" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s);
    }
}

static inline void trace_luring_cleanup_state(void * s)
{
    if (true) {
        _nocheck__trace_luring_cleanup_state(s);
    }
}

#define TRACE_LURING_IO_PLUG_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_LURING_IO_PLUG) || \
    false)

static inline void _nocheck__trace_luring_io_plug(void * s)
{
    if (trace_event_get_state(TRACE_LURING_IO_PLUG) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:luring_io_plug " "LuringState %p plug" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s);
    }
}

static inline void trace_luring_io_plug(void * s)
{
    if (true) {
        _nocheck__trace_luring_io_plug(s);
    }
}

#define TRACE_LURING_IO_UNPLUG_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_LURING_IO_UNPLUG) || \
    false)

static inline void _nocheck__trace_luring_io_unplug(void * s, int blocked, int plugged, int queued, int inflight)
{
    if (trace_event_get_state(TRACE_LURING_IO_UNPLUG) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:luring_io_unplug " "LuringState %p blocked %d plugged %d queued %d inflight %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, blocked, plugged, queued, inflight);
    }
}

static inline void trace_luring_io_unplug(void * s, int blocked, int plugged, int queued, int inflight)
{
    if (true) {
        _nocheck__trace_luring_io_unplug(s, blocked, plugged, queued, inflight);
    }
}

#define TRACE_LURING_DO_SUBMIT_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_LURING_DO_SUBMIT) || \
    false)

static inline void _nocheck__trace_luring_do_submit(void * s, int blocked, int plugged, int queued, int inflight)
{
    if (trace_event_get_state(TRACE_LURING_DO_SUBMIT) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:luring_do_submit " "LuringState %p blocked %d plugged %d queued %d inflight %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, blocked, plugged, queued, inflight);
    }
}

static inline void trace_luring_do_submit(void * s, int blocked, int plugged, int queued, int inflight)
{
    if (true) {
        _nocheck__trace_luring_do_submit(s, blocked, plugged, queued, inflight);
    }
}

#define TRACE_LURING_DO_SUBMIT_DONE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_LURING_DO_SUBMIT_DONE) || \
    false)

static inline void _nocheck__trace_luring_do_submit_done(void * s, int ret)
{
    if (trace_event_get_state(TRACE_LURING_DO_SUBMIT_DONE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:luring_do_submit_done " "LuringState %p submitted to kernel %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, ret);
    }
}

static inline void trace_luring_do_submit_done(void * s, int ret)
{
    if (true) {
        _nocheck__trace_luring_do_submit_done(s, ret);
    }
}

#define TRACE_LURING_CO_SUBMIT_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_LURING_CO_SUBMIT) || \
    false)

static inline void _nocheck__trace_luring_co_submit(void * bs, void * s, void * luringcb, int fd, uint64_t offset, size_t nbytes, int type)
{
    if (trace_event_get_state(TRACE_LURING_CO_SUBMIT) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:luring_co_submit " "bs %p s %p luringcb %p fd %d offset %" PRId64 " nbytes %zd type %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , bs, s, luringcb, fd, offset, nbytes, type);
    }
}

static inline void trace_luring_co_submit(void * bs, void * s, void * luringcb, int fd, uint64_t offset, size_t nbytes, int type)
{
    if (true) {
        _nocheck__trace_luring_co_submit(bs, s, luringcb, fd, offset, nbytes, type);
    }
}

#define TRACE_LURING_PROCESS_COMPLETION_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_LURING_PROCESS_COMPLETION) || \
    false)

static inline void _nocheck__trace_luring_process_completion(void * s, void * aiocb, int ret)
{
    if (trace_event_get_state(TRACE_LURING_PROCESS_COMPLETION) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:luring_process_completion " "LuringState %p luringcb %p ret %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, aiocb, ret);
    }
}

static inline void trace_luring_process_completion(void * s, void * aiocb, int ret)
{
    if (true) {
        _nocheck__trace_luring_process_completion(s, aiocb, ret);
    }
}

#define TRACE_LURING_IO_URING_SUBMIT_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_LURING_IO_URING_SUBMIT) || \
    false)

static inline void _nocheck__trace_luring_io_uring_submit(void * s, int ret)
{
    if (trace_event_get_state(TRACE_LURING_IO_URING_SUBMIT) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:luring_io_uring_submit " "LuringState %p ret %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, ret);
    }
}

static inline void trace_luring_io_uring_submit(void * s, int ret)
{
    if (true) {
        _nocheck__trace_luring_io_uring_submit(s, ret);
    }
}

#define TRACE_LURING_RESUBMIT_SHORT_READ_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_LURING_RESUBMIT_SHORT_READ) || \
    false)

static inline void _nocheck__trace_luring_resubmit_short_read(void * s, void * luringcb, int nread)
{
    if (trace_event_get_state(TRACE_LURING_RESUBMIT_SHORT_READ) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:luring_resubmit_short_read " "LuringState %p luringcb %p nread %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, luringcb, nread);
    }
}

static inline void trace_luring_resubmit_short_read(void * s, void * luringcb, int nread)
{
    if (true) {
        _nocheck__trace_luring_resubmit_short_read(s, luringcb, nread);
    }
}

#define TRACE_QCOW2_ADD_TASK_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QCOW2_ADD_TASK) || \
    false)

static inline void _nocheck__trace_qcow2_add_task(void * co, void * bs, void * pool, const char * action, int cluster_type, uint64_t host_offset, uint64_t offset, uint64_t bytes, void * qiov, size_t qiov_offset)
{
    if (trace_event_get_state(TRACE_QCOW2_ADD_TASK) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qcow2_add_task " "co %p bs %p pool %p: %s: cluster_type %d file_cluster_offset %" PRIu64 " offset %" PRIu64 " bytes %" PRIu64 " qiov %p qiov_offset %zu" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , co, bs, pool, action, cluster_type, host_offset, offset, bytes, qiov, qiov_offset);
    }
}

static inline void trace_qcow2_add_task(void * co, void * bs, void * pool, const char * action, int cluster_type, uint64_t host_offset, uint64_t offset, uint64_t bytes, void * qiov, size_t qiov_offset)
{
    if (true) {
        _nocheck__trace_qcow2_add_task(co, bs, pool, action, cluster_type, host_offset, offset, bytes, qiov, qiov_offset);
    }
}

#define TRACE_QCOW2_WRITEV_START_REQ_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QCOW2_WRITEV_START_REQ) || \
    false)

static inline void _nocheck__trace_qcow2_writev_start_req(void * co, int64_t offset, int bytes)
{
    if (trace_event_get_state(TRACE_QCOW2_WRITEV_START_REQ) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qcow2_writev_start_req " "co %p offset 0x%" PRIx64 " bytes %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , co, offset, bytes);
    }
}

static inline void trace_qcow2_writev_start_req(void * co, int64_t offset, int bytes)
{
    if (true) {
        _nocheck__trace_qcow2_writev_start_req(co, offset, bytes);
    }
}

#define TRACE_QCOW2_WRITEV_DONE_REQ_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QCOW2_WRITEV_DONE_REQ) || \
    false)

static inline void _nocheck__trace_qcow2_writev_done_req(void * co, int ret)
{
    if (trace_event_get_state(TRACE_QCOW2_WRITEV_DONE_REQ) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qcow2_writev_done_req " "co %p ret %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , co, ret);
    }
}

static inline void trace_qcow2_writev_done_req(void * co, int ret)
{
    if (true) {
        _nocheck__trace_qcow2_writev_done_req(co, ret);
    }
}

#define TRACE_QCOW2_WRITEV_START_PART_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QCOW2_WRITEV_START_PART) || \
    false)

static inline void _nocheck__trace_qcow2_writev_start_part(void * co)
{
    if (trace_event_get_state(TRACE_QCOW2_WRITEV_START_PART) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qcow2_writev_start_part " "co %p" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , co);
    }
}

static inline void trace_qcow2_writev_start_part(void * co)
{
    if (true) {
        _nocheck__trace_qcow2_writev_start_part(co);
    }
}

#define TRACE_QCOW2_WRITEV_DONE_PART_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QCOW2_WRITEV_DONE_PART) || \
    false)

static inline void _nocheck__trace_qcow2_writev_done_part(void * co, int cur_bytes)
{
    if (trace_event_get_state(TRACE_QCOW2_WRITEV_DONE_PART) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qcow2_writev_done_part " "co %p cur_bytes %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , co, cur_bytes);
    }
}

static inline void trace_qcow2_writev_done_part(void * co, int cur_bytes)
{
    if (true) {
        _nocheck__trace_qcow2_writev_done_part(co, cur_bytes);
    }
}

#define TRACE_QCOW2_WRITEV_DATA_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QCOW2_WRITEV_DATA) || \
    false)

static inline void _nocheck__trace_qcow2_writev_data(void * co, uint64_t offset)
{
    if (trace_event_get_state(TRACE_QCOW2_WRITEV_DATA) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qcow2_writev_data " "co %p offset 0x%" PRIx64 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , co, offset);
    }
}

static inline void trace_qcow2_writev_data(void * co, uint64_t offset)
{
    if (true) {
        _nocheck__trace_qcow2_writev_data(co, offset);
    }
}

#define TRACE_QCOW2_PWRITE_ZEROES_START_REQ_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QCOW2_PWRITE_ZEROES_START_REQ) || \
    false)

static inline void _nocheck__trace_qcow2_pwrite_zeroes_start_req(void * co, int64_t offset, int count)
{
    if (trace_event_get_state(TRACE_QCOW2_PWRITE_ZEROES_START_REQ) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qcow2_pwrite_zeroes_start_req " "co %p offset 0x%" PRIx64 " count %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , co, offset, count);
    }
}

static inline void trace_qcow2_pwrite_zeroes_start_req(void * co, int64_t offset, int count)
{
    if (true) {
        _nocheck__trace_qcow2_pwrite_zeroes_start_req(co, offset, count);
    }
}

#define TRACE_QCOW2_PWRITE_ZEROES_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QCOW2_PWRITE_ZEROES) || \
    false)

static inline void _nocheck__trace_qcow2_pwrite_zeroes(void * co, int64_t offset, int count)
{
    if (trace_event_get_state(TRACE_QCOW2_PWRITE_ZEROES) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qcow2_pwrite_zeroes " "co %p offset 0x%" PRIx64 " count %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , co, offset, count);
    }
}

static inline void trace_qcow2_pwrite_zeroes(void * co, int64_t offset, int count)
{
    if (true) {
        _nocheck__trace_qcow2_pwrite_zeroes(co, offset, count);
    }
}

#define TRACE_QCOW2_SKIP_COW_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QCOW2_SKIP_COW) || \
    false)

static inline void _nocheck__trace_qcow2_skip_cow(void * co, uint64_t offset, int nb_clusters)
{
    if (trace_event_get_state(TRACE_QCOW2_SKIP_COW) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qcow2_skip_cow " "co %p offset 0x%" PRIx64 " nb_clusters %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , co, offset, nb_clusters);
    }
}

static inline void trace_qcow2_skip_cow(void * co, uint64_t offset, int nb_clusters)
{
    if (true) {
        _nocheck__trace_qcow2_skip_cow(co, offset, nb_clusters);
    }
}

#define TRACE_QCOW2_ALLOC_CLUSTERS_OFFSET_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QCOW2_ALLOC_CLUSTERS_OFFSET) || \
    false)

static inline void _nocheck__trace_qcow2_alloc_clusters_offset(void * co, uint64_t offset, int bytes)
{
    if (trace_event_get_state(TRACE_QCOW2_ALLOC_CLUSTERS_OFFSET) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qcow2_alloc_clusters_offset " "co %p offset 0x%" PRIx64 " bytes %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , co, offset, bytes);
    }
}

static inline void trace_qcow2_alloc_clusters_offset(void * co, uint64_t offset, int bytes)
{
    if (true) {
        _nocheck__trace_qcow2_alloc_clusters_offset(co, offset, bytes);
    }
}

#define TRACE_QCOW2_HANDLE_COPIED_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QCOW2_HANDLE_COPIED) || \
    false)

static inline void _nocheck__trace_qcow2_handle_copied(void * co, uint64_t guest_offset, uint64_t host_offset, uint64_t bytes)
{
    if (trace_event_get_state(TRACE_QCOW2_HANDLE_COPIED) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qcow2_handle_copied " "co %p guest_offset 0x%" PRIx64 " host_offset 0x%" PRIx64 " bytes 0x%" PRIx64 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , co, guest_offset, host_offset, bytes);
    }
}

static inline void trace_qcow2_handle_copied(void * co, uint64_t guest_offset, uint64_t host_offset, uint64_t bytes)
{
    if (true) {
        _nocheck__trace_qcow2_handle_copied(co, guest_offset, host_offset, bytes);
    }
}

#define TRACE_QCOW2_HANDLE_ALLOC_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QCOW2_HANDLE_ALLOC) || \
    false)

static inline void _nocheck__trace_qcow2_handle_alloc(void * co, uint64_t guest_offset, uint64_t host_offset, uint64_t bytes)
{
    if (trace_event_get_state(TRACE_QCOW2_HANDLE_ALLOC) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qcow2_handle_alloc " "co %p guest_offset 0x%" PRIx64 " host_offset 0x%" PRIx64 " bytes 0x%" PRIx64 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , co, guest_offset, host_offset, bytes);
    }
}

static inline void trace_qcow2_handle_alloc(void * co, uint64_t guest_offset, uint64_t host_offset, uint64_t bytes)
{
    if (true) {
        _nocheck__trace_qcow2_handle_alloc(co, guest_offset, host_offset, bytes);
    }
}

#define TRACE_QCOW2_DO_ALLOC_CLUSTERS_OFFSET_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QCOW2_DO_ALLOC_CLUSTERS_OFFSET) || \
    false)

static inline void _nocheck__trace_qcow2_do_alloc_clusters_offset(void * co, uint64_t guest_offset, uint64_t host_offset, int nb_clusters)
{
    if (trace_event_get_state(TRACE_QCOW2_DO_ALLOC_CLUSTERS_OFFSET) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qcow2_do_alloc_clusters_offset " "co %p guest_offset 0x%" PRIx64 " host_offset 0x%" PRIx64 " nb_clusters %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , co, guest_offset, host_offset, nb_clusters);
    }
}

static inline void trace_qcow2_do_alloc_clusters_offset(void * co, uint64_t guest_offset, uint64_t host_offset, int nb_clusters)
{
    if (true) {
        _nocheck__trace_qcow2_do_alloc_clusters_offset(co, guest_offset, host_offset, nb_clusters);
    }
}

#define TRACE_QCOW2_CLUSTER_ALLOC_PHYS_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QCOW2_CLUSTER_ALLOC_PHYS) || \
    false)

static inline void _nocheck__trace_qcow2_cluster_alloc_phys(void * co)
{
    if (trace_event_get_state(TRACE_QCOW2_CLUSTER_ALLOC_PHYS) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qcow2_cluster_alloc_phys " "co %p" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , co);
    }
}

static inline void trace_qcow2_cluster_alloc_phys(void * co)
{
    if (true) {
        _nocheck__trace_qcow2_cluster_alloc_phys(co);
    }
}

#define TRACE_QCOW2_CLUSTER_LINK_L2_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QCOW2_CLUSTER_LINK_L2) || \
    false)

static inline void _nocheck__trace_qcow2_cluster_link_l2(void * co, int nb_clusters)
{
    if (trace_event_get_state(TRACE_QCOW2_CLUSTER_LINK_L2) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qcow2_cluster_link_l2 " "co %p nb_clusters %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , co, nb_clusters);
    }
}

static inline void trace_qcow2_cluster_link_l2(void * co, int nb_clusters)
{
    if (true) {
        _nocheck__trace_qcow2_cluster_link_l2(co, nb_clusters);
    }
}

#define TRACE_QCOW2_L2_ALLOCATE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QCOW2_L2_ALLOCATE) || \
    false)

static inline void _nocheck__trace_qcow2_l2_allocate(void * bs, int l1_index)
{
    if (trace_event_get_state(TRACE_QCOW2_L2_ALLOCATE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qcow2_l2_allocate " "bs %p l1_index %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , bs, l1_index);
    }
}

static inline void trace_qcow2_l2_allocate(void * bs, int l1_index)
{
    if (true) {
        _nocheck__trace_qcow2_l2_allocate(bs, l1_index);
    }
}

#define TRACE_QCOW2_L2_ALLOCATE_GET_EMPTY_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QCOW2_L2_ALLOCATE_GET_EMPTY) || \
    false)

static inline void _nocheck__trace_qcow2_l2_allocate_get_empty(void * bs, int l1_index)
{
    if (trace_event_get_state(TRACE_QCOW2_L2_ALLOCATE_GET_EMPTY) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qcow2_l2_allocate_get_empty " "bs %p l1_index %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , bs, l1_index);
    }
}

static inline void trace_qcow2_l2_allocate_get_empty(void * bs, int l1_index)
{
    if (true) {
        _nocheck__trace_qcow2_l2_allocate_get_empty(bs, l1_index);
    }
}

#define TRACE_QCOW2_L2_ALLOCATE_WRITE_L2_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QCOW2_L2_ALLOCATE_WRITE_L2) || \
    false)

static inline void _nocheck__trace_qcow2_l2_allocate_write_l2(void * bs, int l1_index)
{
    if (trace_event_get_state(TRACE_QCOW2_L2_ALLOCATE_WRITE_L2) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qcow2_l2_allocate_write_l2 " "bs %p l1_index %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , bs, l1_index);
    }
}

static inline void trace_qcow2_l2_allocate_write_l2(void * bs, int l1_index)
{
    if (true) {
        _nocheck__trace_qcow2_l2_allocate_write_l2(bs, l1_index);
    }
}

#define TRACE_QCOW2_L2_ALLOCATE_WRITE_L1_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QCOW2_L2_ALLOCATE_WRITE_L1) || \
    false)

static inline void _nocheck__trace_qcow2_l2_allocate_write_l1(void * bs, int l1_index)
{
    if (trace_event_get_state(TRACE_QCOW2_L2_ALLOCATE_WRITE_L1) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qcow2_l2_allocate_write_l1 " "bs %p l1_index %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , bs, l1_index);
    }
}

static inline void trace_qcow2_l2_allocate_write_l1(void * bs, int l1_index)
{
    if (true) {
        _nocheck__trace_qcow2_l2_allocate_write_l1(bs, l1_index);
    }
}

#define TRACE_QCOW2_L2_ALLOCATE_DONE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QCOW2_L2_ALLOCATE_DONE) || \
    false)

static inline void _nocheck__trace_qcow2_l2_allocate_done(void * bs, int l1_index, int ret)
{
    if (trace_event_get_state(TRACE_QCOW2_L2_ALLOCATE_DONE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qcow2_l2_allocate_done " "bs %p l1_index %d ret %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , bs, l1_index, ret);
    }
}

static inline void trace_qcow2_l2_allocate_done(void * bs, int l1_index, int ret)
{
    if (true) {
        _nocheck__trace_qcow2_l2_allocate_done(bs, l1_index, ret);
    }
}

#define TRACE_QCOW2_CACHE_GET_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QCOW2_CACHE_GET) || \
    false)

static inline void _nocheck__trace_qcow2_cache_get(void * co, int c, uint64_t offset, bool read_from_disk)
{
    if (trace_event_get_state(TRACE_QCOW2_CACHE_GET) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qcow2_cache_get " "co %p is_l2_cache %d offset 0x%" PRIx64 " read_from_disk %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , co, c, offset, read_from_disk);
    }
}

static inline void trace_qcow2_cache_get(void * co, int c, uint64_t offset, bool read_from_disk)
{
    if (true) {
        _nocheck__trace_qcow2_cache_get(co, c, offset, read_from_disk);
    }
}

#define TRACE_QCOW2_CACHE_GET_REPLACE_ENTRY_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QCOW2_CACHE_GET_REPLACE_ENTRY) || \
    false)

static inline void _nocheck__trace_qcow2_cache_get_replace_entry(void * co, int c, int i)
{
    if (trace_event_get_state(TRACE_QCOW2_CACHE_GET_REPLACE_ENTRY) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qcow2_cache_get_replace_entry " "co %p is_l2_cache %d index %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , co, c, i);
    }
}

static inline void trace_qcow2_cache_get_replace_entry(void * co, int c, int i)
{
    if (true) {
        _nocheck__trace_qcow2_cache_get_replace_entry(co, c, i);
    }
}

#define TRACE_QCOW2_CACHE_GET_READ_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QCOW2_CACHE_GET_READ) || \
    false)

static inline void _nocheck__trace_qcow2_cache_get_read(void * co, int c, int i)
{
    if (trace_event_get_state(TRACE_QCOW2_CACHE_GET_READ) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qcow2_cache_get_read " "co %p is_l2_cache %d index %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , co, c, i);
    }
}

static inline void trace_qcow2_cache_get_read(void * co, int c, int i)
{
    if (true) {
        _nocheck__trace_qcow2_cache_get_read(co, c, i);
    }
}

#define TRACE_QCOW2_CACHE_GET_DONE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QCOW2_CACHE_GET_DONE) || \
    false)

static inline void _nocheck__trace_qcow2_cache_get_done(void * co, int c, int i)
{
    if (trace_event_get_state(TRACE_QCOW2_CACHE_GET_DONE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qcow2_cache_get_done " "co %p is_l2_cache %d index %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , co, c, i);
    }
}

static inline void trace_qcow2_cache_get_done(void * co, int c, int i)
{
    if (true) {
        _nocheck__trace_qcow2_cache_get_done(co, c, i);
    }
}

#define TRACE_QCOW2_CACHE_FLUSH_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QCOW2_CACHE_FLUSH) || \
    false)

static inline void _nocheck__trace_qcow2_cache_flush(void * co, int c)
{
    if (trace_event_get_state(TRACE_QCOW2_CACHE_FLUSH) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qcow2_cache_flush " "co %p is_l2_cache %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , co, c);
    }
}

static inline void trace_qcow2_cache_flush(void * co, int c)
{
    if (true) {
        _nocheck__trace_qcow2_cache_flush(co, c);
    }
}

#define TRACE_QCOW2_CACHE_ENTRY_FLUSH_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QCOW2_CACHE_ENTRY_FLUSH) || \
    false)

static inline void _nocheck__trace_qcow2_cache_entry_flush(void * co, int c, int i)
{
    if (trace_event_get_state(TRACE_QCOW2_CACHE_ENTRY_FLUSH) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qcow2_cache_entry_flush " "co %p is_l2_cache %d index %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , co, c, i);
    }
}

static inline void trace_qcow2_cache_entry_flush(void * co, int c, int i)
{
    if (true) {
        _nocheck__trace_qcow2_cache_entry_flush(co, c, i);
    }
}

#define TRACE_QCOW2_PROCESS_DISCARDS_FAILED_REGION_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QCOW2_PROCESS_DISCARDS_FAILED_REGION) || \
    false)

static inline void _nocheck__trace_qcow2_process_discards_failed_region(uint64_t offset, uint64_t bytes, int ret)
{
    if (trace_event_get_state(TRACE_QCOW2_PROCESS_DISCARDS_FAILED_REGION) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qcow2_process_discards_failed_region " "offset 0x%" PRIx64 " bytes 0x%" PRIx64 " ret %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , offset, bytes, ret);
    }
}

static inline void trace_qcow2_process_discards_failed_region(uint64_t offset, uint64_t bytes, int ret)
{
    if (true) {
        _nocheck__trace_qcow2_process_discards_failed_region(offset, bytes, ret);
    }
}

#define TRACE_QED_ALLOC_L2_CACHE_ENTRY_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QED_ALLOC_L2_CACHE_ENTRY) || \
    false)

static inline void _nocheck__trace_qed_alloc_l2_cache_entry(void * l2_cache, void * entry)
{
    if (trace_event_get_state(TRACE_QED_ALLOC_L2_CACHE_ENTRY) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qed_alloc_l2_cache_entry " "l2_cache %p entry %p" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , l2_cache, entry);
    }
}

static inline void trace_qed_alloc_l2_cache_entry(void * l2_cache, void * entry)
{
    if (true) {
        _nocheck__trace_qed_alloc_l2_cache_entry(l2_cache, entry);
    }
}

#define TRACE_QED_UNREF_L2_CACHE_ENTRY_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QED_UNREF_L2_CACHE_ENTRY) || \
    false)

static inline void _nocheck__trace_qed_unref_l2_cache_entry(void * entry, int ref)
{
    if (trace_event_get_state(TRACE_QED_UNREF_L2_CACHE_ENTRY) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qed_unref_l2_cache_entry " "entry %p ref %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , entry, ref);
    }
}

static inline void trace_qed_unref_l2_cache_entry(void * entry, int ref)
{
    if (true) {
        _nocheck__trace_qed_unref_l2_cache_entry(entry, ref);
    }
}

#define TRACE_QED_FIND_L2_CACHE_ENTRY_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QED_FIND_L2_CACHE_ENTRY) || \
    false)

static inline void _nocheck__trace_qed_find_l2_cache_entry(void * l2_cache, void * entry, uint64_t offset, int ref)
{
    if (trace_event_get_state(TRACE_QED_FIND_L2_CACHE_ENTRY) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qed_find_l2_cache_entry " "l2_cache %p entry %p offset %"PRIu64" ref %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , l2_cache, entry, offset, ref);
    }
}

static inline void trace_qed_find_l2_cache_entry(void * l2_cache, void * entry, uint64_t offset, int ref)
{
    if (true) {
        _nocheck__trace_qed_find_l2_cache_entry(l2_cache, entry, offset, ref);
    }
}

#define TRACE_QED_READ_TABLE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QED_READ_TABLE) || \
    false)

static inline void _nocheck__trace_qed_read_table(void * s, uint64_t offset, void * table)
{
    if (trace_event_get_state(TRACE_QED_READ_TABLE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qed_read_table " "s %p offset %"PRIu64" table %p" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, offset, table);
    }
}

static inline void trace_qed_read_table(void * s, uint64_t offset, void * table)
{
    if (true) {
        _nocheck__trace_qed_read_table(s, offset, table);
    }
}

#define TRACE_QED_READ_TABLE_CB_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QED_READ_TABLE_CB) || \
    false)

static inline void _nocheck__trace_qed_read_table_cb(void * s, void * table, int ret)
{
    if (trace_event_get_state(TRACE_QED_READ_TABLE_CB) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qed_read_table_cb " "s %p table %p ret %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, table, ret);
    }
}

static inline void trace_qed_read_table_cb(void * s, void * table, int ret)
{
    if (true) {
        _nocheck__trace_qed_read_table_cb(s, table, ret);
    }
}

#define TRACE_QED_WRITE_TABLE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QED_WRITE_TABLE) || \
    false)

static inline void _nocheck__trace_qed_write_table(void * s, uint64_t offset, void * table, unsigned int index, unsigned int n)
{
    if (trace_event_get_state(TRACE_QED_WRITE_TABLE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qed_write_table " "s %p offset %"PRIu64" table %p index %u n %u" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, offset, table, index, n);
    }
}

static inline void trace_qed_write_table(void * s, uint64_t offset, void * table, unsigned int index, unsigned int n)
{
    if (true) {
        _nocheck__trace_qed_write_table(s, offset, table, index, n);
    }
}

#define TRACE_QED_WRITE_TABLE_CB_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QED_WRITE_TABLE_CB) || \
    false)

static inline void _nocheck__trace_qed_write_table_cb(void * s, void * table, int flush, int ret)
{
    if (trace_event_get_state(TRACE_QED_WRITE_TABLE_CB) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qed_write_table_cb " "s %p table %p flush %d ret %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, table, flush, ret);
    }
}

static inline void trace_qed_write_table_cb(void * s, void * table, int flush, int ret)
{
    if (true) {
        _nocheck__trace_qed_write_table_cb(s, table, flush, ret);
    }
}

#define TRACE_QED_NEED_CHECK_TIMER_CB_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QED_NEED_CHECK_TIMER_CB) || \
    false)

static inline void _nocheck__trace_qed_need_check_timer_cb(void * s)
{
    if (trace_event_get_state(TRACE_QED_NEED_CHECK_TIMER_CB) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qed_need_check_timer_cb " "s %p" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s);
    }
}

static inline void trace_qed_need_check_timer_cb(void * s)
{
    if (true) {
        _nocheck__trace_qed_need_check_timer_cb(s);
    }
}

#define TRACE_QED_START_NEED_CHECK_TIMER_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QED_START_NEED_CHECK_TIMER) || \
    false)

static inline void _nocheck__trace_qed_start_need_check_timer(void * s)
{
    if (trace_event_get_state(TRACE_QED_START_NEED_CHECK_TIMER) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qed_start_need_check_timer " "s %p" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s);
    }
}

static inline void trace_qed_start_need_check_timer(void * s)
{
    if (true) {
        _nocheck__trace_qed_start_need_check_timer(s);
    }
}

#define TRACE_QED_CANCEL_NEED_CHECK_TIMER_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QED_CANCEL_NEED_CHECK_TIMER) || \
    false)

static inline void _nocheck__trace_qed_cancel_need_check_timer(void * s)
{
    if (trace_event_get_state(TRACE_QED_CANCEL_NEED_CHECK_TIMER) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qed_cancel_need_check_timer " "s %p" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s);
    }
}

static inline void trace_qed_cancel_need_check_timer(void * s)
{
    if (true) {
        _nocheck__trace_qed_cancel_need_check_timer(s);
    }
}

#define TRACE_QED_AIO_COMPLETE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QED_AIO_COMPLETE) || \
    false)

static inline void _nocheck__trace_qed_aio_complete(void * s, void * acb, int ret)
{
    if (trace_event_get_state(TRACE_QED_AIO_COMPLETE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qed_aio_complete " "s %p acb %p ret %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, acb, ret);
    }
}

static inline void trace_qed_aio_complete(void * s, void * acb, int ret)
{
    if (true) {
        _nocheck__trace_qed_aio_complete(s, acb, ret);
    }
}

#define TRACE_QED_AIO_SETUP_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QED_AIO_SETUP) || \
    false)

static inline void _nocheck__trace_qed_aio_setup(void * s, void * acb, int64_t sector_num, int nb_sectors, void * opaque, int flags)
{
    if (trace_event_get_state(TRACE_QED_AIO_SETUP) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qed_aio_setup " "s %p acb %p sector_num %"PRId64" nb_sectors %d opaque %p flags 0x%x" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, acb, sector_num, nb_sectors, opaque, flags);
    }
}

static inline void trace_qed_aio_setup(void * s, void * acb, int64_t sector_num, int nb_sectors, void * opaque, int flags)
{
    if (true) {
        _nocheck__trace_qed_aio_setup(s, acb, sector_num, nb_sectors, opaque, flags);
    }
}

#define TRACE_QED_AIO_NEXT_IO_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QED_AIO_NEXT_IO) || \
    false)

static inline void _nocheck__trace_qed_aio_next_io(void * s, void * acb, int ret, uint64_t cur_pos)
{
    if (trace_event_get_state(TRACE_QED_AIO_NEXT_IO) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qed_aio_next_io " "s %p acb %p ret %d cur_pos %"PRIu64 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, acb, ret, cur_pos);
    }
}

static inline void trace_qed_aio_next_io(void * s, void * acb, int ret, uint64_t cur_pos)
{
    if (true) {
        _nocheck__trace_qed_aio_next_io(s, acb, ret, cur_pos);
    }
}

#define TRACE_QED_AIO_READ_DATA_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QED_AIO_READ_DATA) || \
    false)

static inline void _nocheck__trace_qed_aio_read_data(void * s, void * acb, int ret, uint64_t offset, size_t len)
{
    if (trace_event_get_state(TRACE_QED_AIO_READ_DATA) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qed_aio_read_data " "s %p acb %p ret %d offset %"PRIu64" len %zu" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, acb, ret, offset, len);
    }
}

static inline void trace_qed_aio_read_data(void * s, void * acb, int ret, uint64_t offset, size_t len)
{
    if (true) {
        _nocheck__trace_qed_aio_read_data(s, acb, ret, offset, len);
    }
}

#define TRACE_QED_AIO_WRITE_DATA_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QED_AIO_WRITE_DATA) || \
    false)

static inline void _nocheck__trace_qed_aio_write_data(void * s, void * acb, int ret, uint64_t offset, size_t len)
{
    if (trace_event_get_state(TRACE_QED_AIO_WRITE_DATA) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qed_aio_write_data " "s %p acb %p ret %d offset %"PRIu64" len %zu" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, acb, ret, offset, len);
    }
}

static inline void trace_qed_aio_write_data(void * s, void * acb, int ret, uint64_t offset, size_t len)
{
    if (true) {
        _nocheck__trace_qed_aio_write_data(s, acb, ret, offset, len);
    }
}

#define TRACE_QED_AIO_WRITE_PREFILL_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QED_AIO_WRITE_PREFILL) || \
    false)

static inline void _nocheck__trace_qed_aio_write_prefill(void * s, void * acb, uint64_t start, size_t len, uint64_t offset)
{
    if (trace_event_get_state(TRACE_QED_AIO_WRITE_PREFILL) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qed_aio_write_prefill " "s %p acb %p start %"PRIu64" len %zu offset %"PRIu64 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, acb, start, len, offset);
    }
}

static inline void trace_qed_aio_write_prefill(void * s, void * acb, uint64_t start, size_t len, uint64_t offset)
{
    if (true) {
        _nocheck__trace_qed_aio_write_prefill(s, acb, start, len, offset);
    }
}

#define TRACE_QED_AIO_WRITE_POSTFILL_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QED_AIO_WRITE_POSTFILL) || \
    false)

static inline void _nocheck__trace_qed_aio_write_postfill(void * s, void * acb, uint64_t start, size_t len, uint64_t offset)
{
    if (trace_event_get_state(TRACE_QED_AIO_WRITE_POSTFILL) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qed_aio_write_postfill " "s %p acb %p start %"PRIu64" len %zu offset %"PRIu64 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, acb, start, len, offset);
    }
}

static inline void trace_qed_aio_write_postfill(void * s, void * acb, uint64_t start, size_t len, uint64_t offset)
{
    if (true) {
        _nocheck__trace_qed_aio_write_postfill(s, acb, start, len, offset);
    }
}

#define TRACE_QED_AIO_WRITE_MAIN_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_QED_AIO_WRITE_MAIN) || \
    false)

static inline void _nocheck__trace_qed_aio_write_main(void * s, void * acb, int ret, uint64_t offset, size_t len)
{
    if (trace_event_get_state(TRACE_QED_AIO_WRITE_MAIN) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:qed_aio_write_main " "s %p acb %p ret %d offset %"PRIu64" len %zu" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, acb, ret, offset, len);
    }
}

static inline void trace_qed_aio_write_main(void * s, void * acb, int ret, uint64_t offset, size_t len)
{
    if (true) {
        _nocheck__trace_qed_aio_write_main(s, acb, ret, offset, len);
    }
}

#define TRACE_NVME_CONTROLLER_CAPABILITY_RAW_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_CONTROLLER_CAPABILITY_RAW) || \
    false)

static inline void _nocheck__trace_nvme_controller_capability_raw(uint64_t value)
{
    if (trace_event_get_state(TRACE_NVME_CONTROLLER_CAPABILITY_RAW) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_controller_capability_raw " "0x%08"PRIx64 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , value);
    }
}

static inline void trace_nvme_controller_capability_raw(uint64_t value)
{
    if (true) {
        _nocheck__trace_nvme_controller_capability_raw(value);
    }
}

#define TRACE_NVME_CONTROLLER_CAPABILITY_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_CONTROLLER_CAPABILITY) || \
    false)

static inline void _nocheck__trace_nvme_controller_capability(const char * desc, uint64_t value)
{
    if (trace_event_get_state(TRACE_NVME_CONTROLLER_CAPABILITY) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_controller_capability " "%s: %"PRIu64 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , desc, value);
    }
}

static inline void trace_nvme_controller_capability(const char * desc, uint64_t value)
{
    if (true) {
        _nocheck__trace_nvme_controller_capability(desc, value);
    }
}

#define TRACE_NVME_KICK_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_KICK) || \
    false)

static inline void _nocheck__trace_nvme_kick(void * s, unsigned q_index)
{
    if (trace_event_get_state(TRACE_NVME_KICK) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_kick " "s %p q #%u" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, q_index);
    }
}

static inline void trace_nvme_kick(void * s, unsigned q_index)
{
    if (true) {
        _nocheck__trace_nvme_kick(s, q_index);
    }
}

#define TRACE_NVME_DMA_FLUSH_QUEUE_WAIT_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_DMA_FLUSH_QUEUE_WAIT) || \
    false)

static inline void _nocheck__trace_nvme_dma_flush_queue_wait(void * s)
{
    if (trace_event_get_state(TRACE_NVME_DMA_FLUSH_QUEUE_WAIT) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_dma_flush_queue_wait " "s %p" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s);
    }
}

static inline void trace_nvme_dma_flush_queue_wait(void * s)
{
    if (true) {
        _nocheck__trace_nvme_dma_flush_queue_wait(s);
    }
}

#define TRACE_NVME_ERROR_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_ERROR) || \
    false)

static inline void _nocheck__trace_nvme_error(int cmd_specific, int sq_head, int sqid, int cid, int status)
{
    if (trace_event_get_state(TRACE_NVME_ERROR) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_error " "cmd_specific %d sq_head %d sqid %d cid %d status 0x%x" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , cmd_specific, sq_head, sqid, cid, status);
    }
}

static inline void trace_nvme_error(int cmd_specific, int sq_head, int sqid, int cid, int status)
{
    if (true) {
        _nocheck__trace_nvme_error(cmd_specific, sq_head, sqid, cid, status);
    }
}

#define TRACE_NVME_PROCESS_COMPLETION_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_PROCESS_COMPLETION) || \
    false)

static inline void _nocheck__trace_nvme_process_completion(void * s, unsigned q_index, int inflight)
{
    if (trace_event_get_state(TRACE_NVME_PROCESS_COMPLETION) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_process_completion " "s %p q #%u inflight %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, q_index, inflight);
    }
}

static inline void trace_nvme_process_completion(void * s, unsigned q_index, int inflight)
{
    if (true) {
        _nocheck__trace_nvme_process_completion(s, q_index, inflight);
    }
}

#define TRACE_NVME_PROCESS_COMPLETION_QUEUE_PLUGGED_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_PROCESS_COMPLETION_QUEUE_PLUGGED) || \
    false)

static inline void _nocheck__trace_nvme_process_completion_queue_plugged(void * s, unsigned q_index)
{
    if (trace_event_get_state(TRACE_NVME_PROCESS_COMPLETION_QUEUE_PLUGGED) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_process_completion_queue_plugged " "s %p q #%u" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, q_index);
    }
}

static inline void trace_nvme_process_completion_queue_plugged(void * s, unsigned q_index)
{
    if (true) {
        _nocheck__trace_nvme_process_completion_queue_plugged(s, q_index);
    }
}

#define TRACE_NVME_COMPLETE_COMMAND_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_COMPLETE_COMMAND) || \
    false)

static inline void _nocheck__trace_nvme_complete_command(void * s, unsigned q_index, int cid)
{
    if (trace_event_get_state(TRACE_NVME_COMPLETE_COMMAND) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_complete_command " "s %p q #%u cid %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, q_index, cid);
    }
}

static inline void trace_nvme_complete_command(void * s, unsigned q_index, int cid)
{
    if (true) {
        _nocheck__trace_nvme_complete_command(s, q_index, cid);
    }
}

#define TRACE_NVME_SUBMIT_COMMAND_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_SUBMIT_COMMAND) || \
    false)

static inline void _nocheck__trace_nvme_submit_command(void * s, unsigned q_index, int cid)
{
    if (trace_event_get_state(TRACE_NVME_SUBMIT_COMMAND) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_submit_command " "s %p q #%u cid %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, q_index, cid);
    }
}

static inline void trace_nvme_submit_command(void * s, unsigned q_index, int cid)
{
    if (true) {
        _nocheck__trace_nvme_submit_command(s, q_index, cid);
    }
}

#define TRACE_NVME_SUBMIT_COMMAND_RAW_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_SUBMIT_COMMAND_RAW) || \
    false)

static inline void _nocheck__trace_nvme_submit_command_raw(int c0, int c1, int c2, int c3, int c4, int c5, int c6, int c7)
{
    if (trace_event_get_state(TRACE_NVME_SUBMIT_COMMAND_RAW) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_submit_command_raw " "%02x %02x %02x %02x %02x %02x %02x %02x" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , c0, c1, c2, c3, c4, c5, c6, c7);
    }
}

static inline void trace_nvme_submit_command_raw(int c0, int c1, int c2, int c3, int c4, int c5, int c6, int c7)
{
    if (true) {
        _nocheck__trace_nvme_submit_command_raw(c0, c1, c2, c3, c4, c5, c6, c7);
    }
}

#define TRACE_NVME_HANDLE_EVENT_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_HANDLE_EVENT) || \
    false)

static inline void _nocheck__trace_nvme_handle_event(void * s)
{
    if (trace_event_get_state(TRACE_NVME_HANDLE_EVENT) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_handle_event " "s %p" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s);
    }
}

static inline void trace_nvme_handle_event(void * s)
{
    if (true) {
        _nocheck__trace_nvme_handle_event(s);
    }
}

#define TRACE_NVME_POLL_QUEUE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_POLL_QUEUE) || \
    false)

static inline void _nocheck__trace_nvme_poll_queue(void * s, unsigned q_index)
{
    if (trace_event_get_state(TRACE_NVME_POLL_QUEUE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_poll_queue " "s %p q #%u" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, q_index);
    }
}

static inline void trace_nvme_poll_queue(void * s, unsigned q_index)
{
    if (true) {
        _nocheck__trace_nvme_poll_queue(s, q_index);
    }
}

#define TRACE_NVME_PRW_ALIGNED_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_PRW_ALIGNED) || \
    false)

static inline void _nocheck__trace_nvme_prw_aligned(void * s, int is_write, uint64_t offset, uint64_t bytes, int flags, int niov)
{
    if (trace_event_get_state(TRACE_NVME_PRW_ALIGNED) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_prw_aligned " "s %p is_write %d offset 0x%"PRIx64" bytes %"PRId64" flags %d niov %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, is_write, offset, bytes, flags, niov);
    }
}

static inline void trace_nvme_prw_aligned(void * s, int is_write, uint64_t offset, uint64_t bytes, int flags, int niov)
{
    if (true) {
        _nocheck__trace_nvme_prw_aligned(s, is_write, offset, bytes, flags, niov);
    }
}

#define TRACE_NVME_WRITE_ZEROES_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_WRITE_ZEROES) || \
    false)

static inline void _nocheck__trace_nvme_write_zeroes(void * s, uint64_t offset, uint64_t bytes, int flags)
{
    if (trace_event_get_state(TRACE_NVME_WRITE_ZEROES) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_write_zeroes " "s %p offset 0x%"PRIx64" bytes %"PRId64" flags %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, offset, bytes, flags);
    }
}

static inline void trace_nvme_write_zeroes(void * s, uint64_t offset, uint64_t bytes, int flags)
{
    if (true) {
        _nocheck__trace_nvme_write_zeroes(s, offset, bytes, flags);
    }
}

#define TRACE_NVME_QIOV_UNALIGNED_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_QIOV_UNALIGNED) || \
    false)

static inline void _nocheck__trace_nvme_qiov_unaligned(const void * qiov, int n, void * base, size_t size, int align)
{
    if (trace_event_get_state(TRACE_NVME_QIOV_UNALIGNED) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_qiov_unaligned " "qiov %p n %d base %p size 0x%zx align 0x%x" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , qiov, n, base, size, align);
    }
}

static inline void trace_nvme_qiov_unaligned(const void * qiov, int n, void * base, size_t size, int align)
{
    if (true) {
        _nocheck__trace_nvme_qiov_unaligned(qiov, n, base, size, align);
    }
}

#define TRACE_NVME_PRW_BUFFERED_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_PRW_BUFFERED) || \
    false)

static inline void _nocheck__trace_nvme_prw_buffered(void * s, uint64_t offset, uint64_t bytes, int niov, int is_write)
{
    if (trace_event_get_state(TRACE_NVME_PRW_BUFFERED) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_prw_buffered " "s %p offset 0x%"PRIx64" bytes %"PRId64" niov %d is_write %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, offset, bytes, niov, is_write);
    }
}

static inline void trace_nvme_prw_buffered(void * s, uint64_t offset, uint64_t bytes, int niov, int is_write)
{
    if (true) {
        _nocheck__trace_nvme_prw_buffered(s, offset, bytes, niov, is_write);
    }
}

#define TRACE_NVME_RW_DONE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_RW_DONE) || \
    false)

static inline void _nocheck__trace_nvme_rw_done(void * s, int is_write, uint64_t offset, uint64_t bytes, int ret)
{
    if (trace_event_get_state(TRACE_NVME_RW_DONE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_rw_done " "s %p is_write %d offset 0x%"PRIx64" bytes %"PRId64" ret %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, is_write, offset, bytes, ret);
    }
}

static inline void trace_nvme_rw_done(void * s, int is_write, uint64_t offset, uint64_t bytes, int ret)
{
    if (true) {
        _nocheck__trace_nvme_rw_done(s, is_write, offset, bytes, ret);
    }
}

#define TRACE_NVME_DSM_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_DSM) || \
    false)

static inline void _nocheck__trace_nvme_dsm(void * s, uint64_t offset, uint64_t bytes)
{
    if (trace_event_get_state(TRACE_NVME_DSM) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_dsm " "s %p offset 0x%"PRIx64" bytes %"PRId64"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, offset, bytes);
    }
}

static inline void trace_nvme_dsm(void * s, uint64_t offset, uint64_t bytes)
{
    if (true) {
        _nocheck__trace_nvme_dsm(s, offset, bytes);
    }
}

#define TRACE_NVME_DSM_DONE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_DSM_DONE) || \
    false)

static inline void _nocheck__trace_nvme_dsm_done(void * s, uint64_t offset, uint64_t bytes, int ret)
{
    if (trace_event_get_state(TRACE_NVME_DSM_DONE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_dsm_done " "s %p offset 0x%"PRIx64" bytes %"PRId64" ret %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, offset, bytes, ret);
    }
}

static inline void trace_nvme_dsm_done(void * s, uint64_t offset, uint64_t bytes, int ret)
{
    if (true) {
        _nocheck__trace_nvme_dsm_done(s, offset, bytes, ret);
    }
}

#define TRACE_NVME_DMA_MAP_FLUSH_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_DMA_MAP_FLUSH) || \
    false)

static inline void _nocheck__trace_nvme_dma_map_flush(void * s)
{
    if (trace_event_get_state(TRACE_NVME_DMA_MAP_FLUSH) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_dma_map_flush " "s %p" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s);
    }
}

static inline void trace_nvme_dma_map_flush(void * s)
{
    if (true) {
        _nocheck__trace_nvme_dma_map_flush(s);
    }
}

#define TRACE_NVME_FREE_REQ_QUEUE_WAIT_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_FREE_REQ_QUEUE_WAIT) || \
    false)

static inline void _nocheck__trace_nvme_free_req_queue_wait(void * s, unsigned q_index)
{
    if (trace_event_get_state(TRACE_NVME_FREE_REQ_QUEUE_WAIT) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_free_req_queue_wait " "s %p q #%u" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, q_index);
    }
}

static inline void trace_nvme_free_req_queue_wait(void * s, unsigned q_index)
{
    if (true) {
        _nocheck__trace_nvme_free_req_queue_wait(s, q_index);
    }
}

#define TRACE_NVME_CREATE_QUEUE_PAIR_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_CREATE_QUEUE_PAIR) || \
    false)

static inline void _nocheck__trace_nvme_create_queue_pair(unsigned q_index, void * q, unsigned size, void * aio_context, int fd)
{
    if (trace_event_get_state(TRACE_NVME_CREATE_QUEUE_PAIR) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_create_queue_pair " "index %u q %p size %u aioctx %p fd %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , q_index, q, size, aio_context, fd);
    }
}

static inline void trace_nvme_create_queue_pair(unsigned q_index, void * q, unsigned size, void * aio_context, int fd)
{
    if (true) {
        _nocheck__trace_nvme_create_queue_pair(q_index, q, size, aio_context, fd);
    }
}

#define TRACE_NVME_FREE_QUEUE_PAIR_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_FREE_QUEUE_PAIR) || \
    false)

static inline void _nocheck__trace_nvme_free_queue_pair(unsigned q_index, void * q)
{
    if (trace_event_get_state(TRACE_NVME_FREE_QUEUE_PAIR) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_free_queue_pair " "index %u q %p" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , q_index, q);
    }
}

static inline void trace_nvme_free_queue_pair(unsigned q_index, void * q)
{
    if (true) {
        _nocheck__trace_nvme_free_queue_pair(q_index, q);
    }
}

#define TRACE_NVME_CMD_MAP_QIOV_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_CMD_MAP_QIOV) || \
    false)

static inline void _nocheck__trace_nvme_cmd_map_qiov(void * s, void * cmd, void * req, void * qiov, int entries)
{
    if (trace_event_get_state(TRACE_NVME_CMD_MAP_QIOV) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_cmd_map_qiov " "s %p cmd %p req %p qiov %p entries %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, cmd, req, qiov, entries);
    }
}

static inline void trace_nvme_cmd_map_qiov(void * s, void * cmd, void * req, void * qiov, int entries)
{
    if (true) {
        _nocheck__trace_nvme_cmd_map_qiov(s, cmd, req, qiov, entries);
    }
}

#define TRACE_NVME_CMD_MAP_QIOV_PAGES_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_CMD_MAP_QIOV_PAGES) || \
    false)

static inline void _nocheck__trace_nvme_cmd_map_qiov_pages(void * s, int i, uint64_t page)
{
    if (trace_event_get_state(TRACE_NVME_CMD_MAP_QIOV_PAGES) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_cmd_map_qiov_pages " "s %p page[%d] 0x%"PRIx64 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, i, page);
    }
}

static inline void trace_nvme_cmd_map_qiov_pages(void * s, int i, uint64_t page)
{
    if (true) {
        _nocheck__trace_nvme_cmd_map_qiov_pages(s, i, page);
    }
}

#define TRACE_NVME_CMD_MAP_QIOV_IOV_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_CMD_MAP_QIOV_IOV) || \
    false)

static inline void _nocheck__trace_nvme_cmd_map_qiov_iov(void * s, int i, void * page, int pages)
{
    if (trace_event_get_state(TRACE_NVME_CMD_MAP_QIOV_IOV) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_cmd_map_qiov_iov " "s %p iov[%d] %p pages %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, i, page, pages);
    }
}

static inline void trace_nvme_cmd_map_qiov_iov(void * s, int i, void * page, int pages)
{
    if (true) {
        _nocheck__trace_nvme_cmd_map_qiov_iov(s, i, page, pages);
    }
}

#define TRACE_ISCSI_XCOPY_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_ISCSI_XCOPY) || \
    false)

static inline void _nocheck__trace_iscsi_xcopy(void * src_lun, uint64_t src_off, void * dst_lun, uint64_t dst_off, uint64_t bytes, int ret)
{
    if (trace_event_get_state(TRACE_ISCSI_XCOPY) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:iscsi_xcopy " "src_lun %p offset %"PRIu64" dst_lun %p offset %"PRIu64" bytes %"PRIu64" ret %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , src_lun, src_off, dst_lun, dst_off, bytes, ret);
    }
}

static inline void trace_iscsi_xcopy(void * src_lun, uint64_t src_off, void * dst_lun, uint64_t dst_off, uint64_t bytes, int ret)
{
    if (true) {
        _nocheck__trace_iscsi_xcopy(src_lun, src_off, dst_lun, dst_off, bytes, ret);
    }
}

#define TRACE_NBD_PARSE_BLOCKSTATUS_COMPLIANCE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NBD_PARSE_BLOCKSTATUS_COMPLIANCE) || \
    false)

static inline void _nocheck__trace_nbd_parse_blockstatus_compliance(const char * err)
{
    if (trace_event_get_state(TRACE_NBD_PARSE_BLOCKSTATUS_COMPLIANCE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nbd_parse_blockstatus_compliance " "ignoring extra data from non-compliant server: %s" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , err);
    }
}

static inline void trace_nbd_parse_blockstatus_compliance(const char * err)
{
    if (true) {
        _nocheck__trace_nbd_parse_blockstatus_compliance(err);
    }
}

#define TRACE_NBD_STRUCTURED_READ_COMPLIANCE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NBD_STRUCTURED_READ_COMPLIANCE) || \
    false)

static inline void _nocheck__trace_nbd_structured_read_compliance(const char * type)
{
    if (trace_event_get_state(TRACE_NBD_STRUCTURED_READ_COMPLIANCE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nbd_structured_read_compliance " "server sent non-compliant unaligned read %s chunk" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , type);
    }
}

static inline void trace_nbd_structured_read_compliance(const char * type)
{
    if (true) {
        _nocheck__trace_nbd_structured_read_compliance(type);
    }
}

#define TRACE_NBD_READ_REPLY_ENTRY_FAIL_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NBD_READ_REPLY_ENTRY_FAIL) || \
    false)

static inline void _nocheck__trace_nbd_read_reply_entry_fail(int ret, const char * err)
{
    if (trace_event_get_state(TRACE_NBD_READ_REPLY_ENTRY_FAIL) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nbd_read_reply_entry_fail " "ret = %d, err: %s" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , ret, err);
    }
}

static inline void trace_nbd_read_reply_entry_fail(int ret, const char * err)
{
    if (true) {
        _nocheck__trace_nbd_read_reply_entry_fail(ret, err);
    }
}

#define TRACE_NBD_CO_REQUEST_FAIL_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NBD_CO_REQUEST_FAIL) || \
    false)

static inline void _nocheck__trace_nbd_co_request_fail(uint64_t from, uint32_t len, uint64_t handle, uint16_t flags, uint16_t type, const char * name, int ret, const char * err)
{
    if (trace_event_get_state(TRACE_NBD_CO_REQUEST_FAIL) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nbd_co_request_fail " "Request failed { .from = %" PRIu64", .len = %" PRIu32 ", .handle = %" PRIu64 ", .flags = 0x%" PRIx16 ", .type = %" PRIu16 " (%s) } ret = %d, err: %s" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , from, len, handle, flags, type, name, ret, err);
    }
}

static inline void trace_nbd_co_request_fail(uint64_t from, uint32_t len, uint64_t handle, uint16_t flags, uint16_t type, const char * name, int ret, const char * err)
{
    if (true) {
        _nocheck__trace_nbd_co_request_fail(from, len, handle, flags, type, name, ret, err);
    }
}

#define TRACE_NBD_CLIENT_HANDSHAKE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NBD_CLIENT_HANDSHAKE) || \
    false)

static inline void _nocheck__trace_nbd_client_handshake(const char * export_name)
{
    if (trace_event_get_state(TRACE_NBD_CLIENT_HANDSHAKE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nbd_client_handshake " "export '%s'" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , export_name);
    }
}

static inline void trace_nbd_client_handshake(const char * export_name)
{
    if (true) {
        _nocheck__trace_nbd_client_handshake(export_name);
    }
}

#define TRACE_NBD_CLIENT_HANDSHAKE_SUCCESS_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NBD_CLIENT_HANDSHAKE_SUCCESS) || \
    false)

static inline void _nocheck__trace_nbd_client_handshake_success(const char * export_name)
{
    if (trace_event_get_state(TRACE_NBD_CLIENT_HANDSHAKE_SUCCESS) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nbd_client_handshake_success " "export '%s'" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , export_name);
    }
}

static inline void trace_nbd_client_handshake_success(const char * export_name)
{
    if (true) {
        _nocheck__trace_nbd_client_handshake_success(export_name);
    }
}

#define TRACE_SSH_RESTART_COROUTINE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_SSH_RESTART_COROUTINE) || \
    false)

static inline void _nocheck__trace_ssh_restart_coroutine(void * co)
{
    if (trace_event_get_state(TRACE_SSH_RESTART_COROUTINE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:ssh_restart_coroutine " "co=%p" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , co);
    }
}

static inline void trace_ssh_restart_coroutine(void * co)
{
    if (true) {
        _nocheck__trace_ssh_restart_coroutine(co);
    }
}

#define TRACE_SSH_FLUSH_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_SSH_FLUSH) || \
    false)

static inline void _nocheck__trace_ssh_flush(void)
{
    if (trace_event_get_state(TRACE_SSH_FLUSH) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:ssh_flush " "fsync" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_ssh_flush(void)
{
    if (true) {
        _nocheck__trace_ssh_flush();
    }
}

#define TRACE_SSH_CHECK_HOST_KEY_KNOWNHOSTS_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_SSH_CHECK_HOST_KEY_KNOWNHOSTS) || \
    false)

static inline void _nocheck__trace_ssh_check_host_key_knownhosts(void)
{
    if (trace_event_get_state(TRACE_SSH_CHECK_HOST_KEY_KNOWNHOSTS) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:ssh_check_host_key_knownhosts " "host key OK" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_ssh_check_host_key_knownhosts(void)
{
    if (true) {
        _nocheck__trace_ssh_check_host_key_knownhosts();
    }
}

#define TRACE_SSH_CONNECT_TO_SSH_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_SSH_CONNECT_TO_SSH) || \
    false)

static inline void _nocheck__trace_ssh_connect_to_ssh(char * path, int flags, int mode)
{
    if (trace_event_get_state(TRACE_SSH_CONNECT_TO_SSH) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:ssh_connect_to_ssh " "opening file %s flags=0x%x creat_mode=0%o" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , path, flags, mode);
    }
}

static inline void trace_ssh_connect_to_ssh(char * path, int flags, int mode)
{
    if (true) {
        _nocheck__trace_ssh_connect_to_ssh(path, flags, mode);
    }
}

#define TRACE_SSH_CO_YIELD_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_SSH_CO_YIELD) || \
    false)

static inline void _nocheck__trace_ssh_co_yield(int sock, void * rd_handler, void * wr_handler)
{
    if (trace_event_get_state(TRACE_SSH_CO_YIELD) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:ssh_co_yield " "s->sock=%d rd_handler=%p wr_handler=%p" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , sock, rd_handler, wr_handler);
    }
}

static inline void trace_ssh_co_yield(int sock, void * rd_handler, void * wr_handler)
{
    if (true) {
        _nocheck__trace_ssh_co_yield(sock, rd_handler, wr_handler);
    }
}

#define TRACE_SSH_CO_YIELD_BACK_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_SSH_CO_YIELD_BACK) || \
    false)

static inline void _nocheck__trace_ssh_co_yield_back(int sock)
{
    if (trace_event_get_state(TRACE_SSH_CO_YIELD_BACK) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:ssh_co_yield_back " "s->sock=%d - back" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , sock);
    }
}

static inline void trace_ssh_co_yield_back(int sock)
{
    if (true) {
        _nocheck__trace_ssh_co_yield_back(sock);
    }
}

#define TRACE_SSH_GETLENGTH_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_SSH_GETLENGTH) || \
    false)

static inline void _nocheck__trace_ssh_getlength(int64_t length)
{
    if (trace_event_get_state(TRACE_SSH_GETLENGTH) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:ssh_getlength " "length=%" PRIi64 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , length);
    }
}

static inline void trace_ssh_getlength(int64_t length)
{
    if (true) {
        _nocheck__trace_ssh_getlength(length);
    }
}

#define TRACE_SSH_CO_CREATE_OPTS_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_SSH_CO_CREATE_OPTS) || \
    false)

static inline void _nocheck__trace_ssh_co_create_opts(uint64_t size)
{
    if (trace_event_get_state(TRACE_SSH_CO_CREATE_OPTS) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:ssh_co_create_opts " "total_size=%" PRIu64 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , size);
    }
}

static inline void trace_ssh_co_create_opts(uint64_t size)
{
    if (true) {
        _nocheck__trace_ssh_co_create_opts(size);
    }
}

#define TRACE_SSH_READ_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_SSH_READ) || \
    false)

static inline void _nocheck__trace_ssh_read(int64_t offset, size_t size)
{
    if (trace_event_get_state(TRACE_SSH_READ) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:ssh_read " "offset=%" PRIi64 " size=%zu" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , offset, size);
    }
}

static inline void trace_ssh_read(int64_t offset, size_t size)
{
    if (true) {
        _nocheck__trace_ssh_read(offset, size);
    }
}

#define TRACE_SSH_READ_BUF_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_SSH_READ_BUF) || \
    false)

static inline void _nocheck__trace_ssh_read_buf(void * buf, size_t size, size_t actual_size)
{
    if (trace_event_get_state(TRACE_SSH_READ_BUF) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:ssh_read_buf " "sftp_read buf=%p size=%zu (actual size=%zu)" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , buf, size, actual_size);
    }
}

static inline void trace_ssh_read_buf(void * buf, size_t size, size_t actual_size)
{
    if (true) {
        _nocheck__trace_ssh_read_buf(buf, size, actual_size);
    }
}

#define TRACE_SSH_READ_RETURN_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_SSH_READ_RETURN) || \
    false)

static inline void _nocheck__trace_ssh_read_return(ssize_t ret, int sftp_err)
{
    if (trace_event_get_state(TRACE_SSH_READ_RETURN) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:ssh_read_return " "sftp_read returned %zd (sftp error=%d)" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , ret, sftp_err);
    }
}

static inline void trace_ssh_read_return(ssize_t ret, int sftp_err)
{
    if (true) {
        _nocheck__trace_ssh_read_return(ret, sftp_err);
    }
}

#define TRACE_SSH_WRITE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_SSH_WRITE) || \
    false)

static inline void _nocheck__trace_ssh_write(int64_t offset, size_t size)
{
    if (trace_event_get_state(TRACE_SSH_WRITE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:ssh_write " "offset=%" PRIi64 " size=%zu" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , offset, size);
    }
}

static inline void trace_ssh_write(int64_t offset, size_t size)
{
    if (true) {
        _nocheck__trace_ssh_write(offset, size);
    }
}

#define TRACE_SSH_WRITE_BUF_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_SSH_WRITE_BUF) || \
    false)

static inline void _nocheck__trace_ssh_write_buf(void * buf, size_t size, size_t actual_size)
{
    if (trace_event_get_state(TRACE_SSH_WRITE_BUF) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:ssh_write_buf " "sftp_write buf=%p size=%zu (actual size=%zu)" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , buf, size, actual_size);
    }
}

static inline void trace_ssh_write_buf(void * buf, size_t size, size_t actual_size)
{
    if (true) {
        _nocheck__trace_ssh_write_buf(buf, size, actual_size);
    }
}

#define TRACE_SSH_WRITE_RETURN_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_SSH_WRITE_RETURN) || \
    false)

static inline void _nocheck__trace_ssh_write_return(ssize_t ret, int sftp_err)
{
    if (trace_event_get_state(TRACE_SSH_WRITE_RETURN) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:ssh_write_return " "sftp_write returned %zd (sftp error=%d)" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , ret, sftp_err);
    }
}

static inline void trace_ssh_write_return(ssize_t ret, int sftp_err)
{
    if (true) {
        _nocheck__trace_ssh_write_return(ret, sftp_err);
    }
}

#define TRACE_SSH_SEEK_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_SSH_SEEK) || \
    false)

static inline void _nocheck__trace_ssh_seek(int64_t offset)
{
    if (trace_event_get_state(TRACE_SSH_SEEK) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:ssh_seek " "seeking to offset=%" PRIi64 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , offset);
    }
}

static inline void trace_ssh_seek(int64_t offset)
{
    if (true) {
        _nocheck__trace_ssh_seek(offset);
    }
}

#define TRACE_SSH_AUTH_METHODS_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_SSH_AUTH_METHODS) || \
    false)

static inline void _nocheck__trace_ssh_auth_methods(int methods)
{
    if (trace_event_get_state(TRACE_SSH_AUTH_METHODS) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:ssh_auth_methods " "auth methods=0x%x" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , methods);
    }
}

static inline void trace_ssh_auth_methods(int methods)
{
    if (true) {
        _nocheck__trace_ssh_auth_methods(methods);
    }
}

#define TRACE_SSH_SERVER_STATUS_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_SSH_SERVER_STATUS) || \
    false)

static inline void _nocheck__trace_ssh_server_status(int status)
{
    if (trace_event_get_state(TRACE_SSH_SERVER_STATUS) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:ssh_server_status " "server status=%d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , status);
    }
}

static inline void trace_ssh_server_status(int status)
{
    if (true) {
        _nocheck__trace_ssh_server_status(status);
    }
}

#define TRACE_CURL_TIMER_CB_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_CURL_TIMER_CB) || \
    false)

static inline void _nocheck__trace_curl_timer_cb(long timeout_ms)
{
    if (trace_event_get_state(TRACE_CURL_TIMER_CB) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:curl_timer_cb " "timer callback timeout_ms %ld" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , timeout_ms);
    }
}

static inline void trace_curl_timer_cb(long timeout_ms)
{
    if (true) {
        _nocheck__trace_curl_timer_cb(timeout_ms);
    }
}

#define TRACE_CURL_SOCK_CB_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_CURL_SOCK_CB) || \
    false)

static inline void _nocheck__trace_curl_sock_cb(int action, int fd)
{
    if (trace_event_get_state(TRACE_CURL_SOCK_CB) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:curl_sock_cb " "sock action %d on fd %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , action, fd);
    }
}

static inline void trace_curl_sock_cb(int action, int fd)
{
    if (true) {
        _nocheck__trace_curl_sock_cb(action, fd);
    }
}

#define TRACE_CURL_READ_CB_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_CURL_READ_CB) || \
    false)

static inline void _nocheck__trace_curl_read_cb(size_t realsize)
{
    if (trace_event_get_state(TRACE_CURL_READ_CB) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:curl_read_cb " "just reading %zu bytes" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , realsize);
    }
}

static inline void trace_curl_read_cb(size_t realsize)
{
    if (true) {
        _nocheck__trace_curl_read_cb(realsize);
    }
}

#define TRACE_CURL_OPEN_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_CURL_OPEN) || \
    false)

static inline void _nocheck__trace_curl_open(const char * file)
{
    if (trace_event_get_state(TRACE_CURL_OPEN) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:curl_open " "opening %s" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , file);
    }
}

static inline void trace_curl_open(const char * file)
{
    if (true) {
        _nocheck__trace_curl_open(file);
    }
}

#define TRACE_CURL_OPEN_SIZE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_CURL_OPEN_SIZE) || \
    false)

static inline void _nocheck__trace_curl_open_size(uint64_t size)
{
    if (trace_event_get_state(TRACE_CURL_OPEN_SIZE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:curl_open_size " "size = %" PRIu64 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , size);
    }
}

static inline void trace_curl_open_size(uint64_t size)
{
    if (true) {
        _nocheck__trace_curl_open_size(size);
    }
}

#define TRACE_CURL_SETUP_PREADV_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_CURL_SETUP_PREADV) || \
    false)

static inline void _nocheck__trace_curl_setup_preadv(uint64_t bytes, uint64_t start, const char * range)
{
    if (trace_event_get_state(TRACE_CURL_SETUP_PREADV) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:curl_setup_preadv " "reading %" PRIu64 " at %" PRIu64 " (%s)" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , bytes, start, range);
    }
}

static inline void trace_curl_setup_preadv(uint64_t bytes, uint64_t start, const char * range)
{
    if (true) {
        _nocheck__trace_curl_setup_preadv(bytes, start, range);
    }
}

#define TRACE_CURL_CLOSE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_CURL_CLOSE) || \
    false)

static inline void _nocheck__trace_curl_close(void)
{
    if (trace_event_get_state(TRACE_CURL_CLOSE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:curl_close " "close" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_curl_close(void)
{
    if (true) {
        _nocheck__trace_curl_close();
    }
}

#define TRACE_FILE_COPY_FILE_RANGE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_FILE_COPY_FILE_RANGE) || \
    false)

static inline void _nocheck__trace_file_copy_file_range(void * bs, int src, int64_t src_off, int dst, int64_t dst_off, int64_t bytes, int flags, int64_t ret)
{
    if (trace_event_get_state(TRACE_FILE_COPY_FILE_RANGE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:file_copy_file_range " "bs %p src_fd %d offset %"PRIu64" dst_fd %d offset %"PRIu64" bytes %"PRIu64" flags %d ret %"PRId64 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , bs, src, src_off, dst, dst_off, bytes, flags, ret);
    }
}

static inline void trace_file_copy_file_range(void * bs, int src, int64_t src_off, int dst, int64_t dst_off, int64_t bytes, int flags, int64_t ret)
{
    if (true) {
        _nocheck__trace_file_copy_file_range(bs, src, src_off, dst, dst_off, bytes, flags, ret);
    }
}

#define TRACE_FILE_FINDEJECTABLEOPTICALMEDIA_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_FILE_FINDEJECTABLEOPTICALMEDIA) || \
    false)

static inline void _nocheck__trace_file_FindEjectableOpticalMedia(const char * media)
{
    if (trace_event_get_state(TRACE_FILE_FINDEJECTABLEOPTICALMEDIA) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:file_FindEjectableOpticalMedia " "Matching using %s" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , media);
    }
}

static inline void trace_file_FindEjectableOpticalMedia(const char * media)
{
    if (true) {
        _nocheck__trace_file_FindEjectableOpticalMedia(media);
    }
}

#define TRACE_FILE_SETUP_CDROM_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_FILE_SETUP_CDROM) || \
    false)

static inline void _nocheck__trace_file_setup_cdrom(const char * partition)
{
    if (trace_event_get_state(TRACE_FILE_SETUP_CDROM) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:file_setup_cdrom " "Using %s as optical disc" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , partition);
    }
}

static inline void trace_file_setup_cdrom(const char * partition)
{
    if (true) {
        _nocheck__trace_file_setup_cdrom(partition);
    }
}

#define TRACE_FILE_HDEV_IS_SG_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_FILE_HDEV_IS_SG) || \
    false)

static inline void _nocheck__trace_file_hdev_is_sg(int type, int version)
{
    if (trace_event_get_state(TRACE_FILE_HDEV_IS_SG) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:file_hdev_is_sg " "SG device found: type=%d, version=%d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , type, version);
    }
}

static inline void trace_file_hdev_is_sg(int type, int version)
{
    if (true) {
        _nocheck__trace_file_hdev_is_sg(type, version);
    }
}

#define TRACE_SHEEPDOG_RECONNECT_TO_SDOG_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_SHEEPDOG_RECONNECT_TO_SDOG) || \
    false)

static inline void _nocheck__trace_sheepdog_reconnect_to_sdog(void)
{
    if (trace_event_get_state(TRACE_SHEEPDOG_RECONNECT_TO_SDOG) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:sheepdog_reconnect_to_sdog " "Wait for connection to be established" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_sheepdog_reconnect_to_sdog(void)
{
    if (true) {
        _nocheck__trace_sheepdog_reconnect_to_sdog();
    }
}

#define TRACE_SHEEPDOG_AIO_READ_RESPONSE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_SHEEPDOG_AIO_READ_RESPONSE) || \
    false)

static inline void _nocheck__trace_sheepdog_aio_read_response(void)
{
    if (trace_event_get_state(TRACE_SHEEPDOG_AIO_READ_RESPONSE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:sheepdog_aio_read_response " "disable cache since the server doesn't support it" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_sheepdog_aio_read_response(void)
{
    if (true) {
        _nocheck__trace_sheepdog_aio_read_response();
    }
}

#define TRACE_SHEEPDOG_OPEN_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_SHEEPDOG_OPEN) || \
    false)

static inline void _nocheck__trace_sheepdog_open(uint32_t vid)
{
    if (trace_event_get_state(TRACE_SHEEPDOG_OPEN) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:sheepdog_open " "0x%" PRIx32 " snapshot inode was open" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , vid);
    }
}

static inline void trace_sheepdog_open(uint32_t vid)
{
    if (true) {
        _nocheck__trace_sheepdog_open(vid);
    }
}

#define TRACE_SHEEPDOG_CLOSE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_SHEEPDOG_CLOSE) || \
    false)

static inline void _nocheck__trace_sheepdog_close(const char * name)
{
    if (trace_event_get_state(TRACE_SHEEPDOG_CLOSE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:sheepdog_close " "%s" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , name);
    }
}

static inline void trace_sheepdog_close(const char * name)
{
    if (true) {
        _nocheck__trace_sheepdog_close(name);
    }
}

#define TRACE_SHEEPDOG_CREATE_BRANCH_SNAPSHOT_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_SHEEPDOG_CREATE_BRANCH_SNAPSHOT) || \
    false)

static inline void _nocheck__trace_sheepdog_create_branch_snapshot(uint32_t vdi)
{
    if (trace_event_get_state(TRACE_SHEEPDOG_CREATE_BRANCH_SNAPSHOT) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:sheepdog_create_branch_snapshot " "0x%" PRIx32 " is snapshot" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , vdi);
    }
}

static inline void trace_sheepdog_create_branch_snapshot(uint32_t vdi)
{
    if (true) {
        _nocheck__trace_sheepdog_create_branch_snapshot(vdi);
    }
}

#define TRACE_SHEEPDOG_CREATE_BRANCH_CREATED_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_SHEEPDOG_CREATE_BRANCH_CREATED) || \
    false)

static inline void _nocheck__trace_sheepdog_create_branch_created(uint32_t vdi)
{
    if (trace_event_get_state(TRACE_SHEEPDOG_CREATE_BRANCH_CREATED) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:sheepdog_create_branch_created " "0x%" PRIx32 " is created" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , vdi);
    }
}

static inline void trace_sheepdog_create_branch_created(uint32_t vdi)
{
    if (true) {
        _nocheck__trace_sheepdog_create_branch_created(vdi);
    }
}

#define TRACE_SHEEPDOG_CREATE_BRANCH_NEW_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_SHEEPDOG_CREATE_BRANCH_NEW) || \
    false)

static inline void _nocheck__trace_sheepdog_create_branch_new(uint32_t vdi)
{
    if (trace_event_get_state(TRACE_SHEEPDOG_CREATE_BRANCH_NEW) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:sheepdog_create_branch_new " "0x%" PRIx32 " was newly created" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , vdi);
    }
}

static inline void trace_sheepdog_create_branch_new(uint32_t vdi)
{
    if (true) {
        _nocheck__trace_sheepdog_create_branch_new(vdi);
    }
}

#define TRACE_SHEEPDOG_CO_RW_VECTOR_UPDATE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_SHEEPDOG_CO_RW_VECTOR_UPDATE) || \
    false)

static inline void _nocheck__trace_sheepdog_co_rw_vector_update(uint32_t vdi, uint64_t oid, uint64_t data, long idx)
{
    if (trace_event_get_state(TRACE_SHEEPDOG_CO_RW_VECTOR_UPDATE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:sheepdog_co_rw_vector_update " "update ino (%" PRIu32 ") %" PRIu64 " %" PRIu64 " %ld" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , vdi, oid, data, idx);
    }
}

static inline void trace_sheepdog_co_rw_vector_update(uint32_t vdi, uint64_t oid, uint64_t data, long idx)
{
    if (true) {
        _nocheck__trace_sheepdog_co_rw_vector_update(vdi, oid, data, idx);
    }
}

#define TRACE_SHEEPDOG_CO_RW_VECTOR_NEW_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_SHEEPDOG_CO_RW_VECTOR_NEW) || \
    false)

static inline void _nocheck__trace_sheepdog_co_rw_vector_new(uint64_t oid)
{
    if (trace_event_get_state(TRACE_SHEEPDOG_CO_RW_VECTOR_NEW) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:sheepdog_co_rw_vector_new " "new oid 0x%" PRIx64 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , oid);
    }
}

static inline void trace_sheepdog_co_rw_vector_new(uint64_t oid)
{
    if (true) {
        _nocheck__trace_sheepdog_co_rw_vector_new(oid);
    }
}

#define TRACE_SHEEPDOG_SNAPSHOT_CREATE_INFO_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_SHEEPDOG_SNAPSHOT_CREATE_INFO) || \
    false)

static inline void _nocheck__trace_sheepdog_snapshot_create_info(const char * sn_name, const char * id, const char * name, int64_t size, int is_snapshot)
{
    if (trace_event_get_state(TRACE_SHEEPDOG_SNAPSHOT_CREATE_INFO) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:sheepdog_snapshot_create_info " "sn_info: name %s id_str %s s: name %s vm_state_size %" PRId64 " " "is_snapshot %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , sn_name, id, name, size, is_snapshot);
    }
}

static inline void trace_sheepdog_snapshot_create_info(const char * sn_name, const char * id, const char * name, int64_t size, int is_snapshot)
{
    if (true) {
        _nocheck__trace_sheepdog_snapshot_create_info(sn_name, id, name, size, is_snapshot);
    }
}

#define TRACE_SHEEPDOG_SNAPSHOT_CREATE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_SHEEPDOG_SNAPSHOT_CREATE) || \
    false)

static inline void _nocheck__trace_sheepdog_snapshot_create(const char * sn_name, const char * id)
{
    if (trace_event_get_state(TRACE_SHEEPDOG_SNAPSHOT_CREATE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:sheepdog_snapshot_create " "%s %s" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , sn_name, id);
    }
}

static inline void trace_sheepdog_snapshot_create(const char * sn_name, const char * id)
{
    if (true) {
        _nocheck__trace_sheepdog_snapshot_create(sn_name, id);
    }
}

#define TRACE_SHEEPDOG_SNAPSHOT_CREATE_INODE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_SHEEPDOG_SNAPSHOT_CREATE_INODE) || \
    false)

static inline void _nocheck__trace_sheepdog_snapshot_create_inode(const char * name, uint32_t snap, uint32_t vdi)
{
    if (trace_event_get_state(TRACE_SHEEPDOG_SNAPSHOT_CREATE_INODE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:sheepdog_snapshot_create_inode " "s->inode: name %s snap_id 0x%" PRIx32 " vdi 0x%" PRIx32 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , name, snap, vdi);
    }
}

static inline void trace_sheepdog_snapshot_create_inode(const char * name, uint32_t snap, uint32_t vdi)
{
    if (true) {
        _nocheck__trace_sheepdog_snapshot_create_inode(name, snap, vdi);
    }
}

#define TRACE_SFTP_ERROR_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_SFTP_ERROR) || \
    false)

static inline void _nocheck__trace_sftp_error(const char * op, const char * ssh_err, int ssh_err_code, int sftp_err_code)
{
    if (trace_event_get_state(TRACE_SFTP_ERROR) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:sftp_error " "%s failed: %s (libssh error code: %d, sftp error code: %d)" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , op, ssh_err, ssh_err_code, sftp_err_code);
    }
}

static inline void trace_sftp_error(const char * op, const char * ssh_err, int ssh_err_code, int sftp_err_code)
{
    if (true) {
        _nocheck__trace_sftp_error(op, ssh_err, ssh_err_code, sftp_err_code);
    }
}
#endif /* TRACE_BLOCK_GENERATED_TRACERS_H */
