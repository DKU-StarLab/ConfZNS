/* This file is autogenerated by tracetool, do not edit. */

#ifndef TRACE_HW_BLOCK_GENERATED_TRACERS_H
#define TRACE_HW_BLOCK_GENERATED_TRACERS_H

#include "trace/control.h"

extern TraceEvent _TRACE_FDC_IOPORT_READ_EVENT;
extern TraceEvent _TRACE_FDC_IOPORT_WRITE_EVENT;
extern TraceEvent _TRACE_PFLASH_RESET_EVENT;
extern TraceEvent _TRACE_PFLASH_TIMER_EXPIRED_EVENT;
extern TraceEvent _TRACE_PFLASH_IO_READ_EVENT;
extern TraceEvent _TRACE_PFLASH_IO_WRITE_EVENT;
extern TraceEvent _TRACE_PFLASH_DATA_READ_EVENT;
extern TraceEvent _TRACE_PFLASH_DATA_WRITE_EVENT;
extern TraceEvent _TRACE_PFLASH_MANUFACTURER_ID_EVENT;
extern TraceEvent _TRACE_PFLASH_DEVICE_ID_EVENT;
extern TraceEvent _TRACE_PFLASH_DEVICE_INFO_EVENT;
extern TraceEvent _TRACE_VIRTIO_BLK_REQ_COMPLETE_EVENT;
extern TraceEvent _TRACE_VIRTIO_BLK_RW_COMPLETE_EVENT;
extern TraceEvent _TRACE_VIRTIO_BLK_HANDLE_WRITE_EVENT;
extern TraceEvent _TRACE_VIRTIO_BLK_HANDLE_READ_EVENT;
extern TraceEvent _TRACE_VIRTIO_BLK_SUBMIT_MULTIREQ_EVENT;
extern TraceEvent _TRACE_HD_GEOMETRY_LCHS_GUESS_EVENT;
extern TraceEvent _TRACE_HD_GEOMETRY_GUESS_EVENT;
extern TraceEvent _TRACE_PCI_NVME_REGISTER_NAMESPACE_EVENT;
extern TraceEvent _TRACE_PCI_NVME_IRQ_MSIX_EVENT;
extern TraceEvent _TRACE_PCI_NVME_IRQ_PIN_EVENT;
extern TraceEvent _TRACE_PCI_NVME_IRQ_MASKED_EVENT;
extern TraceEvent _TRACE_PCI_NVME_DMA_READ_EVENT;
extern TraceEvent _TRACE_PCI_NVME_MAP_ADDR_EVENT;
extern TraceEvent _TRACE_PCI_NVME_MAP_ADDR_CMB_EVENT;
extern TraceEvent _TRACE_PCI_NVME_MAP_PRP_EVENT;
extern TraceEvent _TRACE_PCI_NVME_MAP_SGL_EVENT;
extern TraceEvent _TRACE_PCI_NVME_IO_CMD_EVENT;
extern TraceEvent _TRACE_PCI_NVME_ADMIN_CMD_EVENT;
extern TraceEvent _TRACE_PCI_NVME_RW_EVENT;
extern TraceEvent _TRACE_PCI_NVME_RW_CB_EVENT;
extern TraceEvent _TRACE_PCI_NVME_WRITE_ZEROES_EVENT;
extern TraceEvent _TRACE_PCI_NVME_CREATE_SQ_EVENT;
extern TraceEvent _TRACE_PCI_NVME_CREATE_CQ_EVENT;
extern TraceEvent _TRACE_PCI_NVME_DEL_SQ_EVENT;
extern TraceEvent _TRACE_PCI_NVME_DEL_CQ_EVENT;
extern TraceEvent _TRACE_PCI_NVME_IDENTIFY_CTRL_EVENT;
extern TraceEvent _TRACE_PCI_NVME_IDENTIFY_NS_EVENT;
extern TraceEvent _TRACE_PCI_NVME_IDENTIFY_NSLIST_EVENT;
extern TraceEvent _TRACE_PCI_NVME_IDENTIFY_NS_DESCR_LIST_EVENT;
extern TraceEvent _TRACE_PCI_NVME_GET_LOG_EVENT;
extern TraceEvent _TRACE_PCI_NVME_GETFEAT_EVENT;
extern TraceEvent _TRACE_PCI_NVME_SETFEAT_EVENT;
extern TraceEvent _TRACE_PCI_NVME_GETFEAT_VWCACHE_EVENT;
extern TraceEvent _TRACE_PCI_NVME_GETFEAT_NUMQ_EVENT;
extern TraceEvent _TRACE_PCI_NVME_SETFEAT_NUMQ_EVENT;
extern TraceEvent _TRACE_PCI_NVME_SETFEAT_TIMESTAMP_EVENT;
extern TraceEvent _TRACE_PCI_NVME_GETFEAT_TIMESTAMP_EVENT;
extern TraceEvent _TRACE_PCI_NVME_PROCESS_AERS_EVENT;
extern TraceEvent _TRACE_PCI_NVME_AER_EVENT;
extern TraceEvent _TRACE_PCI_NVME_AER_AERL_EXCEEDED_EVENT;
extern TraceEvent _TRACE_PCI_NVME_AER_MASKED_EVENT;
extern TraceEvent _TRACE_PCI_NVME_AER_POST_CQE_EVENT;
extern TraceEvent _TRACE_PCI_NVME_ENQUEUE_EVENT_EVENT;
extern TraceEvent _TRACE_PCI_NVME_ENQUEUE_EVENT_NOQUEUE_EVENT;
extern TraceEvent _TRACE_PCI_NVME_ENQUEUE_EVENT_MASKED_EVENT;
extern TraceEvent _TRACE_PCI_NVME_NO_OUTSTANDING_AERS_EVENT;
extern TraceEvent _TRACE_PCI_NVME_ENQUEUE_REQ_COMPLETION_EVENT;
extern TraceEvent _TRACE_PCI_NVME_MMIO_READ_EVENT;
extern TraceEvent _TRACE_PCI_NVME_MMIO_WRITE_EVENT;
extern TraceEvent _TRACE_PCI_NVME_MMIO_DOORBELL_CQ_EVENT;
extern TraceEvent _TRACE_PCI_NVME_MMIO_DOORBELL_SQ_EVENT;
extern TraceEvent _TRACE_PCI_NVME_MMIO_INTM_SET_EVENT;
extern TraceEvent _TRACE_PCI_NVME_MMIO_INTM_CLR_EVENT;
extern TraceEvent _TRACE_PCI_NVME_MMIO_CFG_EVENT;
extern TraceEvent _TRACE_PCI_NVME_MMIO_AQATTR_EVENT;
extern TraceEvent _TRACE_PCI_NVME_MMIO_ASQADDR_EVENT;
extern TraceEvent _TRACE_PCI_NVME_MMIO_ACQADDR_EVENT;
extern TraceEvent _TRACE_PCI_NVME_MMIO_ASQADDR_HI_EVENT;
extern TraceEvent _TRACE_PCI_NVME_MMIO_ACQADDR_HI_EVENT;
extern TraceEvent _TRACE_PCI_NVME_MMIO_START_SUCCESS_EVENT;
extern TraceEvent _TRACE_PCI_NVME_MMIO_STOPPED_EVENT;
extern TraceEvent _TRACE_PCI_NVME_MMIO_SHUTDOWN_SET_EVENT;
extern TraceEvent _TRACE_PCI_NVME_MMIO_SHUTDOWN_CLEARED_EVENT;
extern TraceEvent _TRACE_PCI_NVME_ERR_MDTS_EVENT;
extern TraceEvent _TRACE_PCI_NVME_ERR_REQ_STATUS_EVENT;
extern TraceEvent _TRACE_PCI_NVME_ERR_ADDR_READ_EVENT;
extern TraceEvent _TRACE_PCI_NVME_ERR_ADDR_WRITE_EVENT;
extern TraceEvent _TRACE_PCI_NVME_ERR_CFS_EVENT;
extern TraceEvent _TRACE_PCI_NVME_ERR_AIO_EVENT;
extern TraceEvent _TRACE_PCI_NVME_ERR_INVALID_SGLD_EVENT;
extern TraceEvent _TRACE_PCI_NVME_ERR_INVALID_NUM_SGLD_EVENT;
extern TraceEvent _TRACE_PCI_NVME_ERR_INVALID_SGL_EXCESS_LENGTH_EVENT;
extern TraceEvent _TRACE_PCI_NVME_ERR_INVALID_DMA_EVENT;
extern TraceEvent _TRACE_PCI_NVME_ERR_INVALID_PRPLIST_ENT_EVENT;
extern TraceEvent _TRACE_PCI_NVME_ERR_INVALID_PRP2_ALIGN_EVENT;
extern TraceEvent _TRACE_PCI_NVME_ERR_INVALID_OPC_EVENT;
extern TraceEvent _TRACE_PCI_NVME_ERR_INVALID_ADMIN_OPC_EVENT;
extern TraceEvent _TRACE_PCI_NVME_ERR_INVALID_LBA_RANGE_EVENT;
extern TraceEvent _TRACE_PCI_NVME_ERR_INVALID_DEL_SQ_EVENT;
extern TraceEvent _TRACE_PCI_NVME_ERR_INVALID_CREATE_SQ_CQID_EVENT;
extern TraceEvent _TRACE_PCI_NVME_ERR_INVALID_CREATE_SQ_SQID_EVENT;
extern TraceEvent _TRACE_PCI_NVME_ERR_INVALID_CREATE_SQ_SIZE_EVENT;
extern TraceEvent _TRACE_PCI_NVME_ERR_INVALID_CREATE_SQ_ADDR_EVENT;
extern TraceEvent _TRACE_PCI_NVME_ERR_INVALID_CREATE_SQ_QFLAGS_EVENT;
extern TraceEvent _TRACE_PCI_NVME_ERR_INVALID_DEL_CQ_CQID_EVENT;
extern TraceEvent _TRACE_PCI_NVME_ERR_INVALID_DEL_CQ_NOTEMPTY_EVENT;
extern TraceEvent _TRACE_PCI_NVME_ERR_INVALID_CREATE_CQ_CQID_EVENT;
extern TraceEvent _TRACE_PCI_NVME_ERR_INVALID_CREATE_CQ_SIZE_EVENT;
extern TraceEvent _TRACE_PCI_NVME_ERR_INVALID_CREATE_CQ_ADDR_EVENT;
extern TraceEvent _TRACE_PCI_NVME_ERR_INVALID_CREATE_CQ_VECTOR_EVENT;
extern TraceEvent _TRACE_PCI_NVME_ERR_INVALID_CREATE_CQ_QFLAGS_EVENT;
extern TraceEvent _TRACE_PCI_NVME_ERR_INVALID_IDENTIFY_CNS_EVENT;
extern TraceEvent _TRACE_PCI_NVME_ERR_INVALID_GETFEAT_EVENT;
extern TraceEvent _TRACE_PCI_NVME_ERR_INVALID_SETFEAT_EVENT;
extern TraceEvent _TRACE_PCI_NVME_ERR_INVALID_LOG_PAGE_EVENT;
extern TraceEvent _TRACE_PCI_NVME_ERR_STARTFAIL_CQ_EVENT;
extern TraceEvent _TRACE_PCI_NVME_ERR_STARTFAIL_SQ_EVENT;
extern TraceEvent _TRACE_PCI_NVME_ERR_STARTFAIL_NBARASQ_EVENT;
extern TraceEvent _TRACE_PCI_NVME_ERR_STARTFAIL_NBARACQ_EVENT;
extern TraceEvent _TRACE_PCI_NVME_ERR_STARTFAIL_ASQ_MISALIGNED_EVENT;
extern TraceEvent _TRACE_PCI_NVME_ERR_STARTFAIL_ACQ_MISALIGNED_EVENT;
extern TraceEvent _TRACE_PCI_NVME_ERR_STARTFAIL_PAGE_TOO_SMALL_EVENT;
extern TraceEvent _TRACE_PCI_NVME_ERR_STARTFAIL_PAGE_TOO_LARGE_EVENT;
extern TraceEvent _TRACE_PCI_NVME_ERR_STARTFAIL_CQENT_TOO_SMALL_EVENT;
extern TraceEvent _TRACE_PCI_NVME_ERR_STARTFAIL_CQENT_TOO_LARGE_EVENT;
extern TraceEvent _TRACE_PCI_NVME_ERR_STARTFAIL_SQENT_TOO_SMALL_EVENT;
extern TraceEvent _TRACE_PCI_NVME_ERR_STARTFAIL_SQENT_TOO_LARGE_EVENT;
extern TraceEvent _TRACE_PCI_NVME_ERR_STARTFAIL_CSS_EVENT;
extern TraceEvent _TRACE_PCI_NVME_ERR_STARTFAIL_ASQENT_SZ_ZERO_EVENT;
extern TraceEvent _TRACE_PCI_NVME_ERR_STARTFAIL_ACQENT_SZ_ZERO_EVENT;
extern TraceEvent _TRACE_PCI_NVME_ERR_STARTFAIL_EVENT;
extern TraceEvent _TRACE_PCI_NVME_UB_MMIOWR_MISALIGNED32_EVENT;
extern TraceEvent _TRACE_PCI_NVME_UB_MMIOWR_TOOSMALL_EVENT;
extern TraceEvent _TRACE_PCI_NVME_UB_MMIOWR_INTMASK_WITH_MSIX_EVENT;
extern TraceEvent _TRACE_PCI_NVME_UB_MMIOWR_RO_CSTS_EVENT;
extern TraceEvent _TRACE_PCI_NVME_UB_MMIOWR_SSRESET_W1C_UNSUPPORTED_EVENT;
extern TraceEvent _TRACE_PCI_NVME_UB_MMIOWR_SSRESET_UNSUPPORTED_EVENT;
extern TraceEvent _TRACE_PCI_NVME_UB_MMIOWR_CMBLOC_RESERVED_EVENT;
extern TraceEvent _TRACE_PCI_NVME_UB_MMIOWR_CMBSZ_READONLY_EVENT;
extern TraceEvent _TRACE_PCI_NVME_UB_MMIOWR_PMRCAP_READONLY_EVENT;
extern TraceEvent _TRACE_PCI_NVME_UB_MMIOWR_PMRSTS_READONLY_EVENT;
extern TraceEvent _TRACE_PCI_NVME_UB_MMIOWR_PMREBS_READONLY_EVENT;
extern TraceEvent _TRACE_PCI_NVME_UB_MMIOWR_PMRSWTP_READONLY_EVENT;
extern TraceEvent _TRACE_PCI_NVME_UB_MMIOWR_INVALID_EVENT;
extern TraceEvent _TRACE_PCI_NVME_UB_MMIORD_MISALIGNED32_EVENT;
extern TraceEvent _TRACE_PCI_NVME_UB_MMIORD_TOOSMALL_EVENT;
extern TraceEvent _TRACE_PCI_NVME_UB_MMIORD_INVALID_OFS_EVENT;
extern TraceEvent _TRACE_PCI_NVME_UB_DB_WR_MISALIGNED_EVENT;
extern TraceEvent _TRACE_PCI_NVME_UB_DB_WR_INVALID_CQ_EVENT;
extern TraceEvent _TRACE_PCI_NVME_UB_DB_WR_INVALID_CQHEAD_EVENT;
extern TraceEvent _TRACE_PCI_NVME_UB_DB_WR_INVALID_SQ_EVENT;
extern TraceEvent _TRACE_PCI_NVME_UB_DB_WR_INVALID_SQTAIL_EVENT;
extern TraceEvent _TRACE_XEN_BLOCK_REALIZE_EVENT;
extern TraceEvent _TRACE_XEN_BLOCK_CONNECT_EVENT;
extern TraceEvent _TRACE_XEN_BLOCK_DISCONNECT_EVENT;
extern TraceEvent _TRACE_XEN_BLOCK_UNREALIZE_EVENT;
extern TraceEvent _TRACE_XEN_BLOCK_SIZE_EVENT;
extern TraceEvent _TRACE_XEN_DISK_REALIZE_EVENT;
extern TraceEvent _TRACE_XEN_DISK_UNREALIZE_EVENT;
extern TraceEvent _TRACE_XEN_CDROM_REALIZE_EVENT;
extern TraceEvent _TRACE_XEN_CDROM_UNREALIZE_EVENT;
extern TraceEvent _TRACE_XEN_BLOCK_BLOCKDEV_ADD_EVENT;
extern TraceEvent _TRACE_XEN_BLOCK_BLOCKDEV_DEL_EVENT;
extern TraceEvent _TRACE_XEN_BLOCK_DEVICE_CREATE_EVENT;
extern TraceEvent _TRACE_XEN_BLOCK_DEVICE_DESTROY_EVENT;
extern TraceEvent _TRACE_M25P80_FLASH_ERASE_EVENT;
extern TraceEvent _TRACE_M25P80_PROGRAMMING_ZERO_TO_ONE_EVENT;
extern TraceEvent _TRACE_M25P80_RESET_DONE_EVENT;
extern TraceEvent _TRACE_M25P80_COMMAND_DECODED_EVENT;
extern TraceEvent _TRACE_M25P80_COMPLETE_COLLECTING_EVENT;
extern TraceEvent _TRACE_M25P80_POPULATED_JEDEC_EVENT;
extern TraceEvent _TRACE_M25P80_CHIP_ERASE_EVENT;
extern TraceEvent _TRACE_M25P80_SELECT_EVENT;
extern TraceEvent _TRACE_M25P80_PAGE_PROGRAM_EVENT;
extern TraceEvent _TRACE_M25P80_TRANSFER_EVENT;
extern TraceEvent _TRACE_M25P80_READ_BYTE_EVENT;
extern TraceEvent _TRACE_M25P80_READ_DATA_EVENT;
extern TraceEvent _TRACE_M25P80_BINDING_EVENT;
extern TraceEvent _TRACE_M25P80_BINDING_NO_BDRV_EVENT;
extern uint16_t _TRACE_FDC_IOPORT_READ_DSTATE;
extern uint16_t _TRACE_FDC_IOPORT_WRITE_DSTATE;
extern uint16_t _TRACE_PFLASH_RESET_DSTATE;
extern uint16_t _TRACE_PFLASH_TIMER_EXPIRED_DSTATE;
extern uint16_t _TRACE_PFLASH_IO_READ_DSTATE;
extern uint16_t _TRACE_PFLASH_IO_WRITE_DSTATE;
extern uint16_t _TRACE_PFLASH_DATA_READ_DSTATE;
extern uint16_t _TRACE_PFLASH_DATA_WRITE_DSTATE;
extern uint16_t _TRACE_PFLASH_MANUFACTURER_ID_DSTATE;
extern uint16_t _TRACE_PFLASH_DEVICE_ID_DSTATE;
extern uint16_t _TRACE_PFLASH_DEVICE_INFO_DSTATE;
extern uint16_t _TRACE_VIRTIO_BLK_REQ_COMPLETE_DSTATE;
extern uint16_t _TRACE_VIRTIO_BLK_RW_COMPLETE_DSTATE;
extern uint16_t _TRACE_VIRTIO_BLK_HANDLE_WRITE_DSTATE;
extern uint16_t _TRACE_VIRTIO_BLK_HANDLE_READ_DSTATE;
extern uint16_t _TRACE_VIRTIO_BLK_SUBMIT_MULTIREQ_DSTATE;
extern uint16_t _TRACE_HD_GEOMETRY_LCHS_GUESS_DSTATE;
extern uint16_t _TRACE_HD_GEOMETRY_GUESS_DSTATE;
extern uint16_t _TRACE_PCI_NVME_REGISTER_NAMESPACE_DSTATE;
extern uint16_t _TRACE_PCI_NVME_IRQ_MSIX_DSTATE;
extern uint16_t _TRACE_PCI_NVME_IRQ_PIN_DSTATE;
extern uint16_t _TRACE_PCI_NVME_IRQ_MASKED_DSTATE;
extern uint16_t _TRACE_PCI_NVME_DMA_READ_DSTATE;
extern uint16_t _TRACE_PCI_NVME_MAP_ADDR_DSTATE;
extern uint16_t _TRACE_PCI_NVME_MAP_ADDR_CMB_DSTATE;
extern uint16_t _TRACE_PCI_NVME_MAP_PRP_DSTATE;
extern uint16_t _TRACE_PCI_NVME_MAP_SGL_DSTATE;
extern uint16_t _TRACE_PCI_NVME_IO_CMD_DSTATE;
extern uint16_t _TRACE_PCI_NVME_ADMIN_CMD_DSTATE;
extern uint16_t _TRACE_PCI_NVME_RW_DSTATE;
extern uint16_t _TRACE_PCI_NVME_RW_CB_DSTATE;
extern uint16_t _TRACE_PCI_NVME_WRITE_ZEROES_DSTATE;
extern uint16_t _TRACE_PCI_NVME_CREATE_SQ_DSTATE;
extern uint16_t _TRACE_PCI_NVME_CREATE_CQ_DSTATE;
extern uint16_t _TRACE_PCI_NVME_DEL_SQ_DSTATE;
extern uint16_t _TRACE_PCI_NVME_DEL_CQ_DSTATE;
extern uint16_t _TRACE_PCI_NVME_IDENTIFY_CTRL_DSTATE;
extern uint16_t _TRACE_PCI_NVME_IDENTIFY_NS_DSTATE;
extern uint16_t _TRACE_PCI_NVME_IDENTIFY_NSLIST_DSTATE;
extern uint16_t _TRACE_PCI_NVME_IDENTIFY_NS_DESCR_LIST_DSTATE;
extern uint16_t _TRACE_PCI_NVME_GET_LOG_DSTATE;
extern uint16_t _TRACE_PCI_NVME_GETFEAT_DSTATE;
extern uint16_t _TRACE_PCI_NVME_SETFEAT_DSTATE;
extern uint16_t _TRACE_PCI_NVME_GETFEAT_VWCACHE_DSTATE;
extern uint16_t _TRACE_PCI_NVME_GETFEAT_NUMQ_DSTATE;
extern uint16_t _TRACE_PCI_NVME_SETFEAT_NUMQ_DSTATE;
extern uint16_t _TRACE_PCI_NVME_SETFEAT_TIMESTAMP_DSTATE;
extern uint16_t _TRACE_PCI_NVME_GETFEAT_TIMESTAMP_DSTATE;
extern uint16_t _TRACE_PCI_NVME_PROCESS_AERS_DSTATE;
extern uint16_t _TRACE_PCI_NVME_AER_DSTATE;
extern uint16_t _TRACE_PCI_NVME_AER_AERL_EXCEEDED_DSTATE;
extern uint16_t _TRACE_PCI_NVME_AER_MASKED_DSTATE;
extern uint16_t _TRACE_PCI_NVME_AER_POST_CQE_DSTATE;
extern uint16_t _TRACE_PCI_NVME_ENQUEUE_EVENT_DSTATE;
extern uint16_t _TRACE_PCI_NVME_ENQUEUE_EVENT_NOQUEUE_DSTATE;
extern uint16_t _TRACE_PCI_NVME_ENQUEUE_EVENT_MASKED_DSTATE;
extern uint16_t _TRACE_PCI_NVME_NO_OUTSTANDING_AERS_DSTATE;
extern uint16_t _TRACE_PCI_NVME_ENQUEUE_REQ_COMPLETION_DSTATE;
extern uint16_t _TRACE_PCI_NVME_MMIO_READ_DSTATE;
extern uint16_t _TRACE_PCI_NVME_MMIO_WRITE_DSTATE;
extern uint16_t _TRACE_PCI_NVME_MMIO_DOORBELL_CQ_DSTATE;
extern uint16_t _TRACE_PCI_NVME_MMIO_DOORBELL_SQ_DSTATE;
extern uint16_t _TRACE_PCI_NVME_MMIO_INTM_SET_DSTATE;
extern uint16_t _TRACE_PCI_NVME_MMIO_INTM_CLR_DSTATE;
extern uint16_t _TRACE_PCI_NVME_MMIO_CFG_DSTATE;
extern uint16_t _TRACE_PCI_NVME_MMIO_AQATTR_DSTATE;
extern uint16_t _TRACE_PCI_NVME_MMIO_ASQADDR_DSTATE;
extern uint16_t _TRACE_PCI_NVME_MMIO_ACQADDR_DSTATE;
extern uint16_t _TRACE_PCI_NVME_MMIO_ASQADDR_HI_DSTATE;
extern uint16_t _TRACE_PCI_NVME_MMIO_ACQADDR_HI_DSTATE;
extern uint16_t _TRACE_PCI_NVME_MMIO_START_SUCCESS_DSTATE;
extern uint16_t _TRACE_PCI_NVME_MMIO_STOPPED_DSTATE;
extern uint16_t _TRACE_PCI_NVME_MMIO_SHUTDOWN_SET_DSTATE;
extern uint16_t _TRACE_PCI_NVME_MMIO_SHUTDOWN_CLEARED_DSTATE;
extern uint16_t _TRACE_PCI_NVME_ERR_MDTS_DSTATE;
extern uint16_t _TRACE_PCI_NVME_ERR_REQ_STATUS_DSTATE;
extern uint16_t _TRACE_PCI_NVME_ERR_ADDR_READ_DSTATE;
extern uint16_t _TRACE_PCI_NVME_ERR_ADDR_WRITE_DSTATE;
extern uint16_t _TRACE_PCI_NVME_ERR_CFS_DSTATE;
extern uint16_t _TRACE_PCI_NVME_ERR_AIO_DSTATE;
extern uint16_t _TRACE_PCI_NVME_ERR_INVALID_SGLD_DSTATE;
extern uint16_t _TRACE_PCI_NVME_ERR_INVALID_NUM_SGLD_DSTATE;
extern uint16_t _TRACE_PCI_NVME_ERR_INVALID_SGL_EXCESS_LENGTH_DSTATE;
extern uint16_t _TRACE_PCI_NVME_ERR_INVALID_DMA_DSTATE;
extern uint16_t _TRACE_PCI_NVME_ERR_INVALID_PRPLIST_ENT_DSTATE;
extern uint16_t _TRACE_PCI_NVME_ERR_INVALID_PRP2_ALIGN_DSTATE;
extern uint16_t _TRACE_PCI_NVME_ERR_INVALID_OPC_DSTATE;
extern uint16_t _TRACE_PCI_NVME_ERR_INVALID_ADMIN_OPC_DSTATE;
extern uint16_t _TRACE_PCI_NVME_ERR_INVALID_LBA_RANGE_DSTATE;
extern uint16_t _TRACE_PCI_NVME_ERR_INVALID_DEL_SQ_DSTATE;
extern uint16_t _TRACE_PCI_NVME_ERR_INVALID_CREATE_SQ_CQID_DSTATE;
extern uint16_t _TRACE_PCI_NVME_ERR_INVALID_CREATE_SQ_SQID_DSTATE;
extern uint16_t _TRACE_PCI_NVME_ERR_INVALID_CREATE_SQ_SIZE_DSTATE;
extern uint16_t _TRACE_PCI_NVME_ERR_INVALID_CREATE_SQ_ADDR_DSTATE;
extern uint16_t _TRACE_PCI_NVME_ERR_INVALID_CREATE_SQ_QFLAGS_DSTATE;
extern uint16_t _TRACE_PCI_NVME_ERR_INVALID_DEL_CQ_CQID_DSTATE;
extern uint16_t _TRACE_PCI_NVME_ERR_INVALID_DEL_CQ_NOTEMPTY_DSTATE;
extern uint16_t _TRACE_PCI_NVME_ERR_INVALID_CREATE_CQ_CQID_DSTATE;
extern uint16_t _TRACE_PCI_NVME_ERR_INVALID_CREATE_CQ_SIZE_DSTATE;
extern uint16_t _TRACE_PCI_NVME_ERR_INVALID_CREATE_CQ_ADDR_DSTATE;
extern uint16_t _TRACE_PCI_NVME_ERR_INVALID_CREATE_CQ_VECTOR_DSTATE;
extern uint16_t _TRACE_PCI_NVME_ERR_INVALID_CREATE_CQ_QFLAGS_DSTATE;
extern uint16_t _TRACE_PCI_NVME_ERR_INVALID_IDENTIFY_CNS_DSTATE;
extern uint16_t _TRACE_PCI_NVME_ERR_INVALID_GETFEAT_DSTATE;
extern uint16_t _TRACE_PCI_NVME_ERR_INVALID_SETFEAT_DSTATE;
extern uint16_t _TRACE_PCI_NVME_ERR_INVALID_LOG_PAGE_DSTATE;
extern uint16_t _TRACE_PCI_NVME_ERR_STARTFAIL_CQ_DSTATE;
extern uint16_t _TRACE_PCI_NVME_ERR_STARTFAIL_SQ_DSTATE;
extern uint16_t _TRACE_PCI_NVME_ERR_STARTFAIL_NBARASQ_DSTATE;
extern uint16_t _TRACE_PCI_NVME_ERR_STARTFAIL_NBARACQ_DSTATE;
extern uint16_t _TRACE_PCI_NVME_ERR_STARTFAIL_ASQ_MISALIGNED_DSTATE;
extern uint16_t _TRACE_PCI_NVME_ERR_STARTFAIL_ACQ_MISALIGNED_DSTATE;
extern uint16_t _TRACE_PCI_NVME_ERR_STARTFAIL_PAGE_TOO_SMALL_DSTATE;
extern uint16_t _TRACE_PCI_NVME_ERR_STARTFAIL_PAGE_TOO_LARGE_DSTATE;
extern uint16_t _TRACE_PCI_NVME_ERR_STARTFAIL_CQENT_TOO_SMALL_DSTATE;
extern uint16_t _TRACE_PCI_NVME_ERR_STARTFAIL_CQENT_TOO_LARGE_DSTATE;
extern uint16_t _TRACE_PCI_NVME_ERR_STARTFAIL_SQENT_TOO_SMALL_DSTATE;
extern uint16_t _TRACE_PCI_NVME_ERR_STARTFAIL_SQENT_TOO_LARGE_DSTATE;
extern uint16_t _TRACE_PCI_NVME_ERR_STARTFAIL_CSS_DSTATE;
extern uint16_t _TRACE_PCI_NVME_ERR_STARTFAIL_ASQENT_SZ_ZERO_DSTATE;
extern uint16_t _TRACE_PCI_NVME_ERR_STARTFAIL_ACQENT_SZ_ZERO_DSTATE;
extern uint16_t _TRACE_PCI_NVME_ERR_STARTFAIL_DSTATE;
extern uint16_t _TRACE_PCI_NVME_UB_MMIOWR_MISALIGNED32_DSTATE;
extern uint16_t _TRACE_PCI_NVME_UB_MMIOWR_TOOSMALL_DSTATE;
extern uint16_t _TRACE_PCI_NVME_UB_MMIOWR_INTMASK_WITH_MSIX_DSTATE;
extern uint16_t _TRACE_PCI_NVME_UB_MMIOWR_RO_CSTS_DSTATE;
extern uint16_t _TRACE_PCI_NVME_UB_MMIOWR_SSRESET_W1C_UNSUPPORTED_DSTATE;
extern uint16_t _TRACE_PCI_NVME_UB_MMIOWR_SSRESET_UNSUPPORTED_DSTATE;
extern uint16_t _TRACE_PCI_NVME_UB_MMIOWR_CMBLOC_RESERVED_DSTATE;
extern uint16_t _TRACE_PCI_NVME_UB_MMIOWR_CMBSZ_READONLY_DSTATE;
extern uint16_t _TRACE_PCI_NVME_UB_MMIOWR_PMRCAP_READONLY_DSTATE;
extern uint16_t _TRACE_PCI_NVME_UB_MMIOWR_PMRSTS_READONLY_DSTATE;
extern uint16_t _TRACE_PCI_NVME_UB_MMIOWR_PMREBS_READONLY_DSTATE;
extern uint16_t _TRACE_PCI_NVME_UB_MMIOWR_PMRSWTP_READONLY_DSTATE;
extern uint16_t _TRACE_PCI_NVME_UB_MMIOWR_INVALID_DSTATE;
extern uint16_t _TRACE_PCI_NVME_UB_MMIORD_MISALIGNED32_DSTATE;
extern uint16_t _TRACE_PCI_NVME_UB_MMIORD_TOOSMALL_DSTATE;
extern uint16_t _TRACE_PCI_NVME_UB_MMIORD_INVALID_OFS_DSTATE;
extern uint16_t _TRACE_PCI_NVME_UB_DB_WR_MISALIGNED_DSTATE;
extern uint16_t _TRACE_PCI_NVME_UB_DB_WR_INVALID_CQ_DSTATE;
extern uint16_t _TRACE_PCI_NVME_UB_DB_WR_INVALID_CQHEAD_DSTATE;
extern uint16_t _TRACE_PCI_NVME_UB_DB_WR_INVALID_SQ_DSTATE;
extern uint16_t _TRACE_PCI_NVME_UB_DB_WR_INVALID_SQTAIL_DSTATE;
extern uint16_t _TRACE_XEN_BLOCK_REALIZE_DSTATE;
extern uint16_t _TRACE_XEN_BLOCK_CONNECT_DSTATE;
extern uint16_t _TRACE_XEN_BLOCK_DISCONNECT_DSTATE;
extern uint16_t _TRACE_XEN_BLOCK_UNREALIZE_DSTATE;
extern uint16_t _TRACE_XEN_BLOCK_SIZE_DSTATE;
extern uint16_t _TRACE_XEN_DISK_REALIZE_DSTATE;
extern uint16_t _TRACE_XEN_DISK_UNREALIZE_DSTATE;
extern uint16_t _TRACE_XEN_CDROM_REALIZE_DSTATE;
extern uint16_t _TRACE_XEN_CDROM_UNREALIZE_DSTATE;
extern uint16_t _TRACE_XEN_BLOCK_BLOCKDEV_ADD_DSTATE;
extern uint16_t _TRACE_XEN_BLOCK_BLOCKDEV_DEL_DSTATE;
extern uint16_t _TRACE_XEN_BLOCK_DEVICE_CREATE_DSTATE;
extern uint16_t _TRACE_XEN_BLOCK_DEVICE_DESTROY_DSTATE;
extern uint16_t _TRACE_M25P80_FLASH_ERASE_DSTATE;
extern uint16_t _TRACE_M25P80_PROGRAMMING_ZERO_TO_ONE_DSTATE;
extern uint16_t _TRACE_M25P80_RESET_DONE_DSTATE;
extern uint16_t _TRACE_M25P80_COMMAND_DECODED_DSTATE;
extern uint16_t _TRACE_M25P80_COMPLETE_COLLECTING_DSTATE;
extern uint16_t _TRACE_M25P80_POPULATED_JEDEC_DSTATE;
extern uint16_t _TRACE_M25P80_CHIP_ERASE_DSTATE;
extern uint16_t _TRACE_M25P80_SELECT_DSTATE;
extern uint16_t _TRACE_M25P80_PAGE_PROGRAM_DSTATE;
extern uint16_t _TRACE_M25P80_TRANSFER_DSTATE;
extern uint16_t _TRACE_M25P80_READ_BYTE_DSTATE;
extern uint16_t _TRACE_M25P80_READ_DATA_DSTATE;
extern uint16_t _TRACE_M25P80_BINDING_DSTATE;
extern uint16_t _TRACE_M25P80_BINDING_NO_BDRV_DSTATE;
#define TRACE_FDC_IOPORT_READ_ENABLED 1
#define TRACE_FDC_IOPORT_WRITE_ENABLED 1
#define TRACE_PFLASH_RESET_ENABLED 1
#define TRACE_PFLASH_TIMER_EXPIRED_ENABLED 1
#define TRACE_PFLASH_IO_READ_ENABLED 1
#define TRACE_PFLASH_IO_WRITE_ENABLED 1
#define TRACE_PFLASH_DATA_READ_ENABLED 1
#define TRACE_PFLASH_DATA_WRITE_ENABLED 1
#define TRACE_PFLASH_MANUFACTURER_ID_ENABLED 1
#define TRACE_PFLASH_DEVICE_ID_ENABLED 1
#define TRACE_PFLASH_DEVICE_INFO_ENABLED 1
#define TRACE_VIRTIO_BLK_REQ_COMPLETE_ENABLED 1
#define TRACE_VIRTIO_BLK_RW_COMPLETE_ENABLED 1
#define TRACE_VIRTIO_BLK_HANDLE_WRITE_ENABLED 1
#define TRACE_VIRTIO_BLK_HANDLE_READ_ENABLED 1
#define TRACE_VIRTIO_BLK_SUBMIT_MULTIREQ_ENABLED 1
#define TRACE_HD_GEOMETRY_LCHS_GUESS_ENABLED 1
#define TRACE_HD_GEOMETRY_GUESS_ENABLED 1
#define TRACE_PCI_NVME_REGISTER_NAMESPACE_ENABLED 1
#define TRACE_PCI_NVME_IRQ_MSIX_ENABLED 1
#define TRACE_PCI_NVME_IRQ_PIN_ENABLED 1
#define TRACE_PCI_NVME_IRQ_MASKED_ENABLED 1
#define TRACE_PCI_NVME_DMA_READ_ENABLED 1
#define TRACE_PCI_NVME_MAP_ADDR_ENABLED 1
#define TRACE_PCI_NVME_MAP_ADDR_CMB_ENABLED 1
#define TRACE_PCI_NVME_MAP_PRP_ENABLED 1
#define TRACE_PCI_NVME_MAP_SGL_ENABLED 1
#define TRACE_PCI_NVME_IO_CMD_ENABLED 1
#define TRACE_PCI_NVME_ADMIN_CMD_ENABLED 1
#define TRACE_PCI_NVME_RW_ENABLED 1
#define TRACE_PCI_NVME_RW_CB_ENABLED 1
#define TRACE_PCI_NVME_WRITE_ZEROES_ENABLED 1
#define TRACE_PCI_NVME_CREATE_SQ_ENABLED 1
#define TRACE_PCI_NVME_CREATE_CQ_ENABLED 1
#define TRACE_PCI_NVME_DEL_SQ_ENABLED 1
#define TRACE_PCI_NVME_DEL_CQ_ENABLED 1
#define TRACE_PCI_NVME_IDENTIFY_CTRL_ENABLED 1
#define TRACE_PCI_NVME_IDENTIFY_NS_ENABLED 1
#define TRACE_PCI_NVME_IDENTIFY_NSLIST_ENABLED 1
#define TRACE_PCI_NVME_IDENTIFY_NS_DESCR_LIST_ENABLED 1
#define TRACE_PCI_NVME_GET_LOG_ENABLED 1
#define TRACE_PCI_NVME_GETFEAT_ENABLED 1
#define TRACE_PCI_NVME_SETFEAT_ENABLED 1
#define TRACE_PCI_NVME_GETFEAT_VWCACHE_ENABLED 1
#define TRACE_PCI_NVME_GETFEAT_NUMQ_ENABLED 1
#define TRACE_PCI_NVME_SETFEAT_NUMQ_ENABLED 1
#define TRACE_PCI_NVME_SETFEAT_TIMESTAMP_ENABLED 1
#define TRACE_PCI_NVME_GETFEAT_TIMESTAMP_ENABLED 1
#define TRACE_PCI_NVME_PROCESS_AERS_ENABLED 1
#define TRACE_PCI_NVME_AER_ENABLED 1
#define TRACE_PCI_NVME_AER_AERL_EXCEEDED_ENABLED 1
#define TRACE_PCI_NVME_AER_MASKED_ENABLED 1
#define TRACE_PCI_NVME_AER_POST_CQE_ENABLED 1
#define TRACE_PCI_NVME_ENQUEUE_EVENT_ENABLED 1
#define TRACE_PCI_NVME_ENQUEUE_EVENT_NOQUEUE_ENABLED 1
#define TRACE_PCI_NVME_ENQUEUE_EVENT_MASKED_ENABLED 1
#define TRACE_PCI_NVME_NO_OUTSTANDING_AERS_ENABLED 1
#define TRACE_PCI_NVME_ENQUEUE_REQ_COMPLETION_ENABLED 1
#define TRACE_PCI_NVME_MMIO_READ_ENABLED 1
#define TRACE_PCI_NVME_MMIO_WRITE_ENABLED 1
#define TRACE_PCI_NVME_MMIO_DOORBELL_CQ_ENABLED 1
#define TRACE_PCI_NVME_MMIO_DOORBELL_SQ_ENABLED 1
#define TRACE_PCI_NVME_MMIO_INTM_SET_ENABLED 1
#define TRACE_PCI_NVME_MMIO_INTM_CLR_ENABLED 1
#define TRACE_PCI_NVME_MMIO_CFG_ENABLED 1
#define TRACE_PCI_NVME_MMIO_AQATTR_ENABLED 1
#define TRACE_PCI_NVME_MMIO_ASQADDR_ENABLED 1
#define TRACE_PCI_NVME_MMIO_ACQADDR_ENABLED 1
#define TRACE_PCI_NVME_MMIO_ASQADDR_HI_ENABLED 1
#define TRACE_PCI_NVME_MMIO_ACQADDR_HI_ENABLED 1
#define TRACE_PCI_NVME_MMIO_START_SUCCESS_ENABLED 1
#define TRACE_PCI_NVME_MMIO_STOPPED_ENABLED 1
#define TRACE_PCI_NVME_MMIO_SHUTDOWN_SET_ENABLED 1
#define TRACE_PCI_NVME_MMIO_SHUTDOWN_CLEARED_ENABLED 1
#define TRACE_PCI_NVME_ERR_MDTS_ENABLED 1
#define TRACE_PCI_NVME_ERR_REQ_STATUS_ENABLED 1
#define TRACE_PCI_NVME_ERR_ADDR_READ_ENABLED 1
#define TRACE_PCI_NVME_ERR_ADDR_WRITE_ENABLED 1
#define TRACE_PCI_NVME_ERR_CFS_ENABLED 1
#define TRACE_PCI_NVME_ERR_AIO_ENABLED 1
#define TRACE_PCI_NVME_ERR_INVALID_SGLD_ENABLED 1
#define TRACE_PCI_NVME_ERR_INVALID_NUM_SGLD_ENABLED 1
#define TRACE_PCI_NVME_ERR_INVALID_SGL_EXCESS_LENGTH_ENABLED 1
#define TRACE_PCI_NVME_ERR_INVALID_DMA_ENABLED 1
#define TRACE_PCI_NVME_ERR_INVALID_PRPLIST_ENT_ENABLED 1
#define TRACE_PCI_NVME_ERR_INVALID_PRP2_ALIGN_ENABLED 1
#define TRACE_PCI_NVME_ERR_INVALID_OPC_ENABLED 1
#define TRACE_PCI_NVME_ERR_INVALID_ADMIN_OPC_ENABLED 1
#define TRACE_PCI_NVME_ERR_INVALID_LBA_RANGE_ENABLED 1
#define TRACE_PCI_NVME_ERR_INVALID_DEL_SQ_ENABLED 1
#define TRACE_PCI_NVME_ERR_INVALID_CREATE_SQ_CQID_ENABLED 1
#define TRACE_PCI_NVME_ERR_INVALID_CREATE_SQ_SQID_ENABLED 1
#define TRACE_PCI_NVME_ERR_INVALID_CREATE_SQ_SIZE_ENABLED 1
#define TRACE_PCI_NVME_ERR_INVALID_CREATE_SQ_ADDR_ENABLED 1
#define TRACE_PCI_NVME_ERR_INVALID_CREATE_SQ_QFLAGS_ENABLED 1
#define TRACE_PCI_NVME_ERR_INVALID_DEL_CQ_CQID_ENABLED 1
#define TRACE_PCI_NVME_ERR_INVALID_DEL_CQ_NOTEMPTY_ENABLED 1
#define TRACE_PCI_NVME_ERR_INVALID_CREATE_CQ_CQID_ENABLED 1
#define TRACE_PCI_NVME_ERR_INVALID_CREATE_CQ_SIZE_ENABLED 1
#define TRACE_PCI_NVME_ERR_INVALID_CREATE_CQ_ADDR_ENABLED 1
#define TRACE_PCI_NVME_ERR_INVALID_CREATE_CQ_VECTOR_ENABLED 1
#define TRACE_PCI_NVME_ERR_INVALID_CREATE_CQ_QFLAGS_ENABLED 1
#define TRACE_PCI_NVME_ERR_INVALID_IDENTIFY_CNS_ENABLED 1
#define TRACE_PCI_NVME_ERR_INVALID_GETFEAT_ENABLED 1
#define TRACE_PCI_NVME_ERR_INVALID_SETFEAT_ENABLED 1
#define TRACE_PCI_NVME_ERR_INVALID_LOG_PAGE_ENABLED 1
#define TRACE_PCI_NVME_ERR_STARTFAIL_CQ_ENABLED 1
#define TRACE_PCI_NVME_ERR_STARTFAIL_SQ_ENABLED 1
#define TRACE_PCI_NVME_ERR_STARTFAIL_NBARASQ_ENABLED 1
#define TRACE_PCI_NVME_ERR_STARTFAIL_NBARACQ_ENABLED 1
#define TRACE_PCI_NVME_ERR_STARTFAIL_ASQ_MISALIGNED_ENABLED 1
#define TRACE_PCI_NVME_ERR_STARTFAIL_ACQ_MISALIGNED_ENABLED 1
#define TRACE_PCI_NVME_ERR_STARTFAIL_PAGE_TOO_SMALL_ENABLED 1
#define TRACE_PCI_NVME_ERR_STARTFAIL_PAGE_TOO_LARGE_ENABLED 1
#define TRACE_PCI_NVME_ERR_STARTFAIL_CQENT_TOO_SMALL_ENABLED 1
#define TRACE_PCI_NVME_ERR_STARTFAIL_CQENT_TOO_LARGE_ENABLED 1
#define TRACE_PCI_NVME_ERR_STARTFAIL_SQENT_TOO_SMALL_ENABLED 1
#define TRACE_PCI_NVME_ERR_STARTFAIL_SQENT_TOO_LARGE_ENABLED 1
#define TRACE_PCI_NVME_ERR_STARTFAIL_CSS_ENABLED 1
#define TRACE_PCI_NVME_ERR_STARTFAIL_ASQENT_SZ_ZERO_ENABLED 1
#define TRACE_PCI_NVME_ERR_STARTFAIL_ACQENT_SZ_ZERO_ENABLED 1
#define TRACE_PCI_NVME_ERR_STARTFAIL_ENABLED 1
#define TRACE_PCI_NVME_UB_MMIOWR_MISALIGNED32_ENABLED 1
#define TRACE_PCI_NVME_UB_MMIOWR_TOOSMALL_ENABLED 1
#define TRACE_PCI_NVME_UB_MMIOWR_INTMASK_WITH_MSIX_ENABLED 1
#define TRACE_PCI_NVME_UB_MMIOWR_RO_CSTS_ENABLED 1
#define TRACE_PCI_NVME_UB_MMIOWR_SSRESET_W1C_UNSUPPORTED_ENABLED 1
#define TRACE_PCI_NVME_UB_MMIOWR_SSRESET_UNSUPPORTED_ENABLED 1
#define TRACE_PCI_NVME_UB_MMIOWR_CMBLOC_RESERVED_ENABLED 1
#define TRACE_PCI_NVME_UB_MMIOWR_CMBSZ_READONLY_ENABLED 1
#define TRACE_PCI_NVME_UB_MMIOWR_PMRCAP_READONLY_ENABLED 1
#define TRACE_PCI_NVME_UB_MMIOWR_PMRSTS_READONLY_ENABLED 1
#define TRACE_PCI_NVME_UB_MMIOWR_PMREBS_READONLY_ENABLED 1
#define TRACE_PCI_NVME_UB_MMIOWR_PMRSWTP_READONLY_ENABLED 1
#define TRACE_PCI_NVME_UB_MMIOWR_INVALID_ENABLED 1
#define TRACE_PCI_NVME_UB_MMIORD_MISALIGNED32_ENABLED 1
#define TRACE_PCI_NVME_UB_MMIORD_TOOSMALL_ENABLED 1
#define TRACE_PCI_NVME_UB_MMIORD_INVALID_OFS_ENABLED 1
#define TRACE_PCI_NVME_UB_DB_WR_MISALIGNED_ENABLED 1
#define TRACE_PCI_NVME_UB_DB_WR_INVALID_CQ_ENABLED 1
#define TRACE_PCI_NVME_UB_DB_WR_INVALID_CQHEAD_ENABLED 1
#define TRACE_PCI_NVME_UB_DB_WR_INVALID_SQ_ENABLED 1
#define TRACE_PCI_NVME_UB_DB_WR_INVALID_SQTAIL_ENABLED 1
#define TRACE_XEN_BLOCK_REALIZE_ENABLED 1
#define TRACE_XEN_BLOCK_CONNECT_ENABLED 1
#define TRACE_XEN_BLOCK_DISCONNECT_ENABLED 1
#define TRACE_XEN_BLOCK_UNREALIZE_ENABLED 1
#define TRACE_XEN_BLOCK_SIZE_ENABLED 1
#define TRACE_XEN_DISK_REALIZE_ENABLED 1
#define TRACE_XEN_DISK_UNREALIZE_ENABLED 1
#define TRACE_XEN_CDROM_REALIZE_ENABLED 1
#define TRACE_XEN_CDROM_UNREALIZE_ENABLED 1
#define TRACE_XEN_BLOCK_BLOCKDEV_ADD_ENABLED 1
#define TRACE_XEN_BLOCK_BLOCKDEV_DEL_ENABLED 1
#define TRACE_XEN_BLOCK_DEVICE_CREATE_ENABLED 1
#define TRACE_XEN_BLOCK_DEVICE_DESTROY_ENABLED 1
#define TRACE_M25P80_FLASH_ERASE_ENABLED 1
#define TRACE_M25P80_PROGRAMMING_ZERO_TO_ONE_ENABLED 1
#define TRACE_M25P80_RESET_DONE_ENABLED 1
#define TRACE_M25P80_COMMAND_DECODED_ENABLED 1
#define TRACE_M25P80_COMPLETE_COLLECTING_ENABLED 1
#define TRACE_M25P80_POPULATED_JEDEC_ENABLED 1
#define TRACE_M25P80_CHIP_ERASE_ENABLED 1
#define TRACE_M25P80_SELECT_ENABLED 1
#define TRACE_M25P80_PAGE_PROGRAM_ENABLED 1
#define TRACE_M25P80_TRANSFER_ENABLED 1
#define TRACE_M25P80_READ_BYTE_ENABLED 1
#define TRACE_M25P80_READ_DATA_ENABLED 1
#define TRACE_M25P80_BINDING_ENABLED 1
#define TRACE_M25P80_BINDING_NO_BDRV_ENABLED 1
#include "qemu/log-for-trace.h"


#define TRACE_FDC_IOPORT_READ_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_FDC_IOPORT_READ) || \
    false)

static inline void _nocheck__trace_fdc_ioport_read(uint8_t reg, uint8_t value)
{
    if (trace_event_get_state(TRACE_FDC_IOPORT_READ) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:fdc_ioport_read " "read reg 0x%02x val 0x%02x" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , reg, value);
    }
}

static inline void trace_fdc_ioport_read(uint8_t reg, uint8_t value)
{
    if (true) {
        _nocheck__trace_fdc_ioport_read(reg, value);
    }
}

#define TRACE_FDC_IOPORT_WRITE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_FDC_IOPORT_WRITE) || \
    false)

static inline void _nocheck__trace_fdc_ioport_write(uint8_t reg, uint8_t value)
{
    if (trace_event_get_state(TRACE_FDC_IOPORT_WRITE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:fdc_ioport_write " "write reg 0x%02x val 0x%02x" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , reg, value);
    }
}

static inline void trace_fdc_ioport_write(uint8_t reg, uint8_t value)
{
    if (true) {
        _nocheck__trace_fdc_ioport_write(reg, value);
    }
}

#define TRACE_PFLASH_RESET_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PFLASH_RESET) || \
    false)

static inline void _nocheck__trace_pflash_reset(void)
{
    if (trace_event_get_state(TRACE_PFLASH_RESET) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pflash_reset " "reset" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_pflash_reset(void)
{
    if (true) {
        _nocheck__trace_pflash_reset();
    }
}

#define TRACE_PFLASH_TIMER_EXPIRED_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PFLASH_TIMER_EXPIRED) || \
    false)

static inline void _nocheck__trace_pflash_timer_expired(uint8_t cmd)
{
    if (trace_event_get_state(TRACE_PFLASH_TIMER_EXPIRED) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pflash_timer_expired " "command 0x%02x done" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , cmd);
    }
}

static inline void trace_pflash_timer_expired(uint8_t cmd)
{
    if (true) {
        _nocheck__trace_pflash_timer_expired(cmd);
    }
}

#define TRACE_PFLASH_IO_READ_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PFLASH_IO_READ) || \
    false)

static inline void _nocheck__trace_pflash_io_read(uint64_t offset, unsigned size, uint32_t value, uint8_t cmd, uint8_t wcycle)
{
    if (trace_event_get_state(TRACE_PFLASH_IO_READ) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pflash_io_read " "offset:0x%04"PRIx64" size:%u value:0x%04x cmd:0x%02x wcycle:%u" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , offset, size, value, cmd, wcycle);
    }
}

static inline void trace_pflash_io_read(uint64_t offset, unsigned size, uint32_t value, uint8_t cmd, uint8_t wcycle)
{
    if (true) {
        _nocheck__trace_pflash_io_read(offset, size, value, cmd, wcycle);
    }
}

#define TRACE_PFLASH_IO_WRITE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PFLASH_IO_WRITE) || \
    false)

static inline void _nocheck__trace_pflash_io_write(uint64_t offset, unsigned size, uint32_t value, uint8_t wcycle)
{
    if (trace_event_get_state(TRACE_PFLASH_IO_WRITE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pflash_io_write " "offset:0x%04"PRIx64" size:%u value:0x%04x wcycle:%u" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , offset, size, value, wcycle);
    }
}

static inline void trace_pflash_io_write(uint64_t offset, unsigned size, uint32_t value, uint8_t wcycle)
{
    if (true) {
        _nocheck__trace_pflash_io_write(offset, size, value, wcycle);
    }
}

#define TRACE_PFLASH_DATA_READ_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PFLASH_DATA_READ) || \
    false)

static inline void _nocheck__trace_pflash_data_read(uint64_t offset, unsigned size, uint32_t value)
{
    if (trace_event_get_state(TRACE_PFLASH_DATA_READ) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pflash_data_read " "data offset:0x%04"PRIx64" size:%u value:0x%04x" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , offset, size, value);
    }
}

static inline void trace_pflash_data_read(uint64_t offset, unsigned size, uint32_t value)
{
    if (true) {
        _nocheck__trace_pflash_data_read(offset, size, value);
    }
}

#define TRACE_PFLASH_DATA_WRITE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PFLASH_DATA_WRITE) || \
    false)

static inline void _nocheck__trace_pflash_data_write(uint64_t offset, unsigned size, uint32_t value, uint64_t counter)
{
    if (trace_event_get_state(TRACE_PFLASH_DATA_WRITE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pflash_data_write " "data offset:0x%04"PRIx64" size:%u value:0x%04x counter:0x%016"PRIx64 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , offset, size, value, counter);
    }
}

static inline void trace_pflash_data_write(uint64_t offset, unsigned size, uint32_t value, uint64_t counter)
{
    if (true) {
        _nocheck__trace_pflash_data_write(offset, size, value, counter);
    }
}

#define TRACE_PFLASH_MANUFACTURER_ID_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PFLASH_MANUFACTURER_ID) || \
    false)

static inline void _nocheck__trace_pflash_manufacturer_id(uint16_t id)
{
    if (trace_event_get_state(TRACE_PFLASH_MANUFACTURER_ID) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pflash_manufacturer_id " "Read Manufacturer ID: 0x%04x" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , id);
    }
}

static inline void trace_pflash_manufacturer_id(uint16_t id)
{
    if (true) {
        _nocheck__trace_pflash_manufacturer_id(id);
    }
}

#define TRACE_PFLASH_DEVICE_ID_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PFLASH_DEVICE_ID) || \
    false)

static inline void _nocheck__trace_pflash_device_id(uint16_t id)
{
    if (trace_event_get_state(TRACE_PFLASH_DEVICE_ID) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pflash_device_id " "Read Device ID: 0x%04x" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , id);
    }
}

static inline void trace_pflash_device_id(uint16_t id)
{
    if (true) {
        _nocheck__trace_pflash_device_id(id);
    }
}

#define TRACE_PFLASH_DEVICE_INFO_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PFLASH_DEVICE_INFO) || \
    false)

static inline void _nocheck__trace_pflash_device_info(uint64_t offset)
{
    if (trace_event_get_state(TRACE_PFLASH_DEVICE_INFO) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pflash_device_info " "Read Device Information offset:0x%04"PRIx64 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , offset);
    }
}

static inline void trace_pflash_device_info(uint64_t offset)
{
    if (true) {
        _nocheck__trace_pflash_device_info(offset);
    }
}

#define TRACE_VIRTIO_BLK_REQ_COMPLETE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_VIRTIO_BLK_REQ_COMPLETE) || \
    false)

static inline void _nocheck__trace_virtio_blk_req_complete(void * vdev, void * req, int status)
{
    if (trace_event_get_state(TRACE_VIRTIO_BLK_REQ_COMPLETE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:virtio_blk_req_complete " "vdev %p req %p status %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , vdev, req, status);
    }
}

static inline void trace_virtio_blk_req_complete(void * vdev, void * req, int status)
{
    if (true) {
        _nocheck__trace_virtio_blk_req_complete(vdev, req, status);
    }
}

#define TRACE_VIRTIO_BLK_RW_COMPLETE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_VIRTIO_BLK_RW_COMPLETE) || \
    false)

static inline void _nocheck__trace_virtio_blk_rw_complete(void * vdev, void * req, int ret)
{
    if (trace_event_get_state(TRACE_VIRTIO_BLK_RW_COMPLETE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:virtio_blk_rw_complete " "vdev %p req %p ret %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , vdev, req, ret);
    }
}

static inline void trace_virtio_blk_rw_complete(void * vdev, void * req, int ret)
{
    if (true) {
        _nocheck__trace_virtio_blk_rw_complete(vdev, req, ret);
    }
}

#define TRACE_VIRTIO_BLK_HANDLE_WRITE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_VIRTIO_BLK_HANDLE_WRITE) || \
    false)

static inline void _nocheck__trace_virtio_blk_handle_write(void * vdev, void * req, uint64_t sector, size_t nsectors)
{
    if (trace_event_get_state(TRACE_VIRTIO_BLK_HANDLE_WRITE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:virtio_blk_handle_write " "vdev %p req %p sector %"PRIu64" nsectors %zu" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , vdev, req, sector, nsectors);
    }
}

static inline void trace_virtio_blk_handle_write(void * vdev, void * req, uint64_t sector, size_t nsectors)
{
    if (true) {
        _nocheck__trace_virtio_blk_handle_write(vdev, req, sector, nsectors);
    }
}

#define TRACE_VIRTIO_BLK_HANDLE_READ_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_VIRTIO_BLK_HANDLE_READ) || \
    false)

static inline void _nocheck__trace_virtio_blk_handle_read(void * vdev, void * req, uint64_t sector, size_t nsectors)
{
    if (trace_event_get_state(TRACE_VIRTIO_BLK_HANDLE_READ) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:virtio_blk_handle_read " "vdev %p req %p sector %"PRIu64" nsectors %zu" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , vdev, req, sector, nsectors);
    }
}

static inline void trace_virtio_blk_handle_read(void * vdev, void * req, uint64_t sector, size_t nsectors)
{
    if (true) {
        _nocheck__trace_virtio_blk_handle_read(vdev, req, sector, nsectors);
    }
}

#define TRACE_VIRTIO_BLK_SUBMIT_MULTIREQ_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_VIRTIO_BLK_SUBMIT_MULTIREQ) || \
    false)

static inline void _nocheck__trace_virtio_blk_submit_multireq(void * vdev, void * mrb, int start, int num_reqs, uint64_t offset, size_t size, bool is_write)
{
    if (trace_event_get_state(TRACE_VIRTIO_BLK_SUBMIT_MULTIREQ) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:virtio_blk_submit_multireq " "vdev %p mrb %p start %d num_reqs %d offset %"PRIu64" size %zu is_write %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , vdev, mrb, start, num_reqs, offset, size, is_write);
    }
}

static inline void trace_virtio_blk_submit_multireq(void * vdev, void * mrb, int start, int num_reqs, uint64_t offset, size_t size, bool is_write)
{
    if (true) {
        _nocheck__trace_virtio_blk_submit_multireq(vdev, mrb, start, num_reqs, offset, size, is_write);
    }
}

#define TRACE_HD_GEOMETRY_LCHS_GUESS_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_HD_GEOMETRY_LCHS_GUESS) || \
    false)

static inline void _nocheck__trace_hd_geometry_lchs_guess(void * blk, int cyls, int heads, int secs)
{
    if (trace_event_get_state(TRACE_HD_GEOMETRY_LCHS_GUESS) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:hd_geometry_lchs_guess " "blk %p LCHS %d %d %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , blk, cyls, heads, secs);
    }
}

static inline void trace_hd_geometry_lchs_guess(void * blk, int cyls, int heads, int secs)
{
    if (true) {
        _nocheck__trace_hd_geometry_lchs_guess(blk, cyls, heads, secs);
    }
}

#define TRACE_HD_GEOMETRY_GUESS_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_HD_GEOMETRY_GUESS) || \
    false)

static inline void _nocheck__trace_hd_geometry_guess(void * blk, uint32_t cyls, uint32_t heads, uint32_t secs, int trans)
{
    if (trace_event_get_state(TRACE_HD_GEOMETRY_GUESS) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:hd_geometry_guess " "blk %p CHS %u %u %u trans %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , blk, cyls, heads, secs, trans);
    }
}

static inline void trace_hd_geometry_guess(void * blk, uint32_t cyls, uint32_t heads, uint32_t secs, int trans)
{
    if (true) {
        _nocheck__trace_hd_geometry_guess(blk, cyls, heads, secs, trans);
    }
}

#define TRACE_PCI_NVME_REGISTER_NAMESPACE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_REGISTER_NAMESPACE) || \
    false)

static inline void _nocheck__trace_pci_nvme_register_namespace(uint32_t nsid)
{
    if (trace_event_get_state(TRACE_PCI_NVME_REGISTER_NAMESPACE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_register_namespace " "nsid %"PRIu32"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , nsid);
    }
}

static inline void trace_pci_nvme_register_namespace(uint32_t nsid)
{
    if (true) {
        _nocheck__trace_pci_nvme_register_namespace(nsid);
    }
}

#define TRACE_PCI_NVME_IRQ_MSIX_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_IRQ_MSIX) || \
    false)

static inline void _nocheck__trace_pci_nvme_irq_msix(uint32_t vector)
{
    if (trace_event_get_state(TRACE_PCI_NVME_IRQ_MSIX) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_irq_msix " "raising MSI-X IRQ vector %u" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , vector);
    }
}

static inline void trace_pci_nvme_irq_msix(uint32_t vector)
{
    if (true) {
        _nocheck__trace_pci_nvme_irq_msix(vector);
    }
}

#define TRACE_PCI_NVME_IRQ_PIN_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_IRQ_PIN) || \
    false)

static inline void _nocheck__trace_pci_nvme_irq_pin(void)
{
    if (trace_event_get_state(TRACE_PCI_NVME_IRQ_PIN) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_irq_pin " "pulsing IRQ pin" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_pci_nvme_irq_pin(void)
{
    if (true) {
        _nocheck__trace_pci_nvme_irq_pin();
    }
}

#define TRACE_PCI_NVME_IRQ_MASKED_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_IRQ_MASKED) || \
    false)

static inline void _nocheck__trace_pci_nvme_irq_masked(void)
{
    if (trace_event_get_state(TRACE_PCI_NVME_IRQ_MASKED) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_irq_masked " "IRQ is masked" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_pci_nvme_irq_masked(void)
{
    if (true) {
        _nocheck__trace_pci_nvme_irq_masked();
    }
}

#define TRACE_PCI_NVME_DMA_READ_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_DMA_READ) || \
    false)

static inline void _nocheck__trace_pci_nvme_dma_read(uint64_t prp1, uint64_t prp2)
{
    if (trace_event_get_state(TRACE_PCI_NVME_DMA_READ) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_dma_read " "DMA read, prp1=0x%"PRIx64" prp2=0x%"PRIx64"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , prp1, prp2);
    }
}

static inline void trace_pci_nvme_dma_read(uint64_t prp1, uint64_t prp2)
{
    if (true) {
        _nocheck__trace_pci_nvme_dma_read(prp1, prp2);
    }
}

#define TRACE_PCI_NVME_MAP_ADDR_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_MAP_ADDR) || \
    false)

static inline void _nocheck__trace_pci_nvme_map_addr(uint64_t addr, uint64_t len)
{
    if (trace_event_get_state(TRACE_PCI_NVME_MAP_ADDR) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_map_addr " "addr 0x%"PRIx64" len %"PRIu64"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , addr, len);
    }
}

static inline void trace_pci_nvme_map_addr(uint64_t addr, uint64_t len)
{
    if (true) {
        _nocheck__trace_pci_nvme_map_addr(addr, len);
    }
}

#define TRACE_PCI_NVME_MAP_ADDR_CMB_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_MAP_ADDR_CMB) || \
    false)

static inline void _nocheck__trace_pci_nvme_map_addr_cmb(uint64_t addr, uint64_t len)
{
    if (trace_event_get_state(TRACE_PCI_NVME_MAP_ADDR_CMB) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_map_addr_cmb " "addr 0x%"PRIx64" len %"PRIu64"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , addr, len);
    }
}

static inline void trace_pci_nvme_map_addr_cmb(uint64_t addr, uint64_t len)
{
    if (true) {
        _nocheck__trace_pci_nvme_map_addr_cmb(addr, len);
    }
}

#define TRACE_PCI_NVME_MAP_PRP_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_MAP_PRP) || \
    false)

static inline void _nocheck__trace_pci_nvme_map_prp(uint64_t trans_len, uint32_t len, uint64_t prp1, uint64_t prp2, int num_prps)
{
    if (trace_event_get_state(TRACE_PCI_NVME_MAP_PRP) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_map_prp " "trans_len %"PRIu64" len %"PRIu32" prp1 0x%"PRIx64" prp2 0x%"PRIx64" num_prps %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , trans_len, len, prp1, prp2, num_prps);
    }
}

static inline void trace_pci_nvme_map_prp(uint64_t trans_len, uint32_t len, uint64_t prp1, uint64_t prp2, int num_prps)
{
    if (true) {
        _nocheck__trace_pci_nvme_map_prp(trans_len, len, prp1, prp2, num_prps);
    }
}

#define TRACE_PCI_NVME_MAP_SGL_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_MAP_SGL) || \
    false)

static inline void _nocheck__trace_pci_nvme_map_sgl(uint16_t cid, uint8_t typ, uint64_t len)
{
    if (trace_event_get_state(TRACE_PCI_NVME_MAP_SGL) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_map_sgl " "cid %"PRIu16" type 0x%"PRIx8" len %"PRIu64"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , cid, typ, len);
    }
}

static inline void trace_pci_nvme_map_sgl(uint16_t cid, uint8_t typ, uint64_t len)
{
    if (true) {
        _nocheck__trace_pci_nvme_map_sgl(cid, typ, len);
    }
}

#define TRACE_PCI_NVME_IO_CMD_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_IO_CMD) || \
    false)

static inline void _nocheck__trace_pci_nvme_io_cmd(uint16_t cid, uint32_t nsid, uint16_t sqid, uint8_t opcode, const char * opname)
{
    if (trace_event_get_state(TRACE_PCI_NVME_IO_CMD) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_io_cmd " "cid %"PRIu16" nsid %"PRIu32" sqid %"PRIu16" opc 0x%"PRIx8" opname '%s'" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , cid, nsid, sqid, opcode, opname);
    }
}

static inline void trace_pci_nvme_io_cmd(uint16_t cid, uint32_t nsid, uint16_t sqid, uint8_t opcode, const char * opname)
{
    if (true) {
        _nocheck__trace_pci_nvme_io_cmd(cid, nsid, sqid, opcode, opname);
    }
}

#define TRACE_PCI_NVME_ADMIN_CMD_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_ADMIN_CMD) || \
    false)

static inline void _nocheck__trace_pci_nvme_admin_cmd(uint16_t cid, uint16_t sqid, uint8_t opcode, const char * opname)
{
    if (trace_event_get_state(TRACE_PCI_NVME_ADMIN_CMD) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_admin_cmd " "cid %"PRIu16" sqid %"PRIu16" opc 0x%"PRIx8" opname '%s'" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , cid, sqid, opcode, opname);
    }
}

static inline void trace_pci_nvme_admin_cmd(uint16_t cid, uint16_t sqid, uint8_t opcode, const char * opname)
{
    if (true) {
        _nocheck__trace_pci_nvme_admin_cmd(cid, sqid, opcode, opname);
    }
}

#define TRACE_PCI_NVME_RW_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_RW) || \
    false)

static inline void _nocheck__trace_pci_nvme_rw(uint16_t cid, const char * verb, uint32_t nsid, uint32_t nlb, uint64_t count, uint64_t lba)
{
    if (trace_event_get_state(TRACE_PCI_NVME_RW) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_rw " "cid %"PRIu16" opname '%s' nsid %"PRIu32" nlb %"PRIu32" count %"PRIu64" lba 0x%"PRIx64"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , cid, verb, nsid, nlb, count, lba);
    }
}

static inline void trace_pci_nvme_rw(uint16_t cid, const char * verb, uint32_t nsid, uint32_t nlb, uint64_t count, uint64_t lba)
{
    if (true) {
        _nocheck__trace_pci_nvme_rw(cid, verb, nsid, nlb, count, lba);
    }
}

#define TRACE_PCI_NVME_RW_CB_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_RW_CB) || \
    false)

static inline void _nocheck__trace_pci_nvme_rw_cb(uint16_t cid, const char * blkname)
{
    if (trace_event_get_state(TRACE_PCI_NVME_RW_CB) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_rw_cb " "cid %"PRIu16" blk '%s'" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , cid, blkname);
    }
}

static inline void trace_pci_nvme_rw_cb(uint16_t cid, const char * blkname)
{
    if (true) {
        _nocheck__trace_pci_nvme_rw_cb(cid, blkname);
    }
}

#define TRACE_PCI_NVME_WRITE_ZEROES_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_WRITE_ZEROES) || \
    false)

static inline void _nocheck__trace_pci_nvme_write_zeroes(uint16_t cid, uint32_t nsid, uint64_t slba, uint32_t nlb)
{
    if (trace_event_get_state(TRACE_PCI_NVME_WRITE_ZEROES) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_write_zeroes " "cid %"PRIu16" nsid %"PRIu32" slba %"PRIu64" nlb %"PRIu32"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , cid, nsid, slba, nlb);
    }
}

static inline void trace_pci_nvme_write_zeroes(uint16_t cid, uint32_t nsid, uint64_t slba, uint32_t nlb)
{
    if (true) {
        _nocheck__trace_pci_nvme_write_zeroes(cid, nsid, slba, nlb);
    }
}

#define TRACE_PCI_NVME_CREATE_SQ_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_CREATE_SQ) || \
    false)

static inline void _nocheck__trace_pci_nvme_create_sq(uint64_t addr, uint16_t sqid, uint16_t cqid, uint16_t qsize, uint16_t qflags)
{
    if (trace_event_get_state(TRACE_PCI_NVME_CREATE_SQ) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_create_sq " "create submission queue, addr=0x%"PRIx64", sqid=%"PRIu16", cqid=%"PRIu16", qsize=%"PRIu16", qflags=%"PRIu16"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , addr, sqid, cqid, qsize, qflags);
    }
}

static inline void trace_pci_nvme_create_sq(uint64_t addr, uint16_t sqid, uint16_t cqid, uint16_t qsize, uint16_t qflags)
{
    if (true) {
        _nocheck__trace_pci_nvme_create_sq(addr, sqid, cqid, qsize, qflags);
    }
}

#define TRACE_PCI_NVME_CREATE_CQ_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_CREATE_CQ) || \
    false)

static inline void _nocheck__trace_pci_nvme_create_cq(uint64_t addr, uint16_t cqid, uint16_t vector, uint16_t size, uint16_t qflags, int ien)
{
    if (trace_event_get_state(TRACE_PCI_NVME_CREATE_CQ) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_create_cq " "create completion queue, addr=0x%"PRIx64", cqid=%"PRIu16", vector=%"PRIu16", qsize=%"PRIu16", qflags=%"PRIu16", ien=%d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , addr, cqid, vector, size, qflags, ien);
    }
}

static inline void trace_pci_nvme_create_cq(uint64_t addr, uint16_t cqid, uint16_t vector, uint16_t size, uint16_t qflags, int ien)
{
    if (true) {
        _nocheck__trace_pci_nvme_create_cq(addr, cqid, vector, size, qflags, ien);
    }
}

#define TRACE_PCI_NVME_DEL_SQ_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_DEL_SQ) || \
    false)

static inline void _nocheck__trace_pci_nvme_del_sq(uint16_t qid)
{
    if (trace_event_get_state(TRACE_PCI_NVME_DEL_SQ) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_del_sq " "deleting submission queue sqid=%"PRIu16"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , qid);
    }
}

static inline void trace_pci_nvme_del_sq(uint16_t qid)
{
    if (true) {
        _nocheck__trace_pci_nvme_del_sq(qid);
    }
}

#define TRACE_PCI_NVME_DEL_CQ_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_DEL_CQ) || \
    false)

static inline void _nocheck__trace_pci_nvme_del_cq(uint16_t cqid)
{
    if (trace_event_get_state(TRACE_PCI_NVME_DEL_CQ) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_del_cq " "deleted completion queue, cqid=%"PRIu16"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , cqid);
    }
}

static inline void trace_pci_nvme_del_cq(uint16_t cqid)
{
    if (true) {
        _nocheck__trace_pci_nvme_del_cq(cqid);
    }
}

#define TRACE_PCI_NVME_IDENTIFY_CTRL_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_IDENTIFY_CTRL) || \
    false)

static inline void _nocheck__trace_pci_nvme_identify_ctrl(void)
{
    if (trace_event_get_state(TRACE_PCI_NVME_IDENTIFY_CTRL) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_identify_ctrl " "identify controller" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_pci_nvme_identify_ctrl(void)
{
    if (true) {
        _nocheck__trace_pci_nvme_identify_ctrl();
    }
}

#define TRACE_PCI_NVME_IDENTIFY_NS_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_IDENTIFY_NS) || \
    false)

static inline void _nocheck__trace_pci_nvme_identify_ns(uint32_t ns)
{
    if (trace_event_get_state(TRACE_PCI_NVME_IDENTIFY_NS) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_identify_ns " "nsid %"PRIu32"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , ns);
    }
}

static inline void trace_pci_nvme_identify_ns(uint32_t ns)
{
    if (true) {
        _nocheck__trace_pci_nvme_identify_ns(ns);
    }
}

#define TRACE_PCI_NVME_IDENTIFY_NSLIST_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_IDENTIFY_NSLIST) || \
    false)

static inline void _nocheck__trace_pci_nvme_identify_nslist(uint32_t ns)
{
    if (trace_event_get_state(TRACE_PCI_NVME_IDENTIFY_NSLIST) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_identify_nslist " "nsid %"PRIu32"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , ns);
    }
}

static inline void trace_pci_nvme_identify_nslist(uint32_t ns)
{
    if (true) {
        _nocheck__trace_pci_nvme_identify_nslist(ns);
    }
}

#define TRACE_PCI_NVME_IDENTIFY_NS_DESCR_LIST_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_IDENTIFY_NS_DESCR_LIST) || \
    false)

static inline void _nocheck__trace_pci_nvme_identify_ns_descr_list(uint32_t ns)
{
    if (trace_event_get_state(TRACE_PCI_NVME_IDENTIFY_NS_DESCR_LIST) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_identify_ns_descr_list " "nsid %"PRIu32"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , ns);
    }
}

static inline void trace_pci_nvme_identify_ns_descr_list(uint32_t ns)
{
    if (true) {
        _nocheck__trace_pci_nvme_identify_ns_descr_list(ns);
    }
}

#define TRACE_PCI_NVME_GET_LOG_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_GET_LOG) || \
    false)

static inline void _nocheck__trace_pci_nvme_get_log(uint16_t cid, uint8_t lid, uint8_t lsp, uint8_t rae, uint32_t len, uint64_t off)
{
    if (trace_event_get_state(TRACE_PCI_NVME_GET_LOG) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_get_log " "cid %"PRIu16" lid 0x%"PRIx8" lsp 0x%"PRIx8" rae 0x%"PRIx8" len %"PRIu32" off %"PRIu64"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , cid, lid, lsp, rae, len, off);
    }
}

static inline void trace_pci_nvme_get_log(uint16_t cid, uint8_t lid, uint8_t lsp, uint8_t rae, uint32_t len, uint64_t off)
{
    if (true) {
        _nocheck__trace_pci_nvme_get_log(cid, lid, lsp, rae, len, off);
    }
}

#define TRACE_PCI_NVME_GETFEAT_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_GETFEAT) || \
    false)

static inline void _nocheck__trace_pci_nvme_getfeat(uint16_t cid, uint32_t nsid, uint8_t fid, uint8_t sel, uint32_t cdw11)
{
    if (trace_event_get_state(TRACE_PCI_NVME_GETFEAT) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_getfeat " "cid %"PRIu16" nsid 0x%"PRIx32" fid 0x%"PRIx8" sel 0x%"PRIx8" cdw11 0x%"PRIx32"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , cid, nsid, fid, sel, cdw11);
    }
}

static inline void trace_pci_nvme_getfeat(uint16_t cid, uint32_t nsid, uint8_t fid, uint8_t sel, uint32_t cdw11)
{
    if (true) {
        _nocheck__trace_pci_nvme_getfeat(cid, nsid, fid, sel, cdw11);
    }
}

#define TRACE_PCI_NVME_SETFEAT_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_SETFEAT) || \
    false)

static inline void _nocheck__trace_pci_nvme_setfeat(uint16_t cid, uint32_t nsid, uint8_t fid, uint8_t save, uint32_t cdw11)
{
    if (trace_event_get_state(TRACE_PCI_NVME_SETFEAT) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_setfeat " "cid %"PRIu16" nsid 0x%"PRIx32" fid 0x%"PRIx8" save 0x%"PRIx8" cdw11 0x%"PRIx32"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , cid, nsid, fid, save, cdw11);
    }
}

static inline void trace_pci_nvme_setfeat(uint16_t cid, uint32_t nsid, uint8_t fid, uint8_t save, uint32_t cdw11)
{
    if (true) {
        _nocheck__trace_pci_nvme_setfeat(cid, nsid, fid, save, cdw11);
    }
}

#define TRACE_PCI_NVME_GETFEAT_VWCACHE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_GETFEAT_VWCACHE) || \
    false)

static inline void _nocheck__trace_pci_nvme_getfeat_vwcache(const char* result)
{
    if (trace_event_get_state(TRACE_PCI_NVME_GETFEAT_VWCACHE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_getfeat_vwcache " "get feature volatile write cache, result=%s" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , result);
    }
}

static inline void trace_pci_nvme_getfeat_vwcache(const char* result)
{
    if (true) {
        _nocheck__trace_pci_nvme_getfeat_vwcache(result);
    }
}

#define TRACE_PCI_NVME_GETFEAT_NUMQ_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_GETFEAT_NUMQ) || \
    false)

static inline void _nocheck__trace_pci_nvme_getfeat_numq(int result)
{
    if (trace_event_get_state(TRACE_PCI_NVME_GETFEAT_NUMQ) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_getfeat_numq " "get feature number of queues, result=%d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , result);
    }
}

static inline void trace_pci_nvme_getfeat_numq(int result)
{
    if (true) {
        _nocheck__trace_pci_nvme_getfeat_numq(result);
    }
}

#define TRACE_PCI_NVME_SETFEAT_NUMQ_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_SETFEAT_NUMQ) || \
    false)

static inline void _nocheck__trace_pci_nvme_setfeat_numq(int reqcq, int reqsq, int gotcq, int gotsq)
{
    if (trace_event_get_state(TRACE_PCI_NVME_SETFEAT_NUMQ) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_setfeat_numq " "requested cq_count=%d sq_count=%d, responding with cq_count=%d sq_count=%d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , reqcq, reqsq, gotcq, gotsq);
    }
}

static inline void trace_pci_nvme_setfeat_numq(int reqcq, int reqsq, int gotcq, int gotsq)
{
    if (true) {
        _nocheck__trace_pci_nvme_setfeat_numq(reqcq, reqsq, gotcq, gotsq);
    }
}

#define TRACE_PCI_NVME_SETFEAT_TIMESTAMP_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_SETFEAT_TIMESTAMP) || \
    false)

static inline void _nocheck__trace_pci_nvme_setfeat_timestamp(uint64_t ts)
{
    if (trace_event_get_state(TRACE_PCI_NVME_SETFEAT_TIMESTAMP) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_setfeat_timestamp " "set feature timestamp = 0x%"PRIx64"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , ts);
    }
}

static inline void trace_pci_nvme_setfeat_timestamp(uint64_t ts)
{
    if (true) {
        _nocheck__trace_pci_nvme_setfeat_timestamp(ts);
    }
}

#define TRACE_PCI_NVME_GETFEAT_TIMESTAMP_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_GETFEAT_TIMESTAMP) || \
    false)

static inline void _nocheck__trace_pci_nvme_getfeat_timestamp(uint64_t ts)
{
    if (trace_event_get_state(TRACE_PCI_NVME_GETFEAT_TIMESTAMP) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_getfeat_timestamp " "get feature timestamp = 0x%"PRIx64"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , ts);
    }
}

static inline void trace_pci_nvme_getfeat_timestamp(uint64_t ts)
{
    if (true) {
        _nocheck__trace_pci_nvme_getfeat_timestamp(ts);
    }
}

#define TRACE_PCI_NVME_PROCESS_AERS_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_PROCESS_AERS) || \
    false)

static inline void _nocheck__trace_pci_nvme_process_aers(int queued)
{
    if (trace_event_get_state(TRACE_PCI_NVME_PROCESS_AERS) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_process_aers " "queued %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , queued);
    }
}

static inline void trace_pci_nvme_process_aers(int queued)
{
    if (true) {
        _nocheck__trace_pci_nvme_process_aers(queued);
    }
}

#define TRACE_PCI_NVME_AER_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_AER) || \
    false)

static inline void _nocheck__trace_pci_nvme_aer(uint16_t cid)
{
    if (trace_event_get_state(TRACE_PCI_NVME_AER) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_aer " "cid %"PRIu16"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , cid);
    }
}

static inline void trace_pci_nvme_aer(uint16_t cid)
{
    if (true) {
        _nocheck__trace_pci_nvme_aer(cid);
    }
}

#define TRACE_PCI_NVME_AER_AERL_EXCEEDED_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_AER_AERL_EXCEEDED) || \
    false)

static inline void _nocheck__trace_pci_nvme_aer_aerl_exceeded(void)
{
    if (trace_event_get_state(TRACE_PCI_NVME_AER_AERL_EXCEEDED) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_aer_aerl_exceeded " "aerl exceeded" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_pci_nvme_aer_aerl_exceeded(void)
{
    if (true) {
        _nocheck__trace_pci_nvme_aer_aerl_exceeded();
    }
}

#define TRACE_PCI_NVME_AER_MASKED_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_AER_MASKED) || \
    false)

static inline void _nocheck__trace_pci_nvme_aer_masked(uint8_t type, uint8_t mask)
{
    if (trace_event_get_state(TRACE_PCI_NVME_AER_MASKED) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_aer_masked " "type 0x%"PRIx8" mask 0x%"PRIx8"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , type, mask);
    }
}

static inline void trace_pci_nvme_aer_masked(uint8_t type, uint8_t mask)
{
    if (true) {
        _nocheck__trace_pci_nvme_aer_masked(type, mask);
    }
}

#define TRACE_PCI_NVME_AER_POST_CQE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_AER_POST_CQE) || \
    false)

static inline void _nocheck__trace_pci_nvme_aer_post_cqe(uint8_t typ, uint8_t info, uint8_t log_page)
{
    if (trace_event_get_state(TRACE_PCI_NVME_AER_POST_CQE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_aer_post_cqe " "type 0x%"PRIx8" info 0x%"PRIx8" lid 0x%"PRIx8"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , typ, info, log_page);
    }
}

static inline void trace_pci_nvme_aer_post_cqe(uint8_t typ, uint8_t info, uint8_t log_page)
{
    if (true) {
        _nocheck__trace_pci_nvme_aer_post_cqe(typ, info, log_page);
    }
}

#define TRACE_PCI_NVME_ENQUEUE_EVENT_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_ENQUEUE_EVENT) || \
    false)

static inline void _nocheck__trace_pci_nvme_enqueue_event(uint8_t typ, uint8_t info, uint8_t log_page)
{
    if (trace_event_get_state(TRACE_PCI_NVME_ENQUEUE_EVENT) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_enqueue_event " "type 0x%"PRIx8" info 0x%"PRIx8" lid 0x%"PRIx8"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , typ, info, log_page);
    }
}

static inline void trace_pci_nvme_enqueue_event(uint8_t typ, uint8_t info, uint8_t log_page)
{
    if (true) {
        _nocheck__trace_pci_nvme_enqueue_event(typ, info, log_page);
    }
}

#define TRACE_PCI_NVME_ENQUEUE_EVENT_NOQUEUE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_ENQUEUE_EVENT_NOQUEUE) || \
    false)

static inline void _nocheck__trace_pci_nvme_enqueue_event_noqueue(int queued)
{
    if (trace_event_get_state(TRACE_PCI_NVME_ENQUEUE_EVENT_NOQUEUE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_enqueue_event_noqueue " "queued %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , queued);
    }
}

static inline void trace_pci_nvme_enqueue_event_noqueue(int queued)
{
    if (true) {
        _nocheck__trace_pci_nvme_enqueue_event_noqueue(queued);
    }
}

#define TRACE_PCI_NVME_ENQUEUE_EVENT_MASKED_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_ENQUEUE_EVENT_MASKED) || \
    false)

static inline void _nocheck__trace_pci_nvme_enqueue_event_masked(uint8_t typ)
{
    if (trace_event_get_state(TRACE_PCI_NVME_ENQUEUE_EVENT_MASKED) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_enqueue_event_masked " "type 0x%"PRIx8"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , typ);
    }
}

static inline void trace_pci_nvme_enqueue_event_masked(uint8_t typ)
{
    if (true) {
        _nocheck__trace_pci_nvme_enqueue_event_masked(typ);
    }
}

#define TRACE_PCI_NVME_NO_OUTSTANDING_AERS_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_NO_OUTSTANDING_AERS) || \
    false)

static inline void _nocheck__trace_pci_nvme_no_outstanding_aers(void)
{
    if (trace_event_get_state(TRACE_PCI_NVME_NO_OUTSTANDING_AERS) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_no_outstanding_aers " "ignoring event; no outstanding AERs" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_pci_nvme_no_outstanding_aers(void)
{
    if (true) {
        _nocheck__trace_pci_nvme_no_outstanding_aers();
    }
}

#define TRACE_PCI_NVME_ENQUEUE_REQ_COMPLETION_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_ENQUEUE_REQ_COMPLETION) || \
    false)

static inline void _nocheck__trace_pci_nvme_enqueue_req_completion(uint16_t cid, uint16_t cqid, uint16_t status)
{
    if (trace_event_get_state(TRACE_PCI_NVME_ENQUEUE_REQ_COMPLETION) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_enqueue_req_completion " "cid %"PRIu16" cqid %"PRIu16" status 0x%"PRIx16"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , cid, cqid, status);
    }
}

static inline void trace_pci_nvme_enqueue_req_completion(uint16_t cid, uint16_t cqid, uint16_t status)
{
    if (true) {
        _nocheck__trace_pci_nvme_enqueue_req_completion(cid, cqid, status);
    }
}

#define TRACE_PCI_NVME_MMIO_READ_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_MMIO_READ) || \
    false)

static inline void _nocheck__trace_pci_nvme_mmio_read(uint64_t addr)
{
    if (trace_event_get_state(TRACE_PCI_NVME_MMIO_READ) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_mmio_read " "addr 0x%"PRIx64"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , addr);
    }
}

static inline void trace_pci_nvme_mmio_read(uint64_t addr)
{
    if (true) {
        _nocheck__trace_pci_nvme_mmio_read(addr);
    }
}

#define TRACE_PCI_NVME_MMIO_WRITE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_MMIO_WRITE) || \
    false)

static inline void _nocheck__trace_pci_nvme_mmio_write(uint64_t addr, uint64_t data)
{
    if (trace_event_get_state(TRACE_PCI_NVME_MMIO_WRITE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_mmio_write " "addr 0x%"PRIx64" data 0x%"PRIx64"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , addr, data);
    }
}

static inline void trace_pci_nvme_mmio_write(uint64_t addr, uint64_t data)
{
    if (true) {
        _nocheck__trace_pci_nvme_mmio_write(addr, data);
    }
}

#define TRACE_PCI_NVME_MMIO_DOORBELL_CQ_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_MMIO_DOORBELL_CQ) || \
    false)

static inline void _nocheck__trace_pci_nvme_mmio_doorbell_cq(uint16_t cqid, uint16_t new_head)
{
    if (trace_event_get_state(TRACE_PCI_NVME_MMIO_DOORBELL_CQ) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_mmio_doorbell_cq " "cqid %"PRIu16" new_head %"PRIu16"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , cqid, new_head);
    }
}

static inline void trace_pci_nvme_mmio_doorbell_cq(uint16_t cqid, uint16_t new_head)
{
    if (true) {
        _nocheck__trace_pci_nvme_mmio_doorbell_cq(cqid, new_head);
    }
}

#define TRACE_PCI_NVME_MMIO_DOORBELL_SQ_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_MMIO_DOORBELL_SQ) || \
    false)

static inline void _nocheck__trace_pci_nvme_mmio_doorbell_sq(uint16_t sqid, uint16_t new_tail)
{
    if (trace_event_get_state(TRACE_PCI_NVME_MMIO_DOORBELL_SQ) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_mmio_doorbell_sq " "sqid %"PRIu16" new_tail %"PRIu16"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , sqid, new_tail);
    }
}

static inline void trace_pci_nvme_mmio_doorbell_sq(uint16_t sqid, uint16_t new_tail)
{
    if (true) {
        _nocheck__trace_pci_nvme_mmio_doorbell_sq(sqid, new_tail);
    }
}

#define TRACE_PCI_NVME_MMIO_INTM_SET_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_MMIO_INTM_SET) || \
    false)

static inline void _nocheck__trace_pci_nvme_mmio_intm_set(uint64_t data, uint64_t new_mask)
{
    if (trace_event_get_state(TRACE_PCI_NVME_MMIO_INTM_SET) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_mmio_intm_set " "wrote MMIO, interrupt mask set, data=0x%"PRIx64", new_mask=0x%"PRIx64"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , data, new_mask);
    }
}

static inline void trace_pci_nvme_mmio_intm_set(uint64_t data, uint64_t new_mask)
{
    if (true) {
        _nocheck__trace_pci_nvme_mmio_intm_set(data, new_mask);
    }
}

#define TRACE_PCI_NVME_MMIO_INTM_CLR_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_MMIO_INTM_CLR) || \
    false)

static inline void _nocheck__trace_pci_nvme_mmio_intm_clr(uint64_t data, uint64_t new_mask)
{
    if (trace_event_get_state(TRACE_PCI_NVME_MMIO_INTM_CLR) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_mmio_intm_clr " "wrote MMIO, interrupt mask clr, data=0x%"PRIx64", new_mask=0x%"PRIx64"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , data, new_mask);
    }
}

static inline void trace_pci_nvme_mmio_intm_clr(uint64_t data, uint64_t new_mask)
{
    if (true) {
        _nocheck__trace_pci_nvme_mmio_intm_clr(data, new_mask);
    }
}

#define TRACE_PCI_NVME_MMIO_CFG_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_MMIO_CFG) || \
    false)

static inline void _nocheck__trace_pci_nvme_mmio_cfg(uint64_t data)
{
    if (trace_event_get_state(TRACE_PCI_NVME_MMIO_CFG) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_mmio_cfg " "wrote MMIO, config controller config=0x%"PRIx64"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , data);
    }
}

static inline void trace_pci_nvme_mmio_cfg(uint64_t data)
{
    if (true) {
        _nocheck__trace_pci_nvme_mmio_cfg(data);
    }
}

#define TRACE_PCI_NVME_MMIO_AQATTR_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_MMIO_AQATTR) || \
    false)

static inline void _nocheck__trace_pci_nvme_mmio_aqattr(uint64_t data)
{
    if (trace_event_get_state(TRACE_PCI_NVME_MMIO_AQATTR) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_mmio_aqattr " "wrote MMIO, admin queue attributes=0x%"PRIx64"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , data);
    }
}

static inline void trace_pci_nvme_mmio_aqattr(uint64_t data)
{
    if (true) {
        _nocheck__trace_pci_nvme_mmio_aqattr(data);
    }
}

#define TRACE_PCI_NVME_MMIO_ASQADDR_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_MMIO_ASQADDR) || \
    false)

static inline void _nocheck__trace_pci_nvme_mmio_asqaddr(uint64_t data)
{
    if (trace_event_get_state(TRACE_PCI_NVME_MMIO_ASQADDR) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_mmio_asqaddr " "wrote MMIO, admin submission queue address=0x%"PRIx64"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , data);
    }
}

static inline void trace_pci_nvme_mmio_asqaddr(uint64_t data)
{
    if (true) {
        _nocheck__trace_pci_nvme_mmio_asqaddr(data);
    }
}

#define TRACE_PCI_NVME_MMIO_ACQADDR_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_MMIO_ACQADDR) || \
    false)

static inline void _nocheck__trace_pci_nvme_mmio_acqaddr(uint64_t data)
{
    if (trace_event_get_state(TRACE_PCI_NVME_MMIO_ACQADDR) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_mmio_acqaddr " "wrote MMIO, admin completion queue address=0x%"PRIx64"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , data);
    }
}

static inline void trace_pci_nvme_mmio_acqaddr(uint64_t data)
{
    if (true) {
        _nocheck__trace_pci_nvme_mmio_acqaddr(data);
    }
}

#define TRACE_PCI_NVME_MMIO_ASQADDR_HI_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_MMIO_ASQADDR_HI) || \
    false)

static inline void _nocheck__trace_pci_nvme_mmio_asqaddr_hi(uint64_t data, uint64_t new_addr)
{
    if (trace_event_get_state(TRACE_PCI_NVME_MMIO_ASQADDR_HI) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_mmio_asqaddr_hi " "wrote MMIO, admin submission queue high half=0x%"PRIx64", new_address=0x%"PRIx64"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , data, new_addr);
    }
}

static inline void trace_pci_nvme_mmio_asqaddr_hi(uint64_t data, uint64_t new_addr)
{
    if (true) {
        _nocheck__trace_pci_nvme_mmio_asqaddr_hi(data, new_addr);
    }
}

#define TRACE_PCI_NVME_MMIO_ACQADDR_HI_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_MMIO_ACQADDR_HI) || \
    false)

static inline void _nocheck__trace_pci_nvme_mmio_acqaddr_hi(uint64_t data, uint64_t new_addr)
{
    if (trace_event_get_state(TRACE_PCI_NVME_MMIO_ACQADDR_HI) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_mmio_acqaddr_hi " "wrote MMIO, admin completion queue high half=0x%"PRIx64", new_address=0x%"PRIx64"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , data, new_addr);
    }
}

static inline void trace_pci_nvme_mmio_acqaddr_hi(uint64_t data, uint64_t new_addr)
{
    if (true) {
        _nocheck__trace_pci_nvme_mmio_acqaddr_hi(data, new_addr);
    }
}

#define TRACE_PCI_NVME_MMIO_START_SUCCESS_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_MMIO_START_SUCCESS) || \
    false)

static inline void _nocheck__trace_pci_nvme_mmio_start_success(void)
{
    if (trace_event_get_state(TRACE_PCI_NVME_MMIO_START_SUCCESS) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_mmio_start_success " "setting controller enable bit succeeded" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_pci_nvme_mmio_start_success(void)
{
    if (true) {
        _nocheck__trace_pci_nvme_mmio_start_success();
    }
}

#define TRACE_PCI_NVME_MMIO_STOPPED_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_MMIO_STOPPED) || \
    false)

static inline void _nocheck__trace_pci_nvme_mmio_stopped(void)
{
    if (trace_event_get_state(TRACE_PCI_NVME_MMIO_STOPPED) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_mmio_stopped " "cleared controller enable bit" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_pci_nvme_mmio_stopped(void)
{
    if (true) {
        _nocheck__trace_pci_nvme_mmio_stopped();
    }
}

#define TRACE_PCI_NVME_MMIO_SHUTDOWN_SET_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_MMIO_SHUTDOWN_SET) || \
    false)

static inline void _nocheck__trace_pci_nvme_mmio_shutdown_set(void)
{
    if (trace_event_get_state(TRACE_PCI_NVME_MMIO_SHUTDOWN_SET) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_mmio_shutdown_set " "shutdown bit set" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_pci_nvme_mmio_shutdown_set(void)
{
    if (true) {
        _nocheck__trace_pci_nvme_mmio_shutdown_set();
    }
}

#define TRACE_PCI_NVME_MMIO_SHUTDOWN_CLEARED_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_MMIO_SHUTDOWN_CLEARED) || \
    false)

static inline void _nocheck__trace_pci_nvme_mmio_shutdown_cleared(void)
{
    if (trace_event_get_state(TRACE_PCI_NVME_MMIO_SHUTDOWN_CLEARED) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_mmio_shutdown_cleared " "shutdown bit cleared" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_pci_nvme_mmio_shutdown_cleared(void)
{
    if (true) {
        _nocheck__trace_pci_nvme_mmio_shutdown_cleared();
    }
}

#define TRACE_PCI_NVME_ERR_MDTS_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_ERR_MDTS) || \
    false)

static inline void _nocheck__trace_pci_nvme_err_mdts(uint16_t cid, size_t len)
{
    if (trace_event_get_state(TRACE_PCI_NVME_ERR_MDTS) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_err_mdts " "cid %"PRIu16" len %zu" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , cid, len);
    }
}

static inline void trace_pci_nvme_err_mdts(uint16_t cid, size_t len)
{
    if (true) {
        _nocheck__trace_pci_nvme_err_mdts(cid, len);
    }
}

#define TRACE_PCI_NVME_ERR_REQ_STATUS_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_ERR_REQ_STATUS) || \
    false)

static inline void _nocheck__trace_pci_nvme_err_req_status(uint16_t cid, uint32_t nsid, uint16_t status, uint8_t opc)
{
    if (trace_event_get_state(TRACE_PCI_NVME_ERR_REQ_STATUS) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_err_req_status " "cid %"PRIu16" nsid %"PRIu32" status 0x%"PRIx16" opc 0x%"PRIx8"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , cid, nsid, status, opc);
    }
}

static inline void trace_pci_nvme_err_req_status(uint16_t cid, uint32_t nsid, uint16_t status, uint8_t opc)
{
    if (true) {
        _nocheck__trace_pci_nvme_err_req_status(cid, nsid, status, opc);
    }
}

#define TRACE_PCI_NVME_ERR_ADDR_READ_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_ERR_ADDR_READ) || \
    false)

static inline void _nocheck__trace_pci_nvme_err_addr_read(uint64_t addr)
{
    if (trace_event_get_state(TRACE_PCI_NVME_ERR_ADDR_READ) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_err_addr_read " "addr 0x%"PRIx64"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , addr);
    }
}

static inline void trace_pci_nvme_err_addr_read(uint64_t addr)
{
    if (true) {
        _nocheck__trace_pci_nvme_err_addr_read(addr);
    }
}

#define TRACE_PCI_NVME_ERR_ADDR_WRITE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_ERR_ADDR_WRITE) || \
    false)

static inline void _nocheck__trace_pci_nvme_err_addr_write(uint64_t addr)
{
    if (trace_event_get_state(TRACE_PCI_NVME_ERR_ADDR_WRITE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_err_addr_write " "addr 0x%"PRIx64"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , addr);
    }
}

static inline void trace_pci_nvme_err_addr_write(uint64_t addr)
{
    if (true) {
        _nocheck__trace_pci_nvme_err_addr_write(addr);
    }
}

#define TRACE_PCI_NVME_ERR_CFS_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_ERR_CFS) || \
    false)

static inline void _nocheck__trace_pci_nvme_err_cfs(void)
{
    if (trace_event_get_state(TRACE_PCI_NVME_ERR_CFS) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_err_cfs " "controller fatal status" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_pci_nvme_err_cfs(void)
{
    if (true) {
        _nocheck__trace_pci_nvme_err_cfs();
    }
}

#define TRACE_PCI_NVME_ERR_AIO_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_ERR_AIO) || \
    false)

static inline void _nocheck__trace_pci_nvme_err_aio(uint16_t cid, const char * errname, uint16_t status)
{
    if (trace_event_get_state(TRACE_PCI_NVME_ERR_AIO) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_err_aio " "cid %"PRIu16" err '%s' status 0x%"PRIx16"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , cid, errname, status);
    }
}

static inline void trace_pci_nvme_err_aio(uint16_t cid, const char * errname, uint16_t status)
{
    if (true) {
        _nocheck__trace_pci_nvme_err_aio(cid, errname, status);
    }
}

#define TRACE_PCI_NVME_ERR_INVALID_SGLD_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_ERR_INVALID_SGLD) || \
    false)

static inline void _nocheck__trace_pci_nvme_err_invalid_sgld(uint16_t cid, uint8_t typ)
{
    if (trace_event_get_state(TRACE_PCI_NVME_ERR_INVALID_SGLD) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_err_invalid_sgld " "cid %"PRIu16" type 0x%"PRIx8"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , cid, typ);
    }
}

static inline void trace_pci_nvme_err_invalid_sgld(uint16_t cid, uint8_t typ)
{
    if (true) {
        _nocheck__trace_pci_nvme_err_invalid_sgld(cid, typ);
    }
}

#define TRACE_PCI_NVME_ERR_INVALID_NUM_SGLD_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_ERR_INVALID_NUM_SGLD) || \
    false)

static inline void _nocheck__trace_pci_nvme_err_invalid_num_sgld(uint16_t cid, uint8_t typ)
{
    if (trace_event_get_state(TRACE_PCI_NVME_ERR_INVALID_NUM_SGLD) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_err_invalid_num_sgld " "cid %"PRIu16" type 0x%"PRIx8"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , cid, typ);
    }
}

static inline void trace_pci_nvme_err_invalid_num_sgld(uint16_t cid, uint8_t typ)
{
    if (true) {
        _nocheck__trace_pci_nvme_err_invalid_num_sgld(cid, typ);
    }
}

#define TRACE_PCI_NVME_ERR_INVALID_SGL_EXCESS_LENGTH_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_ERR_INVALID_SGL_EXCESS_LENGTH) || \
    false)

static inline void _nocheck__trace_pci_nvme_err_invalid_sgl_excess_length(uint16_t cid)
{
    if (trace_event_get_state(TRACE_PCI_NVME_ERR_INVALID_SGL_EXCESS_LENGTH) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_err_invalid_sgl_excess_length " "cid %"PRIu16"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , cid);
    }
}

static inline void trace_pci_nvme_err_invalid_sgl_excess_length(uint16_t cid)
{
    if (true) {
        _nocheck__trace_pci_nvme_err_invalid_sgl_excess_length(cid);
    }
}

#define TRACE_PCI_NVME_ERR_INVALID_DMA_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_ERR_INVALID_DMA) || \
    false)

static inline void _nocheck__trace_pci_nvme_err_invalid_dma(void)
{
    if (trace_event_get_state(TRACE_PCI_NVME_ERR_INVALID_DMA) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_err_invalid_dma " "PRP/SGL is too small for transfer size" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_pci_nvme_err_invalid_dma(void)
{
    if (true) {
        _nocheck__trace_pci_nvme_err_invalid_dma();
    }
}

#define TRACE_PCI_NVME_ERR_INVALID_PRPLIST_ENT_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_ERR_INVALID_PRPLIST_ENT) || \
    false)

static inline void _nocheck__trace_pci_nvme_err_invalid_prplist_ent(uint64_t prplist)
{
    if (trace_event_get_state(TRACE_PCI_NVME_ERR_INVALID_PRPLIST_ENT) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_err_invalid_prplist_ent " "PRP list entry is not page aligned: 0x%"PRIx64"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , prplist);
    }
}

static inline void trace_pci_nvme_err_invalid_prplist_ent(uint64_t prplist)
{
    if (true) {
        _nocheck__trace_pci_nvme_err_invalid_prplist_ent(prplist);
    }
}

#define TRACE_PCI_NVME_ERR_INVALID_PRP2_ALIGN_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_ERR_INVALID_PRP2_ALIGN) || \
    false)

static inline void _nocheck__trace_pci_nvme_err_invalid_prp2_align(uint64_t prp2)
{
    if (trace_event_get_state(TRACE_PCI_NVME_ERR_INVALID_PRP2_ALIGN) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_err_invalid_prp2_align " "PRP2 is not page aligned: 0x%"PRIx64"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , prp2);
    }
}

static inline void trace_pci_nvme_err_invalid_prp2_align(uint64_t prp2)
{
    if (true) {
        _nocheck__trace_pci_nvme_err_invalid_prp2_align(prp2);
    }
}

#define TRACE_PCI_NVME_ERR_INVALID_OPC_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_ERR_INVALID_OPC) || \
    false)

static inline void _nocheck__trace_pci_nvme_err_invalid_opc(uint8_t opc)
{
    if (trace_event_get_state(TRACE_PCI_NVME_ERR_INVALID_OPC) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_err_invalid_opc " "invalid opcode 0x%"PRIx8"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , opc);
    }
}

static inline void trace_pci_nvme_err_invalid_opc(uint8_t opc)
{
    if (true) {
        _nocheck__trace_pci_nvme_err_invalid_opc(opc);
    }
}

#define TRACE_PCI_NVME_ERR_INVALID_ADMIN_OPC_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_ERR_INVALID_ADMIN_OPC) || \
    false)

static inline void _nocheck__trace_pci_nvme_err_invalid_admin_opc(uint8_t opc)
{
    if (trace_event_get_state(TRACE_PCI_NVME_ERR_INVALID_ADMIN_OPC) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_err_invalid_admin_opc " "invalid admin opcode 0x%"PRIx8"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , opc);
    }
}

static inline void trace_pci_nvme_err_invalid_admin_opc(uint8_t opc)
{
    if (true) {
        _nocheck__trace_pci_nvme_err_invalid_admin_opc(opc);
    }
}

#define TRACE_PCI_NVME_ERR_INVALID_LBA_RANGE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_ERR_INVALID_LBA_RANGE) || \
    false)

static inline void _nocheck__trace_pci_nvme_err_invalid_lba_range(uint64_t start, uint64_t len, uint64_t limit)
{
    if (trace_event_get_state(TRACE_PCI_NVME_ERR_INVALID_LBA_RANGE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_err_invalid_lba_range " "Invalid LBA start=%"PRIu64" len=%"PRIu64" limit=%"PRIu64"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , start, len, limit);
    }
}

static inline void trace_pci_nvme_err_invalid_lba_range(uint64_t start, uint64_t len, uint64_t limit)
{
    if (true) {
        _nocheck__trace_pci_nvme_err_invalid_lba_range(start, len, limit);
    }
}

#define TRACE_PCI_NVME_ERR_INVALID_DEL_SQ_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_ERR_INVALID_DEL_SQ) || \
    false)

static inline void _nocheck__trace_pci_nvme_err_invalid_del_sq(uint16_t qid)
{
    if (trace_event_get_state(TRACE_PCI_NVME_ERR_INVALID_DEL_SQ) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_err_invalid_del_sq " "invalid submission queue deletion, sid=%"PRIu16"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , qid);
    }
}

static inline void trace_pci_nvme_err_invalid_del_sq(uint16_t qid)
{
    if (true) {
        _nocheck__trace_pci_nvme_err_invalid_del_sq(qid);
    }
}

#define TRACE_PCI_NVME_ERR_INVALID_CREATE_SQ_CQID_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_ERR_INVALID_CREATE_SQ_CQID) || \
    false)

static inline void _nocheck__trace_pci_nvme_err_invalid_create_sq_cqid(uint16_t cqid)
{
    if (trace_event_get_state(TRACE_PCI_NVME_ERR_INVALID_CREATE_SQ_CQID) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_err_invalid_create_sq_cqid " "failed creating submission queue, invalid cqid=%"PRIu16"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , cqid);
    }
}

static inline void trace_pci_nvme_err_invalid_create_sq_cqid(uint16_t cqid)
{
    if (true) {
        _nocheck__trace_pci_nvme_err_invalid_create_sq_cqid(cqid);
    }
}

#define TRACE_PCI_NVME_ERR_INVALID_CREATE_SQ_SQID_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_ERR_INVALID_CREATE_SQ_SQID) || \
    false)

static inline void _nocheck__trace_pci_nvme_err_invalid_create_sq_sqid(uint16_t sqid)
{
    if (trace_event_get_state(TRACE_PCI_NVME_ERR_INVALID_CREATE_SQ_SQID) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_err_invalid_create_sq_sqid " "failed creating submission queue, invalid sqid=%"PRIu16"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , sqid);
    }
}

static inline void trace_pci_nvme_err_invalid_create_sq_sqid(uint16_t sqid)
{
    if (true) {
        _nocheck__trace_pci_nvme_err_invalid_create_sq_sqid(sqid);
    }
}

#define TRACE_PCI_NVME_ERR_INVALID_CREATE_SQ_SIZE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_ERR_INVALID_CREATE_SQ_SIZE) || \
    false)

static inline void _nocheck__trace_pci_nvme_err_invalid_create_sq_size(uint16_t qsize)
{
    if (trace_event_get_state(TRACE_PCI_NVME_ERR_INVALID_CREATE_SQ_SIZE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_err_invalid_create_sq_size " "failed creating submission queue, invalid qsize=%"PRIu16"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , qsize);
    }
}

static inline void trace_pci_nvme_err_invalid_create_sq_size(uint16_t qsize)
{
    if (true) {
        _nocheck__trace_pci_nvme_err_invalid_create_sq_size(qsize);
    }
}

#define TRACE_PCI_NVME_ERR_INVALID_CREATE_SQ_ADDR_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_ERR_INVALID_CREATE_SQ_ADDR) || \
    false)

static inline void _nocheck__trace_pci_nvme_err_invalid_create_sq_addr(uint64_t addr)
{
    if (trace_event_get_state(TRACE_PCI_NVME_ERR_INVALID_CREATE_SQ_ADDR) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_err_invalid_create_sq_addr " "failed creating submission queue, addr=0x%"PRIx64"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , addr);
    }
}

static inline void trace_pci_nvme_err_invalid_create_sq_addr(uint64_t addr)
{
    if (true) {
        _nocheck__trace_pci_nvme_err_invalid_create_sq_addr(addr);
    }
}

#define TRACE_PCI_NVME_ERR_INVALID_CREATE_SQ_QFLAGS_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_ERR_INVALID_CREATE_SQ_QFLAGS) || \
    false)

static inline void _nocheck__trace_pci_nvme_err_invalid_create_sq_qflags(uint16_t qflags)
{
    if (trace_event_get_state(TRACE_PCI_NVME_ERR_INVALID_CREATE_SQ_QFLAGS) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_err_invalid_create_sq_qflags " "failed creating submission queue, qflags=%"PRIu16"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , qflags);
    }
}

static inline void trace_pci_nvme_err_invalid_create_sq_qflags(uint16_t qflags)
{
    if (true) {
        _nocheck__trace_pci_nvme_err_invalid_create_sq_qflags(qflags);
    }
}

#define TRACE_PCI_NVME_ERR_INVALID_DEL_CQ_CQID_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_ERR_INVALID_DEL_CQ_CQID) || \
    false)

static inline void _nocheck__trace_pci_nvme_err_invalid_del_cq_cqid(uint16_t cqid)
{
    if (trace_event_get_state(TRACE_PCI_NVME_ERR_INVALID_DEL_CQ_CQID) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_err_invalid_del_cq_cqid " "failed deleting completion queue, cqid=%"PRIu16"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , cqid);
    }
}

static inline void trace_pci_nvme_err_invalid_del_cq_cqid(uint16_t cqid)
{
    if (true) {
        _nocheck__trace_pci_nvme_err_invalid_del_cq_cqid(cqid);
    }
}

#define TRACE_PCI_NVME_ERR_INVALID_DEL_CQ_NOTEMPTY_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_ERR_INVALID_DEL_CQ_NOTEMPTY) || \
    false)

static inline void _nocheck__trace_pci_nvme_err_invalid_del_cq_notempty(uint16_t cqid)
{
    if (trace_event_get_state(TRACE_PCI_NVME_ERR_INVALID_DEL_CQ_NOTEMPTY) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_err_invalid_del_cq_notempty " "failed deleting completion queue, it is not empty, cqid=%"PRIu16"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , cqid);
    }
}

static inline void trace_pci_nvme_err_invalid_del_cq_notempty(uint16_t cqid)
{
    if (true) {
        _nocheck__trace_pci_nvme_err_invalid_del_cq_notempty(cqid);
    }
}

#define TRACE_PCI_NVME_ERR_INVALID_CREATE_CQ_CQID_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_ERR_INVALID_CREATE_CQ_CQID) || \
    false)

static inline void _nocheck__trace_pci_nvme_err_invalid_create_cq_cqid(uint16_t cqid)
{
    if (trace_event_get_state(TRACE_PCI_NVME_ERR_INVALID_CREATE_CQ_CQID) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_err_invalid_create_cq_cqid " "failed creating completion queue, cqid=%"PRIu16"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , cqid);
    }
}

static inline void trace_pci_nvme_err_invalid_create_cq_cqid(uint16_t cqid)
{
    if (true) {
        _nocheck__trace_pci_nvme_err_invalid_create_cq_cqid(cqid);
    }
}

#define TRACE_PCI_NVME_ERR_INVALID_CREATE_CQ_SIZE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_ERR_INVALID_CREATE_CQ_SIZE) || \
    false)

static inline void _nocheck__trace_pci_nvme_err_invalid_create_cq_size(uint16_t size)
{
    if (trace_event_get_state(TRACE_PCI_NVME_ERR_INVALID_CREATE_CQ_SIZE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_err_invalid_create_cq_size " "failed creating completion queue, size=%"PRIu16"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , size);
    }
}

static inline void trace_pci_nvme_err_invalid_create_cq_size(uint16_t size)
{
    if (true) {
        _nocheck__trace_pci_nvme_err_invalid_create_cq_size(size);
    }
}

#define TRACE_PCI_NVME_ERR_INVALID_CREATE_CQ_ADDR_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_ERR_INVALID_CREATE_CQ_ADDR) || \
    false)

static inline void _nocheck__trace_pci_nvme_err_invalid_create_cq_addr(uint64_t addr)
{
    if (trace_event_get_state(TRACE_PCI_NVME_ERR_INVALID_CREATE_CQ_ADDR) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_err_invalid_create_cq_addr " "failed creating completion queue, addr=0x%"PRIx64"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , addr);
    }
}

static inline void trace_pci_nvme_err_invalid_create_cq_addr(uint64_t addr)
{
    if (true) {
        _nocheck__trace_pci_nvme_err_invalid_create_cq_addr(addr);
    }
}

#define TRACE_PCI_NVME_ERR_INVALID_CREATE_CQ_VECTOR_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_ERR_INVALID_CREATE_CQ_VECTOR) || \
    false)

static inline void _nocheck__trace_pci_nvme_err_invalid_create_cq_vector(uint16_t vector)
{
    if (trace_event_get_state(TRACE_PCI_NVME_ERR_INVALID_CREATE_CQ_VECTOR) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_err_invalid_create_cq_vector " "failed creating completion queue, vector=%"PRIu16"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , vector);
    }
}

static inline void trace_pci_nvme_err_invalid_create_cq_vector(uint16_t vector)
{
    if (true) {
        _nocheck__trace_pci_nvme_err_invalid_create_cq_vector(vector);
    }
}

#define TRACE_PCI_NVME_ERR_INVALID_CREATE_CQ_QFLAGS_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_ERR_INVALID_CREATE_CQ_QFLAGS) || \
    false)

static inline void _nocheck__trace_pci_nvme_err_invalid_create_cq_qflags(uint16_t qflags)
{
    if (trace_event_get_state(TRACE_PCI_NVME_ERR_INVALID_CREATE_CQ_QFLAGS) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_err_invalid_create_cq_qflags " "failed creating completion queue, qflags=%"PRIu16"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , qflags);
    }
}

static inline void trace_pci_nvme_err_invalid_create_cq_qflags(uint16_t qflags)
{
    if (true) {
        _nocheck__trace_pci_nvme_err_invalid_create_cq_qflags(qflags);
    }
}

#define TRACE_PCI_NVME_ERR_INVALID_IDENTIFY_CNS_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_ERR_INVALID_IDENTIFY_CNS) || \
    false)

static inline void _nocheck__trace_pci_nvme_err_invalid_identify_cns(uint16_t cns)
{
    if (trace_event_get_state(TRACE_PCI_NVME_ERR_INVALID_IDENTIFY_CNS) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_err_invalid_identify_cns " "identify, invalid cns=0x%"PRIx16"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , cns);
    }
}

static inline void trace_pci_nvme_err_invalid_identify_cns(uint16_t cns)
{
    if (true) {
        _nocheck__trace_pci_nvme_err_invalid_identify_cns(cns);
    }
}

#define TRACE_PCI_NVME_ERR_INVALID_GETFEAT_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_ERR_INVALID_GETFEAT) || \
    false)

static inline void _nocheck__trace_pci_nvme_err_invalid_getfeat(int dw10)
{
    if (trace_event_get_state(TRACE_PCI_NVME_ERR_INVALID_GETFEAT) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_err_invalid_getfeat " "invalid get features, dw10=0x%"PRIx32"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , dw10);
    }
}

static inline void trace_pci_nvme_err_invalid_getfeat(int dw10)
{
    if (true) {
        _nocheck__trace_pci_nvme_err_invalid_getfeat(dw10);
    }
}

#define TRACE_PCI_NVME_ERR_INVALID_SETFEAT_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_ERR_INVALID_SETFEAT) || \
    false)

static inline void _nocheck__trace_pci_nvme_err_invalid_setfeat(uint32_t dw10)
{
    if (trace_event_get_state(TRACE_PCI_NVME_ERR_INVALID_SETFEAT) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_err_invalid_setfeat " "invalid set features, dw10=0x%"PRIx32"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , dw10);
    }
}

static inline void trace_pci_nvme_err_invalid_setfeat(uint32_t dw10)
{
    if (true) {
        _nocheck__trace_pci_nvme_err_invalid_setfeat(dw10);
    }
}

#define TRACE_PCI_NVME_ERR_INVALID_LOG_PAGE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_ERR_INVALID_LOG_PAGE) || \
    false)

static inline void _nocheck__trace_pci_nvme_err_invalid_log_page(uint16_t cid, uint16_t lid)
{
    if (trace_event_get_state(TRACE_PCI_NVME_ERR_INVALID_LOG_PAGE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_err_invalid_log_page " "cid %"PRIu16" lid 0x%"PRIx16"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , cid, lid);
    }
}

static inline void trace_pci_nvme_err_invalid_log_page(uint16_t cid, uint16_t lid)
{
    if (true) {
        _nocheck__trace_pci_nvme_err_invalid_log_page(cid, lid);
    }
}

#define TRACE_PCI_NVME_ERR_STARTFAIL_CQ_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_ERR_STARTFAIL_CQ) || \
    false)

static inline void _nocheck__trace_pci_nvme_err_startfail_cq(void)
{
    if (trace_event_get_state(TRACE_PCI_NVME_ERR_STARTFAIL_CQ) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_err_startfail_cq " "nvme_start_ctrl failed because there are non-admin completion queues" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_pci_nvme_err_startfail_cq(void)
{
    if (true) {
        _nocheck__trace_pci_nvme_err_startfail_cq();
    }
}

#define TRACE_PCI_NVME_ERR_STARTFAIL_SQ_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_ERR_STARTFAIL_SQ) || \
    false)

static inline void _nocheck__trace_pci_nvme_err_startfail_sq(void)
{
    if (trace_event_get_state(TRACE_PCI_NVME_ERR_STARTFAIL_SQ) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_err_startfail_sq " "nvme_start_ctrl failed because there are non-admin submission queues" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_pci_nvme_err_startfail_sq(void)
{
    if (true) {
        _nocheck__trace_pci_nvme_err_startfail_sq();
    }
}

#define TRACE_PCI_NVME_ERR_STARTFAIL_NBARASQ_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_ERR_STARTFAIL_NBARASQ) || \
    false)

static inline void _nocheck__trace_pci_nvme_err_startfail_nbarasq(void)
{
    if (trace_event_get_state(TRACE_PCI_NVME_ERR_STARTFAIL_NBARASQ) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_err_startfail_nbarasq " "nvme_start_ctrl failed because the admin submission queue address is null" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_pci_nvme_err_startfail_nbarasq(void)
{
    if (true) {
        _nocheck__trace_pci_nvme_err_startfail_nbarasq();
    }
}

#define TRACE_PCI_NVME_ERR_STARTFAIL_NBARACQ_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_ERR_STARTFAIL_NBARACQ) || \
    false)

static inline void _nocheck__trace_pci_nvme_err_startfail_nbaracq(void)
{
    if (trace_event_get_state(TRACE_PCI_NVME_ERR_STARTFAIL_NBARACQ) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_err_startfail_nbaracq " "nvme_start_ctrl failed because the admin completion queue address is null" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_pci_nvme_err_startfail_nbaracq(void)
{
    if (true) {
        _nocheck__trace_pci_nvme_err_startfail_nbaracq();
    }
}

#define TRACE_PCI_NVME_ERR_STARTFAIL_ASQ_MISALIGNED_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_ERR_STARTFAIL_ASQ_MISALIGNED) || \
    false)

static inline void _nocheck__trace_pci_nvme_err_startfail_asq_misaligned(uint64_t addr)
{
    if (trace_event_get_state(TRACE_PCI_NVME_ERR_STARTFAIL_ASQ_MISALIGNED) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_err_startfail_asq_misaligned " "nvme_start_ctrl failed because the admin submission queue address is misaligned: 0x%"PRIx64"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , addr);
    }
}

static inline void trace_pci_nvme_err_startfail_asq_misaligned(uint64_t addr)
{
    if (true) {
        _nocheck__trace_pci_nvme_err_startfail_asq_misaligned(addr);
    }
}

#define TRACE_PCI_NVME_ERR_STARTFAIL_ACQ_MISALIGNED_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_ERR_STARTFAIL_ACQ_MISALIGNED) || \
    false)

static inline void _nocheck__trace_pci_nvme_err_startfail_acq_misaligned(uint64_t addr)
{
    if (trace_event_get_state(TRACE_PCI_NVME_ERR_STARTFAIL_ACQ_MISALIGNED) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_err_startfail_acq_misaligned " "nvme_start_ctrl failed because the admin completion queue address is misaligned: 0x%"PRIx64"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , addr);
    }
}

static inline void trace_pci_nvme_err_startfail_acq_misaligned(uint64_t addr)
{
    if (true) {
        _nocheck__trace_pci_nvme_err_startfail_acq_misaligned(addr);
    }
}

#define TRACE_PCI_NVME_ERR_STARTFAIL_PAGE_TOO_SMALL_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_ERR_STARTFAIL_PAGE_TOO_SMALL) || \
    false)

static inline void _nocheck__trace_pci_nvme_err_startfail_page_too_small(uint8_t log2ps, uint8_t maxlog2ps)
{
    if (trace_event_get_state(TRACE_PCI_NVME_ERR_STARTFAIL_PAGE_TOO_SMALL) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_err_startfail_page_too_small " "nvme_start_ctrl failed because the page size is too small: log2size=%u, min=%u" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , log2ps, maxlog2ps);
    }
}

static inline void trace_pci_nvme_err_startfail_page_too_small(uint8_t log2ps, uint8_t maxlog2ps)
{
    if (true) {
        _nocheck__trace_pci_nvme_err_startfail_page_too_small(log2ps, maxlog2ps);
    }
}

#define TRACE_PCI_NVME_ERR_STARTFAIL_PAGE_TOO_LARGE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_ERR_STARTFAIL_PAGE_TOO_LARGE) || \
    false)

static inline void _nocheck__trace_pci_nvme_err_startfail_page_too_large(uint8_t log2ps, uint8_t maxlog2ps)
{
    if (trace_event_get_state(TRACE_PCI_NVME_ERR_STARTFAIL_PAGE_TOO_LARGE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_err_startfail_page_too_large " "nvme_start_ctrl failed because the page size is too large: log2size=%u, max=%u" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , log2ps, maxlog2ps);
    }
}

static inline void trace_pci_nvme_err_startfail_page_too_large(uint8_t log2ps, uint8_t maxlog2ps)
{
    if (true) {
        _nocheck__trace_pci_nvme_err_startfail_page_too_large(log2ps, maxlog2ps);
    }
}

#define TRACE_PCI_NVME_ERR_STARTFAIL_CQENT_TOO_SMALL_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_ERR_STARTFAIL_CQENT_TOO_SMALL) || \
    false)

static inline void _nocheck__trace_pci_nvme_err_startfail_cqent_too_small(uint8_t log2ps, uint8_t maxlog2ps)
{
    if (trace_event_get_state(TRACE_PCI_NVME_ERR_STARTFAIL_CQENT_TOO_SMALL) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_err_startfail_cqent_too_small " "nvme_start_ctrl failed because the completion queue entry size is too small: log2size=%u, min=%u" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , log2ps, maxlog2ps);
    }
}

static inline void trace_pci_nvme_err_startfail_cqent_too_small(uint8_t log2ps, uint8_t maxlog2ps)
{
    if (true) {
        _nocheck__trace_pci_nvme_err_startfail_cqent_too_small(log2ps, maxlog2ps);
    }
}

#define TRACE_PCI_NVME_ERR_STARTFAIL_CQENT_TOO_LARGE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_ERR_STARTFAIL_CQENT_TOO_LARGE) || \
    false)

static inline void _nocheck__trace_pci_nvme_err_startfail_cqent_too_large(uint8_t log2ps, uint8_t maxlog2ps)
{
    if (trace_event_get_state(TRACE_PCI_NVME_ERR_STARTFAIL_CQENT_TOO_LARGE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_err_startfail_cqent_too_large " "nvme_start_ctrl failed because the completion queue entry size is too large: log2size=%u, max=%u" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , log2ps, maxlog2ps);
    }
}

static inline void trace_pci_nvme_err_startfail_cqent_too_large(uint8_t log2ps, uint8_t maxlog2ps)
{
    if (true) {
        _nocheck__trace_pci_nvme_err_startfail_cqent_too_large(log2ps, maxlog2ps);
    }
}

#define TRACE_PCI_NVME_ERR_STARTFAIL_SQENT_TOO_SMALL_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_ERR_STARTFAIL_SQENT_TOO_SMALL) || \
    false)

static inline void _nocheck__trace_pci_nvme_err_startfail_sqent_too_small(uint8_t log2ps, uint8_t maxlog2ps)
{
    if (trace_event_get_state(TRACE_PCI_NVME_ERR_STARTFAIL_SQENT_TOO_SMALL) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_err_startfail_sqent_too_small " "nvme_start_ctrl failed because the submission queue entry size is too small: log2size=%u, min=%u" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , log2ps, maxlog2ps);
    }
}

static inline void trace_pci_nvme_err_startfail_sqent_too_small(uint8_t log2ps, uint8_t maxlog2ps)
{
    if (true) {
        _nocheck__trace_pci_nvme_err_startfail_sqent_too_small(log2ps, maxlog2ps);
    }
}

#define TRACE_PCI_NVME_ERR_STARTFAIL_SQENT_TOO_LARGE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_ERR_STARTFAIL_SQENT_TOO_LARGE) || \
    false)

static inline void _nocheck__trace_pci_nvme_err_startfail_sqent_too_large(uint8_t log2ps, uint8_t maxlog2ps)
{
    if (trace_event_get_state(TRACE_PCI_NVME_ERR_STARTFAIL_SQENT_TOO_LARGE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_err_startfail_sqent_too_large " "nvme_start_ctrl failed because the submission queue entry size is too large: log2size=%u, max=%u" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , log2ps, maxlog2ps);
    }
}

static inline void trace_pci_nvme_err_startfail_sqent_too_large(uint8_t log2ps, uint8_t maxlog2ps)
{
    if (true) {
        _nocheck__trace_pci_nvme_err_startfail_sqent_too_large(log2ps, maxlog2ps);
    }
}

#define TRACE_PCI_NVME_ERR_STARTFAIL_CSS_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_ERR_STARTFAIL_CSS) || \
    false)

static inline void _nocheck__trace_pci_nvme_err_startfail_css(uint8_t css)
{
    if (trace_event_get_state(TRACE_PCI_NVME_ERR_STARTFAIL_CSS) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_err_startfail_css " "nvme_start_ctrl failed because invalid command set selected:%u" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , css);
    }
}

static inline void trace_pci_nvme_err_startfail_css(uint8_t css)
{
    if (true) {
        _nocheck__trace_pci_nvme_err_startfail_css(css);
    }
}

#define TRACE_PCI_NVME_ERR_STARTFAIL_ASQENT_SZ_ZERO_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_ERR_STARTFAIL_ASQENT_SZ_ZERO) || \
    false)

static inline void _nocheck__trace_pci_nvme_err_startfail_asqent_sz_zero(void)
{
    if (trace_event_get_state(TRACE_PCI_NVME_ERR_STARTFAIL_ASQENT_SZ_ZERO) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_err_startfail_asqent_sz_zero " "nvme_start_ctrl failed because the admin submission queue size is zero" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_pci_nvme_err_startfail_asqent_sz_zero(void)
{
    if (true) {
        _nocheck__trace_pci_nvme_err_startfail_asqent_sz_zero();
    }
}

#define TRACE_PCI_NVME_ERR_STARTFAIL_ACQENT_SZ_ZERO_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_ERR_STARTFAIL_ACQENT_SZ_ZERO) || \
    false)

static inline void _nocheck__trace_pci_nvme_err_startfail_acqent_sz_zero(void)
{
    if (trace_event_get_state(TRACE_PCI_NVME_ERR_STARTFAIL_ACQENT_SZ_ZERO) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_err_startfail_acqent_sz_zero " "nvme_start_ctrl failed because the admin completion queue size is zero" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_pci_nvme_err_startfail_acqent_sz_zero(void)
{
    if (true) {
        _nocheck__trace_pci_nvme_err_startfail_acqent_sz_zero();
    }
}

#define TRACE_PCI_NVME_ERR_STARTFAIL_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_ERR_STARTFAIL) || \
    false)

static inline void _nocheck__trace_pci_nvme_err_startfail(void)
{
    if (trace_event_get_state(TRACE_PCI_NVME_ERR_STARTFAIL) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_err_startfail " "setting controller enable bit failed" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_pci_nvme_err_startfail(void)
{
    if (true) {
        _nocheck__trace_pci_nvme_err_startfail();
    }
}

#define TRACE_PCI_NVME_UB_MMIOWR_MISALIGNED32_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_UB_MMIOWR_MISALIGNED32) || \
    false)

static inline void _nocheck__trace_pci_nvme_ub_mmiowr_misaligned32(uint64_t offset)
{
    if (trace_event_get_state(TRACE_PCI_NVME_UB_MMIOWR_MISALIGNED32) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_ub_mmiowr_misaligned32 " "MMIO write not 32-bit aligned, offset=0x%"PRIx64"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , offset);
    }
}

static inline void trace_pci_nvme_ub_mmiowr_misaligned32(uint64_t offset)
{
    if (true) {
        _nocheck__trace_pci_nvme_ub_mmiowr_misaligned32(offset);
    }
}

#define TRACE_PCI_NVME_UB_MMIOWR_TOOSMALL_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_UB_MMIOWR_TOOSMALL) || \
    false)

static inline void _nocheck__trace_pci_nvme_ub_mmiowr_toosmall(uint64_t offset, unsigned size)
{
    if (trace_event_get_state(TRACE_PCI_NVME_UB_MMIOWR_TOOSMALL) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_ub_mmiowr_toosmall " "MMIO write smaller than 32 bits, offset=0x%"PRIx64", size=%u" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , offset, size);
    }
}

static inline void trace_pci_nvme_ub_mmiowr_toosmall(uint64_t offset, unsigned size)
{
    if (true) {
        _nocheck__trace_pci_nvme_ub_mmiowr_toosmall(offset, size);
    }
}

#define TRACE_PCI_NVME_UB_MMIOWR_INTMASK_WITH_MSIX_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_UB_MMIOWR_INTMASK_WITH_MSIX) || \
    false)

static inline void _nocheck__trace_pci_nvme_ub_mmiowr_intmask_with_msix(void)
{
    if (trace_event_get_state(TRACE_PCI_NVME_UB_MMIOWR_INTMASK_WITH_MSIX) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_ub_mmiowr_intmask_with_msix " "undefined access to interrupt mask set when MSI-X is enabled" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_pci_nvme_ub_mmiowr_intmask_with_msix(void)
{
    if (true) {
        _nocheck__trace_pci_nvme_ub_mmiowr_intmask_with_msix();
    }
}

#define TRACE_PCI_NVME_UB_MMIOWR_RO_CSTS_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_UB_MMIOWR_RO_CSTS) || \
    false)

static inline void _nocheck__trace_pci_nvme_ub_mmiowr_ro_csts(void)
{
    if (trace_event_get_state(TRACE_PCI_NVME_UB_MMIOWR_RO_CSTS) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_ub_mmiowr_ro_csts " "attempted to set a read only bit of controller status" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_pci_nvme_ub_mmiowr_ro_csts(void)
{
    if (true) {
        _nocheck__trace_pci_nvme_ub_mmiowr_ro_csts();
    }
}

#define TRACE_PCI_NVME_UB_MMIOWR_SSRESET_W1C_UNSUPPORTED_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_UB_MMIOWR_SSRESET_W1C_UNSUPPORTED) || \
    false)

static inline void _nocheck__trace_pci_nvme_ub_mmiowr_ssreset_w1c_unsupported(void)
{
    if (trace_event_get_state(TRACE_PCI_NVME_UB_MMIOWR_SSRESET_W1C_UNSUPPORTED) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_ub_mmiowr_ssreset_w1c_unsupported " "attempted to W1C CSTS.NSSRO but CAP.NSSRS is zero (not supported)" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_pci_nvme_ub_mmiowr_ssreset_w1c_unsupported(void)
{
    if (true) {
        _nocheck__trace_pci_nvme_ub_mmiowr_ssreset_w1c_unsupported();
    }
}

#define TRACE_PCI_NVME_UB_MMIOWR_SSRESET_UNSUPPORTED_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_UB_MMIOWR_SSRESET_UNSUPPORTED) || \
    false)

static inline void _nocheck__trace_pci_nvme_ub_mmiowr_ssreset_unsupported(void)
{
    if (trace_event_get_state(TRACE_PCI_NVME_UB_MMIOWR_SSRESET_UNSUPPORTED) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_ub_mmiowr_ssreset_unsupported " "attempted NVM subsystem reset but CAP.NSSRS is zero (not supported)" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_pci_nvme_ub_mmiowr_ssreset_unsupported(void)
{
    if (true) {
        _nocheck__trace_pci_nvme_ub_mmiowr_ssreset_unsupported();
    }
}

#define TRACE_PCI_NVME_UB_MMIOWR_CMBLOC_RESERVED_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_UB_MMIOWR_CMBLOC_RESERVED) || \
    false)

static inline void _nocheck__trace_pci_nvme_ub_mmiowr_cmbloc_reserved(void)
{
    if (trace_event_get_state(TRACE_PCI_NVME_UB_MMIOWR_CMBLOC_RESERVED) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_ub_mmiowr_cmbloc_reserved " "invalid write to reserved CMBLOC when CMBSZ is zero, ignored" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_pci_nvme_ub_mmiowr_cmbloc_reserved(void)
{
    if (true) {
        _nocheck__trace_pci_nvme_ub_mmiowr_cmbloc_reserved();
    }
}

#define TRACE_PCI_NVME_UB_MMIOWR_CMBSZ_READONLY_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_UB_MMIOWR_CMBSZ_READONLY) || \
    false)

static inline void _nocheck__trace_pci_nvme_ub_mmiowr_cmbsz_readonly(void)
{
    if (trace_event_get_state(TRACE_PCI_NVME_UB_MMIOWR_CMBSZ_READONLY) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_ub_mmiowr_cmbsz_readonly " "invalid write to read only CMBSZ, ignored" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_pci_nvme_ub_mmiowr_cmbsz_readonly(void)
{
    if (true) {
        _nocheck__trace_pci_nvme_ub_mmiowr_cmbsz_readonly();
    }
}

#define TRACE_PCI_NVME_UB_MMIOWR_PMRCAP_READONLY_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_UB_MMIOWR_PMRCAP_READONLY) || \
    false)

static inline void _nocheck__trace_pci_nvme_ub_mmiowr_pmrcap_readonly(void)
{
    if (trace_event_get_state(TRACE_PCI_NVME_UB_MMIOWR_PMRCAP_READONLY) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_ub_mmiowr_pmrcap_readonly " "invalid write to read only PMRCAP, ignored" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_pci_nvme_ub_mmiowr_pmrcap_readonly(void)
{
    if (true) {
        _nocheck__trace_pci_nvme_ub_mmiowr_pmrcap_readonly();
    }
}

#define TRACE_PCI_NVME_UB_MMIOWR_PMRSTS_READONLY_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_UB_MMIOWR_PMRSTS_READONLY) || \
    false)

static inline void _nocheck__trace_pci_nvme_ub_mmiowr_pmrsts_readonly(void)
{
    if (trace_event_get_state(TRACE_PCI_NVME_UB_MMIOWR_PMRSTS_READONLY) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_ub_mmiowr_pmrsts_readonly " "invalid write to read only PMRSTS, ignored" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_pci_nvme_ub_mmiowr_pmrsts_readonly(void)
{
    if (true) {
        _nocheck__trace_pci_nvme_ub_mmiowr_pmrsts_readonly();
    }
}

#define TRACE_PCI_NVME_UB_MMIOWR_PMREBS_READONLY_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_UB_MMIOWR_PMREBS_READONLY) || \
    false)

static inline void _nocheck__trace_pci_nvme_ub_mmiowr_pmrebs_readonly(void)
{
    if (trace_event_get_state(TRACE_PCI_NVME_UB_MMIOWR_PMREBS_READONLY) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_ub_mmiowr_pmrebs_readonly " "invalid write to read only PMREBS, ignored" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_pci_nvme_ub_mmiowr_pmrebs_readonly(void)
{
    if (true) {
        _nocheck__trace_pci_nvme_ub_mmiowr_pmrebs_readonly();
    }
}

#define TRACE_PCI_NVME_UB_MMIOWR_PMRSWTP_READONLY_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_UB_MMIOWR_PMRSWTP_READONLY) || \
    false)

static inline void _nocheck__trace_pci_nvme_ub_mmiowr_pmrswtp_readonly(void)
{
    if (trace_event_get_state(TRACE_PCI_NVME_UB_MMIOWR_PMRSWTP_READONLY) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_ub_mmiowr_pmrswtp_readonly " "invalid write to read only PMRSWTP, ignored" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_pci_nvme_ub_mmiowr_pmrswtp_readonly(void)
{
    if (true) {
        _nocheck__trace_pci_nvme_ub_mmiowr_pmrswtp_readonly();
    }
}

#define TRACE_PCI_NVME_UB_MMIOWR_INVALID_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_UB_MMIOWR_INVALID) || \
    false)

static inline void _nocheck__trace_pci_nvme_ub_mmiowr_invalid(uint64_t offset, uint64_t data)
{
    if (trace_event_get_state(TRACE_PCI_NVME_UB_MMIOWR_INVALID) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_ub_mmiowr_invalid " "invalid MMIO write, offset=0x%"PRIx64", data=0x%"PRIx64"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , offset, data);
    }
}

static inline void trace_pci_nvme_ub_mmiowr_invalid(uint64_t offset, uint64_t data)
{
    if (true) {
        _nocheck__trace_pci_nvme_ub_mmiowr_invalid(offset, data);
    }
}

#define TRACE_PCI_NVME_UB_MMIORD_MISALIGNED32_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_UB_MMIORD_MISALIGNED32) || \
    false)

static inline void _nocheck__trace_pci_nvme_ub_mmiord_misaligned32(uint64_t offset)
{
    if (trace_event_get_state(TRACE_PCI_NVME_UB_MMIORD_MISALIGNED32) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_ub_mmiord_misaligned32 " "MMIO read not 32-bit aligned, offset=0x%"PRIx64"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , offset);
    }
}

static inline void trace_pci_nvme_ub_mmiord_misaligned32(uint64_t offset)
{
    if (true) {
        _nocheck__trace_pci_nvme_ub_mmiord_misaligned32(offset);
    }
}

#define TRACE_PCI_NVME_UB_MMIORD_TOOSMALL_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_UB_MMIORD_TOOSMALL) || \
    false)

static inline void _nocheck__trace_pci_nvme_ub_mmiord_toosmall(uint64_t offset)
{
    if (trace_event_get_state(TRACE_PCI_NVME_UB_MMIORD_TOOSMALL) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_ub_mmiord_toosmall " "MMIO read smaller than 32-bits, offset=0x%"PRIx64"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , offset);
    }
}

static inline void trace_pci_nvme_ub_mmiord_toosmall(uint64_t offset)
{
    if (true) {
        _nocheck__trace_pci_nvme_ub_mmiord_toosmall(offset);
    }
}

#define TRACE_PCI_NVME_UB_MMIORD_INVALID_OFS_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_UB_MMIORD_INVALID_OFS) || \
    false)

static inline void _nocheck__trace_pci_nvme_ub_mmiord_invalid_ofs(uint64_t offset)
{
    if (trace_event_get_state(TRACE_PCI_NVME_UB_MMIORD_INVALID_OFS) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_ub_mmiord_invalid_ofs " "MMIO read beyond last register, offset=0x%"PRIx64", returning 0" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , offset);
    }
}

static inline void trace_pci_nvme_ub_mmiord_invalid_ofs(uint64_t offset)
{
    if (true) {
        _nocheck__trace_pci_nvme_ub_mmiord_invalid_ofs(offset);
    }
}

#define TRACE_PCI_NVME_UB_DB_WR_MISALIGNED_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_UB_DB_WR_MISALIGNED) || \
    false)

static inline void _nocheck__trace_pci_nvme_ub_db_wr_misaligned(uint64_t offset)
{
    if (trace_event_get_state(TRACE_PCI_NVME_UB_DB_WR_MISALIGNED) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_ub_db_wr_misaligned " "doorbell write not 32-bit aligned, offset=0x%"PRIx64", ignoring" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , offset);
    }
}

static inline void trace_pci_nvme_ub_db_wr_misaligned(uint64_t offset)
{
    if (true) {
        _nocheck__trace_pci_nvme_ub_db_wr_misaligned(offset);
    }
}

#define TRACE_PCI_NVME_UB_DB_WR_INVALID_CQ_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_UB_DB_WR_INVALID_CQ) || \
    false)

static inline void _nocheck__trace_pci_nvme_ub_db_wr_invalid_cq(uint32_t qid)
{
    if (trace_event_get_state(TRACE_PCI_NVME_UB_DB_WR_INVALID_CQ) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_ub_db_wr_invalid_cq " "completion queue doorbell write for nonexistent queue, cqid=%"PRIu32", ignoring" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , qid);
    }
}

static inline void trace_pci_nvme_ub_db_wr_invalid_cq(uint32_t qid)
{
    if (true) {
        _nocheck__trace_pci_nvme_ub_db_wr_invalid_cq(qid);
    }
}

#define TRACE_PCI_NVME_UB_DB_WR_INVALID_CQHEAD_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_UB_DB_WR_INVALID_CQHEAD) || \
    false)

static inline void _nocheck__trace_pci_nvme_ub_db_wr_invalid_cqhead(uint32_t qid, uint16_t new_head)
{
    if (trace_event_get_state(TRACE_PCI_NVME_UB_DB_WR_INVALID_CQHEAD) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_ub_db_wr_invalid_cqhead " "completion queue doorbell write value beyond queue size, cqid=%"PRIu32", new_head=%"PRIu16", ignoring" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , qid, new_head);
    }
}

static inline void trace_pci_nvme_ub_db_wr_invalid_cqhead(uint32_t qid, uint16_t new_head)
{
    if (true) {
        _nocheck__trace_pci_nvme_ub_db_wr_invalid_cqhead(qid, new_head);
    }
}

#define TRACE_PCI_NVME_UB_DB_WR_INVALID_SQ_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_UB_DB_WR_INVALID_SQ) || \
    false)

static inline void _nocheck__trace_pci_nvme_ub_db_wr_invalid_sq(uint32_t qid)
{
    if (trace_event_get_state(TRACE_PCI_NVME_UB_DB_WR_INVALID_SQ) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_ub_db_wr_invalid_sq " "submission queue doorbell write for nonexistent queue, sqid=%"PRIu32", ignoring" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , qid);
    }
}

static inline void trace_pci_nvme_ub_db_wr_invalid_sq(uint32_t qid)
{
    if (true) {
        _nocheck__trace_pci_nvme_ub_db_wr_invalid_sq(qid);
    }
}

#define TRACE_PCI_NVME_UB_DB_WR_INVALID_SQTAIL_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PCI_NVME_UB_DB_WR_INVALID_SQTAIL) || \
    false)

static inline void _nocheck__trace_pci_nvme_ub_db_wr_invalid_sqtail(uint32_t qid, uint16_t new_tail)
{
    if (trace_event_get_state(TRACE_PCI_NVME_UB_DB_WR_INVALID_SQTAIL) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pci_nvme_ub_db_wr_invalid_sqtail " "submission queue doorbell write value beyond queue size, sqid=%"PRIu32", new_head=%"PRIu16", ignoring" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , qid, new_tail);
    }
}

static inline void trace_pci_nvme_ub_db_wr_invalid_sqtail(uint32_t qid, uint16_t new_tail)
{
    if (true) {
        _nocheck__trace_pci_nvme_ub_db_wr_invalid_sqtail(qid, new_tail);
    }
}

#define TRACE_XEN_BLOCK_REALIZE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_XEN_BLOCK_REALIZE) || \
    false)

static inline void _nocheck__trace_xen_block_realize(const char * type, uint32_t disk, uint32_t partition)
{
    if (trace_event_get_state(TRACE_XEN_BLOCK_REALIZE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:xen_block_realize " "%s d%up%u" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , type, disk, partition);
    }
}

static inline void trace_xen_block_realize(const char * type, uint32_t disk, uint32_t partition)
{
    if (true) {
        _nocheck__trace_xen_block_realize(type, disk, partition);
    }
}

#define TRACE_XEN_BLOCK_CONNECT_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_XEN_BLOCK_CONNECT) || \
    false)

static inline void _nocheck__trace_xen_block_connect(const char * type, uint32_t disk, uint32_t partition)
{
    if (trace_event_get_state(TRACE_XEN_BLOCK_CONNECT) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:xen_block_connect " "%s d%up%u" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , type, disk, partition);
    }
}

static inline void trace_xen_block_connect(const char * type, uint32_t disk, uint32_t partition)
{
    if (true) {
        _nocheck__trace_xen_block_connect(type, disk, partition);
    }
}

#define TRACE_XEN_BLOCK_DISCONNECT_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_XEN_BLOCK_DISCONNECT) || \
    false)

static inline void _nocheck__trace_xen_block_disconnect(const char * type, uint32_t disk, uint32_t partition)
{
    if (trace_event_get_state(TRACE_XEN_BLOCK_DISCONNECT) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:xen_block_disconnect " "%s d%up%u" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , type, disk, partition);
    }
}

static inline void trace_xen_block_disconnect(const char * type, uint32_t disk, uint32_t partition)
{
    if (true) {
        _nocheck__trace_xen_block_disconnect(type, disk, partition);
    }
}

#define TRACE_XEN_BLOCK_UNREALIZE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_XEN_BLOCK_UNREALIZE) || \
    false)

static inline void _nocheck__trace_xen_block_unrealize(const char * type, uint32_t disk, uint32_t partition)
{
    if (trace_event_get_state(TRACE_XEN_BLOCK_UNREALIZE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:xen_block_unrealize " "%s d%up%u" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , type, disk, partition);
    }
}

static inline void trace_xen_block_unrealize(const char * type, uint32_t disk, uint32_t partition)
{
    if (true) {
        _nocheck__trace_xen_block_unrealize(type, disk, partition);
    }
}

#define TRACE_XEN_BLOCK_SIZE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_XEN_BLOCK_SIZE) || \
    false)

static inline void _nocheck__trace_xen_block_size(const char * type, uint32_t disk, uint32_t partition, int64_t sectors)
{
    if (trace_event_get_state(TRACE_XEN_BLOCK_SIZE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:xen_block_size " "%s d%up%u %"PRIi64 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , type, disk, partition, sectors);
    }
}

static inline void trace_xen_block_size(const char * type, uint32_t disk, uint32_t partition, int64_t sectors)
{
    if (true) {
        _nocheck__trace_xen_block_size(type, disk, partition, sectors);
    }
}

#define TRACE_XEN_DISK_REALIZE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_XEN_DISK_REALIZE) || \
    false)

static inline void _nocheck__trace_xen_disk_realize(void)
{
    if (trace_event_get_state(TRACE_XEN_DISK_REALIZE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:xen_disk_realize " "" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_xen_disk_realize(void)
{
    if (true) {
        _nocheck__trace_xen_disk_realize();
    }
}

#define TRACE_XEN_DISK_UNREALIZE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_XEN_DISK_UNREALIZE) || \
    false)

static inline void _nocheck__trace_xen_disk_unrealize(void)
{
    if (trace_event_get_state(TRACE_XEN_DISK_UNREALIZE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:xen_disk_unrealize " "" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_xen_disk_unrealize(void)
{
    if (true) {
        _nocheck__trace_xen_disk_unrealize();
    }
}

#define TRACE_XEN_CDROM_REALIZE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_XEN_CDROM_REALIZE) || \
    false)

static inline void _nocheck__trace_xen_cdrom_realize(void)
{
    if (trace_event_get_state(TRACE_XEN_CDROM_REALIZE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:xen_cdrom_realize " "" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_xen_cdrom_realize(void)
{
    if (true) {
        _nocheck__trace_xen_cdrom_realize();
    }
}

#define TRACE_XEN_CDROM_UNREALIZE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_XEN_CDROM_UNREALIZE) || \
    false)

static inline void _nocheck__trace_xen_cdrom_unrealize(void)
{
    if (trace_event_get_state(TRACE_XEN_CDROM_UNREALIZE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:xen_cdrom_unrealize " "" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_xen_cdrom_unrealize(void)
{
    if (true) {
        _nocheck__trace_xen_cdrom_unrealize();
    }
}

#define TRACE_XEN_BLOCK_BLOCKDEV_ADD_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_XEN_BLOCK_BLOCKDEV_ADD) || \
    false)

static inline void _nocheck__trace_xen_block_blockdev_add(char * str)
{
    if (trace_event_get_state(TRACE_XEN_BLOCK_BLOCKDEV_ADD) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:xen_block_blockdev_add " "%s" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , str);
    }
}

static inline void trace_xen_block_blockdev_add(char * str)
{
    if (true) {
        _nocheck__trace_xen_block_blockdev_add(str);
    }
}

#define TRACE_XEN_BLOCK_BLOCKDEV_DEL_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_XEN_BLOCK_BLOCKDEV_DEL) || \
    false)

static inline void _nocheck__trace_xen_block_blockdev_del(const char * node_name)
{
    if (trace_event_get_state(TRACE_XEN_BLOCK_BLOCKDEV_DEL) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:xen_block_blockdev_del " "%s" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , node_name);
    }
}

static inline void trace_xen_block_blockdev_del(const char * node_name)
{
    if (true) {
        _nocheck__trace_xen_block_blockdev_del(node_name);
    }
}

#define TRACE_XEN_BLOCK_DEVICE_CREATE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_XEN_BLOCK_DEVICE_CREATE) || \
    false)

static inline void _nocheck__trace_xen_block_device_create(unsigned int number)
{
    if (trace_event_get_state(TRACE_XEN_BLOCK_DEVICE_CREATE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:xen_block_device_create " "%u" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , number);
    }
}

static inline void trace_xen_block_device_create(unsigned int number)
{
    if (true) {
        _nocheck__trace_xen_block_device_create(number);
    }
}

#define TRACE_XEN_BLOCK_DEVICE_DESTROY_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_XEN_BLOCK_DEVICE_DESTROY) || \
    false)

static inline void _nocheck__trace_xen_block_device_destroy(unsigned int number)
{
    if (trace_event_get_state(TRACE_XEN_BLOCK_DEVICE_DESTROY) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:xen_block_device_destroy " "%u" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , number);
    }
}

static inline void trace_xen_block_device_destroy(unsigned int number)
{
    if (true) {
        _nocheck__trace_xen_block_device_destroy(number);
    }
}

#define TRACE_M25P80_FLASH_ERASE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_M25P80_FLASH_ERASE) || \
    false)

static inline void _nocheck__trace_m25p80_flash_erase(void * s, int offset, uint32_t len)
{
    if (trace_event_get_state(TRACE_M25P80_FLASH_ERASE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:m25p80_flash_erase " "[%p] offset = 0x%"PRIx32", len = %u" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, offset, len);
    }
}

static inline void trace_m25p80_flash_erase(void * s, int offset, uint32_t len)
{
    if (true) {
        _nocheck__trace_m25p80_flash_erase(s, offset, len);
    }
}

#define TRACE_M25P80_PROGRAMMING_ZERO_TO_ONE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_M25P80_PROGRAMMING_ZERO_TO_ONE) || \
    false)

static inline void _nocheck__trace_m25p80_programming_zero_to_one(void * s, uint32_t addr, uint8_t prev, uint8_t data)
{
    if (trace_event_get_state(TRACE_M25P80_PROGRAMMING_ZERO_TO_ONE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:m25p80_programming_zero_to_one " "[%p] programming zero to one! addr=0x%"PRIx32"  0x%"PRIx8" -> 0x%"PRIx8 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, addr, prev, data);
    }
}

static inline void trace_m25p80_programming_zero_to_one(void * s, uint32_t addr, uint8_t prev, uint8_t data)
{
    if (true) {
        _nocheck__trace_m25p80_programming_zero_to_one(s, addr, prev, data);
    }
}

#define TRACE_M25P80_RESET_DONE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_M25P80_RESET_DONE) || \
    false)

static inline void _nocheck__trace_m25p80_reset_done(void * s)
{
    if (trace_event_get_state(TRACE_M25P80_RESET_DONE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:m25p80_reset_done " "[%p] Reset done." "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s);
    }
}

static inline void trace_m25p80_reset_done(void * s)
{
    if (true) {
        _nocheck__trace_m25p80_reset_done(s);
    }
}

#define TRACE_M25P80_COMMAND_DECODED_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_M25P80_COMMAND_DECODED) || \
    false)

static inline void _nocheck__trace_m25p80_command_decoded(void * s, uint32_t cmd)
{
    if (trace_event_get_state(TRACE_M25P80_COMMAND_DECODED) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:m25p80_command_decoded " "[%p] new command:0x%"PRIx32 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, cmd);
    }
}

static inline void trace_m25p80_command_decoded(void * s, uint32_t cmd)
{
    if (true) {
        _nocheck__trace_m25p80_command_decoded(s, cmd);
    }
}

#define TRACE_M25P80_COMPLETE_COLLECTING_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_M25P80_COMPLETE_COLLECTING) || \
    false)

static inline void _nocheck__trace_m25p80_complete_collecting(void * s, uint32_t cmd, int n, uint8_t ear, uint32_t cur_addr)
{
    if (trace_event_get_state(TRACE_M25P80_COMPLETE_COLLECTING) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:m25p80_complete_collecting " "[%p] decode cmd: 0x%"PRIx32" len %d ear 0x%"PRIx8" addr 0x%"PRIx32 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, cmd, n, ear, cur_addr);
    }
}

static inline void trace_m25p80_complete_collecting(void * s, uint32_t cmd, int n, uint8_t ear, uint32_t cur_addr)
{
    if (true) {
        _nocheck__trace_m25p80_complete_collecting(s, cmd, n, ear, cur_addr);
    }
}

#define TRACE_M25P80_POPULATED_JEDEC_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_M25P80_POPULATED_JEDEC) || \
    false)

static inline void _nocheck__trace_m25p80_populated_jedec(void * s)
{
    if (trace_event_get_state(TRACE_M25P80_POPULATED_JEDEC) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:m25p80_populated_jedec " "[%p] populated jedec code" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s);
    }
}

static inline void trace_m25p80_populated_jedec(void * s)
{
    if (true) {
        _nocheck__trace_m25p80_populated_jedec(s);
    }
}

#define TRACE_M25P80_CHIP_ERASE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_M25P80_CHIP_ERASE) || \
    false)

static inline void _nocheck__trace_m25p80_chip_erase(void * s)
{
    if (trace_event_get_state(TRACE_M25P80_CHIP_ERASE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:m25p80_chip_erase " "[%p] chip erase" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s);
    }
}

static inline void trace_m25p80_chip_erase(void * s)
{
    if (true) {
        _nocheck__trace_m25p80_chip_erase(s);
    }
}

#define TRACE_M25P80_SELECT_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_M25P80_SELECT) || \
    false)

static inline void _nocheck__trace_m25p80_select(void * s, const char * what)
{
    if (trace_event_get_state(TRACE_M25P80_SELECT) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:m25p80_select " "[%p] %sselect" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, what);
    }
}

static inline void trace_m25p80_select(void * s, const char * what)
{
    if (true) {
        _nocheck__trace_m25p80_select(s, what);
    }
}

#define TRACE_M25P80_PAGE_PROGRAM_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_M25P80_PAGE_PROGRAM) || \
    false)

static inline void _nocheck__trace_m25p80_page_program(void * s, uint32_t addr, uint8_t tx)
{
    if (trace_event_get_state(TRACE_M25P80_PAGE_PROGRAM) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:m25p80_page_program " "[%p] page program cur_addr=0x%"PRIx32" data=0x%"PRIx8 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, addr, tx);
    }
}

static inline void trace_m25p80_page_program(void * s, uint32_t addr, uint8_t tx)
{
    if (true) {
        _nocheck__trace_m25p80_page_program(s, addr, tx);
    }
}

#define TRACE_M25P80_TRANSFER_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_M25P80_TRANSFER) || \
    false)

static inline void _nocheck__trace_m25p80_transfer(void * s, uint8_t state, uint32_t len, uint8_t needed, uint32_t pos, uint32_t cur_addr, uint8_t t)
{
    if (trace_event_get_state(TRACE_M25P80_TRANSFER) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:m25p80_transfer " "[%p] Transfer state 0x%"PRIx8" len 0x%"PRIx32" needed 0x%"PRIx8" pos 0x%"PRIx32" addr 0x%"PRIx32" tx 0x%"PRIx8 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, state, len, needed, pos, cur_addr, t);
    }
}

static inline void trace_m25p80_transfer(void * s, uint8_t state, uint32_t len, uint8_t needed, uint32_t pos, uint32_t cur_addr, uint8_t t)
{
    if (true) {
        _nocheck__trace_m25p80_transfer(s, state, len, needed, pos, cur_addr, t);
    }
}

#define TRACE_M25P80_READ_BYTE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_M25P80_READ_BYTE) || \
    false)

static inline void _nocheck__trace_m25p80_read_byte(void * s, uint32_t addr, uint8_t v)
{
    if (trace_event_get_state(TRACE_M25P80_READ_BYTE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:m25p80_read_byte " "[%p] Read byte 0x%"PRIx32"=0x%"PRIx8 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, addr, v);
    }
}

static inline void trace_m25p80_read_byte(void * s, uint32_t addr, uint8_t v)
{
    if (true) {
        _nocheck__trace_m25p80_read_byte(s, addr, v);
    }
}

#define TRACE_M25P80_READ_DATA_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_M25P80_READ_DATA) || \
    false)

static inline void _nocheck__trace_m25p80_read_data(void * s, uint32_t pos, uint8_t v)
{
    if (trace_event_get_state(TRACE_M25P80_READ_DATA) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:m25p80_read_data " "[%p] Read data 0x%"PRIx32"=0x%"PRIx8 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s, pos, v);
    }
}

static inline void trace_m25p80_read_data(void * s, uint32_t pos, uint8_t v)
{
    if (true) {
        _nocheck__trace_m25p80_read_data(s, pos, v);
    }
}

#define TRACE_M25P80_BINDING_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_M25P80_BINDING) || \
    false)

static inline void _nocheck__trace_m25p80_binding(void * s)
{
    if (trace_event_get_state(TRACE_M25P80_BINDING) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:m25p80_binding " "[%p] Binding to IF_MTD drive" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s);
    }
}

static inline void trace_m25p80_binding(void * s)
{
    if (true) {
        _nocheck__trace_m25p80_binding(s);
    }
}

#define TRACE_M25P80_BINDING_NO_BDRV_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_M25P80_BINDING_NO_BDRV) || \
    false)

static inline void _nocheck__trace_m25p80_binding_no_bdrv(void * s)
{
    if (trace_event_get_state(TRACE_M25P80_BINDING_NO_BDRV) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:m25p80_binding_no_bdrv " "[%p] No BDRV - binding to RAM" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , s);
    }
}

static inline void trace_m25p80_binding_no_bdrv(void * s)
{
    if (true) {
        _nocheck__trace_m25p80_binding_no_bdrv(s);
    }
}
#endif /* TRACE_HW_BLOCK_GENERATED_TRACERS_H */
