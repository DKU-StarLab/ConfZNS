/* This file is autogenerated by tracetool, do not edit. */

#ifndef TRACE_ACCEL_KVM_GENERATED_TRACERS_H
#define TRACE_ACCEL_KVM_GENERATED_TRACERS_H

#include "trace/control.h"

extern TraceEvent _TRACE_KVM_IOCTL_EVENT;
extern TraceEvent _TRACE_KVM_VM_IOCTL_EVENT;
extern TraceEvent _TRACE_KVM_VCPU_IOCTL_EVENT;
extern TraceEvent _TRACE_KVM_RUN_EXIT_EVENT;
extern TraceEvent _TRACE_KVM_DEVICE_IOCTL_EVENT;
extern TraceEvent _TRACE_KVM_FAILED_REG_GET_EVENT;
extern TraceEvent _TRACE_KVM_FAILED_REG_SET_EVENT;
extern TraceEvent _TRACE_KVM_INIT_VCPU_EVENT;
extern TraceEvent _TRACE_KVM_IRQCHIP_COMMIT_ROUTES_EVENT;
extern TraceEvent _TRACE_KVM_IRQCHIP_ADD_MSI_ROUTE_EVENT;
extern TraceEvent _TRACE_KVM_IRQCHIP_UPDATE_MSI_ROUTE_EVENT;
extern TraceEvent _TRACE_KVM_IRQCHIP_RELEASE_VIRQ_EVENT;
extern TraceEvent _TRACE_KVM_SET_IOEVENTFD_MMIO_EVENT;
extern TraceEvent _TRACE_KVM_SET_IOEVENTFD_PIO_EVENT;
extern TraceEvent _TRACE_KVM_SET_USER_MEMORY_EVENT;
extern TraceEvent _TRACE_KVM_CLEAR_DIRTY_LOG_EVENT;
extern TraceEvent _TRACE_KVM_RESAMPLE_FD_NOTIFY_EVENT;
extern uint16_t _TRACE_KVM_IOCTL_DSTATE;
extern uint16_t _TRACE_KVM_VM_IOCTL_DSTATE;
extern uint16_t _TRACE_KVM_VCPU_IOCTL_DSTATE;
extern uint16_t _TRACE_KVM_RUN_EXIT_DSTATE;
extern uint16_t _TRACE_KVM_DEVICE_IOCTL_DSTATE;
extern uint16_t _TRACE_KVM_FAILED_REG_GET_DSTATE;
extern uint16_t _TRACE_KVM_FAILED_REG_SET_DSTATE;
extern uint16_t _TRACE_KVM_INIT_VCPU_DSTATE;
extern uint16_t _TRACE_KVM_IRQCHIP_COMMIT_ROUTES_DSTATE;
extern uint16_t _TRACE_KVM_IRQCHIP_ADD_MSI_ROUTE_DSTATE;
extern uint16_t _TRACE_KVM_IRQCHIP_UPDATE_MSI_ROUTE_DSTATE;
extern uint16_t _TRACE_KVM_IRQCHIP_RELEASE_VIRQ_DSTATE;
extern uint16_t _TRACE_KVM_SET_IOEVENTFD_MMIO_DSTATE;
extern uint16_t _TRACE_KVM_SET_IOEVENTFD_PIO_DSTATE;
extern uint16_t _TRACE_KVM_SET_USER_MEMORY_DSTATE;
extern uint16_t _TRACE_KVM_CLEAR_DIRTY_LOG_DSTATE;
extern uint16_t _TRACE_KVM_RESAMPLE_FD_NOTIFY_DSTATE;
#define TRACE_KVM_IOCTL_ENABLED 1
#define TRACE_KVM_VM_IOCTL_ENABLED 1
#define TRACE_KVM_VCPU_IOCTL_ENABLED 1
#define TRACE_KVM_RUN_EXIT_ENABLED 1
#define TRACE_KVM_DEVICE_IOCTL_ENABLED 1
#define TRACE_KVM_FAILED_REG_GET_ENABLED 1
#define TRACE_KVM_FAILED_REG_SET_ENABLED 1
#define TRACE_KVM_INIT_VCPU_ENABLED 1
#define TRACE_KVM_IRQCHIP_COMMIT_ROUTES_ENABLED 1
#define TRACE_KVM_IRQCHIP_ADD_MSI_ROUTE_ENABLED 1
#define TRACE_KVM_IRQCHIP_UPDATE_MSI_ROUTE_ENABLED 1
#define TRACE_KVM_IRQCHIP_RELEASE_VIRQ_ENABLED 1
#define TRACE_KVM_SET_IOEVENTFD_MMIO_ENABLED 1
#define TRACE_KVM_SET_IOEVENTFD_PIO_ENABLED 1
#define TRACE_KVM_SET_USER_MEMORY_ENABLED 1
#define TRACE_KVM_CLEAR_DIRTY_LOG_ENABLED 1
#define TRACE_KVM_RESAMPLE_FD_NOTIFY_ENABLED 1
#include "qemu/log-for-trace.h"


#define TRACE_KVM_IOCTL_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_KVM_IOCTL) || \
    false)

static inline void _nocheck__trace_kvm_ioctl(int type, void * arg)
{
    if (trace_event_get_state(TRACE_KVM_IOCTL) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:kvm_ioctl " "type 0x%x, arg %p" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , type, arg);
    }
}

static inline void trace_kvm_ioctl(int type, void * arg)
{
    if (true) {
        _nocheck__trace_kvm_ioctl(type, arg);
    }
}

#define TRACE_KVM_VM_IOCTL_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_KVM_VM_IOCTL) || \
    false)

static inline void _nocheck__trace_kvm_vm_ioctl(int type, void * arg)
{
    if (trace_event_get_state(TRACE_KVM_VM_IOCTL) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:kvm_vm_ioctl " "type 0x%x, arg %p" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , type, arg);
    }
}

static inline void trace_kvm_vm_ioctl(int type, void * arg)
{
    if (true) {
        _nocheck__trace_kvm_vm_ioctl(type, arg);
    }
}

#define TRACE_KVM_VCPU_IOCTL_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_KVM_VCPU_IOCTL) || \
    false)

static inline void _nocheck__trace_kvm_vcpu_ioctl(int cpu_index, int type, void * arg)
{
    if (trace_event_get_state(TRACE_KVM_VCPU_IOCTL) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:kvm_vcpu_ioctl " "cpu_index %d, type 0x%x, arg %p" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , cpu_index, type, arg);
    }
}

static inline void trace_kvm_vcpu_ioctl(int cpu_index, int type, void * arg)
{
    if (true) {
        _nocheck__trace_kvm_vcpu_ioctl(cpu_index, type, arg);
    }
}

#define TRACE_KVM_RUN_EXIT_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_KVM_RUN_EXIT) || \
    false)

static inline void _nocheck__trace_kvm_run_exit(int cpu_index, uint32_t reason)
{
    if (trace_event_get_state(TRACE_KVM_RUN_EXIT) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:kvm_run_exit " "cpu_index %d, reason %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , cpu_index, reason);
    }
}

static inline void trace_kvm_run_exit(int cpu_index, uint32_t reason)
{
    if (true) {
        _nocheck__trace_kvm_run_exit(cpu_index, reason);
    }
}

#define TRACE_KVM_DEVICE_IOCTL_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_KVM_DEVICE_IOCTL) || \
    false)

static inline void _nocheck__trace_kvm_device_ioctl(int fd, int type, void * arg)
{
    if (trace_event_get_state(TRACE_KVM_DEVICE_IOCTL) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:kvm_device_ioctl " "dev fd %d, type 0x%x, arg %p" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , fd, type, arg);
    }
}

static inline void trace_kvm_device_ioctl(int fd, int type, void * arg)
{
    if (true) {
        _nocheck__trace_kvm_device_ioctl(fd, type, arg);
    }
}

#define TRACE_KVM_FAILED_REG_GET_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_KVM_FAILED_REG_GET) || \
    false)

static inline void _nocheck__trace_kvm_failed_reg_get(uint64_t id, const char * msg)
{
    if (trace_event_get_state(TRACE_KVM_FAILED_REG_GET) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:kvm_failed_reg_get " "Warning: Unable to retrieve ONEREG %" PRIu64 " from KVM: %s" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , id, msg);
    }
}

static inline void trace_kvm_failed_reg_get(uint64_t id, const char * msg)
{
    if (true) {
        _nocheck__trace_kvm_failed_reg_get(id, msg);
    }
}

#define TRACE_KVM_FAILED_REG_SET_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_KVM_FAILED_REG_SET) || \
    false)

static inline void _nocheck__trace_kvm_failed_reg_set(uint64_t id, const char * msg)
{
    if (trace_event_get_state(TRACE_KVM_FAILED_REG_SET) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:kvm_failed_reg_set " "Warning: Unable to set ONEREG %" PRIu64 " to KVM: %s" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , id, msg);
    }
}

static inline void trace_kvm_failed_reg_set(uint64_t id, const char * msg)
{
    if (true) {
        _nocheck__trace_kvm_failed_reg_set(id, msg);
    }
}

#define TRACE_KVM_INIT_VCPU_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_KVM_INIT_VCPU) || \
    false)

static inline void _nocheck__trace_kvm_init_vcpu(int cpu_index, unsigned long arch_cpu_id)
{
    if (trace_event_get_state(TRACE_KVM_INIT_VCPU) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:kvm_init_vcpu " "index: %d id: %lu" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , cpu_index, arch_cpu_id);
    }
}

static inline void trace_kvm_init_vcpu(int cpu_index, unsigned long arch_cpu_id)
{
    if (true) {
        _nocheck__trace_kvm_init_vcpu(cpu_index, arch_cpu_id);
    }
}

#define TRACE_KVM_IRQCHIP_COMMIT_ROUTES_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_KVM_IRQCHIP_COMMIT_ROUTES) || \
    false)

static inline void _nocheck__trace_kvm_irqchip_commit_routes(void)
{
    if (trace_event_get_state(TRACE_KVM_IRQCHIP_COMMIT_ROUTES) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:kvm_irqchip_commit_routes " "" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_kvm_irqchip_commit_routes(void)
{
    if (true) {
        _nocheck__trace_kvm_irqchip_commit_routes();
    }
}

#define TRACE_KVM_IRQCHIP_ADD_MSI_ROUTE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_KVM_IRQCHIP_ADD_MSI_ROUTE) || \
    false)

static inline void _nocheck__trace_kvm_irqchip_add_msi_route(char * name, int vector, int virq)
{
    if (trace_event_get_state(TRACE_KVM_IRQCHIP_ADD_MSI_ROUTE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:kvm_irqchip_add_msi_route " "dev %s vector %d virq %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , name, vector, virq);
    }
}

static inline void trace_kvm_irqchip_add_msi_route(char * name, int vector, int virq)
{
    if (true) {
        _nocheck__trace_kvm_irqchip_add_msi_route(name, vector, virq);
    }
}

#define TRACE_KVM_IRQCHIP_UPDATE_MSI_ROUTE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_KVM_IRQCHIP_UPDATE_MSI_ROUTE) || \
    false)

static inline void _nocheck__trace_kvm_irqchip_update_msi_route(int virq)
{
    if (trace_event_get_state(TRACE_KVM_IRQCHIP_UPDATE_MSI_ROUTE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:kvm_irqchip_update_msi_route " "Updating MSI route virq=%d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , virq);
    }
}

static inline void trace_kvm_irqchip_update_msi_route(int virq)
{
    if (true) {
        _nocheck__trace_kvm_irqchip_update_msi_route(virq);
    }
}

#define TRACE_KVM_IRQCHIP_RELEASE_VIRQ_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_KVM_IRQCHIP_RELEASE_VIRQ) || \
    false)

static inline void _nocheck__trace_kvm_irqchip_release_virq(int virq)
{
    if (trace_event_get_state(TRACE_KVM_IRQCHIP_RELEASE_VIRQ) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:kvm_irqchip_release_virq " "virq %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , virq);
    }
}

static inline void trace_kvm_irqchip_release_virq(int virq)
{
    if (true) {
        _nocheck__trace_kvm_irqchip_release_virq(virq);
    }
}

#define TRACE_KVM_SET_IOEVENTFD_MMIO_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_KVM_SET_IOEVENTFD_MMIO) || \
    false)

static inline void _nocheck__trace_kvm_set_ioeventfd_mmio(int fd, uint64_t addr, uint32_t val, bool assign, uint32_t size, bool datamatch)
{
    if (trace_event_get_state(TRACE_KVM_SET_IOEVENTFD_MMIO) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:kvm_set_ioeventfd_mmio " "fd: %d @0x%" PRIx64 " val=0x%x assign: %d size: %d match: %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , fd, addr, val, assign, size, datamatch);
    }
}

static inline void trace_kvm_set_ioeventfd_mmio(int fd, uint64_t addr, uint32_t val, bool assign, uint32_t size, bool datamatch)
{
    if (true) {
        _nocheck__trace_kvm_set_ioeventfd_mmio(fd, addr, val, assign, size, datamatch);
    }
}

#define TRACE_KVM_SET_IOEVENTFD_PIO_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_KVM_SET_IOEVENTFD_PIO) || \
    false)

static inline void _nocheck__trace_kvm_set_ioeventfd_pio(int fd, uint16_t addr, uint32_t val, bool assign, uint32_t size, bool datamatch)
{
    if (trace_event_get_state(TRACE_KVM_SET_IOEVENTFD_PIO) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:kvm_set_ioeventfd_pio " "fd: %d @0x%x val=0x%x assign: %d size: %d match: %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , fd, addr, val, assign, size, datamatch);
    }
}

static inline void trace_kvm_set_ioeventfd_pio(int fd, uint16_t addr, uint32_t val, bool assign, uint32_t size, bool datamatch)
{
    if (true) {
        _nocheck__trace_kvm_set_ioeventfd_pio(fd, addr, val, assign, size, datamatch);
    }
}

#define TRACE_KVM_SET_USER_MEMORY_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_KVM_SET_USER_MEMORY) || \
    false)

static inline void _nocheck__trace_kvm_set_user_memory(uint32_t slot, uint32_t flags, uint64_t guest_phys_addr, uint64_t memory_size, uint64_t userspace_addr, int ret)
{
    if (trace_event_get_state(TRACE_KVM_SET_USER_MEMORY) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:kvm_set_user_memory " "Slot#%d flags=0x%x gpa=0x%"PRIx64 " size=0x%"PRIx64 " ua=0x%"PRIx64 " ret=%d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , slot, flags, guest_phys_addr, memory_size, userspace_addr, ret);
    }
}

static inline void trace_kvm_set_user_memory(uint32_t slot, uint32_t flags, uint64_t guest_phys_addr, uint64_t memory_size, uint64_t userspace_addr, int ret)
{
    if (true) {
        _nocheck__trace_kvm_set_user_memory(slot, flags, guest_phys_addr, memory_size, userspace_addr, ret);
    }
}

#define TRACE_KVM_CLEAR_DIRTY_LOG_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_KVM_CLEAR_DIRTY_LOG) || \
    false)

static inline void _nocheck__trace_kvm_clear_dirty_log(uint32_t slot, uint64_t start, uint32_t size)
{
    if (trace_event_get_state(TRACE_KVM_CLEAR_DIRTY_LOG) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:kvm_clear_dirty_log " "slot#%"PRId32" start 0x%"PRIx64" size 0x%"PRIx32 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , slot, start, size);
    }
}

static inline void trace_kvm_clear_dirty_log(uint32_t slot, uint64_t start, uint32_t size)
{
    if (true) {
        _nocheck__trace_kvm_clear_dirty_log(slot, start, size);
    }
}

#define TRACE_KVM_RESAMPLE_FD_NOTIFY_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_KVM_RESAMPLE_FD_NOTIFY) || \
    false)

static inline void _nocheck__trace_kvm_resample_fd_notify(int gsi)
{
    if (trace_event_get_state(TRACE_KVM_RESAMPLE_FD_NOTIFY) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:kvm_resample_fd_notify " "gsi %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , gsi);
    }
}

static inline void trace_kvm_resample_fd_notify(int gsi)
{
    if (true) {
        _nocheck__trace_kvm_resample_fd_notify(gsi);
    }
}
#endif /* TRACE_ACCEL_KVM_GENERATED_TRACERS_H */
